<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 4.2.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css">


<script id="hexo-configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    hostname: new URL('https://longzl2015.github.io').hostname,
    root: '/',
    scheme: 'Gemini',
    version: '7.7.0',
    exturl: false,
    sidebar: {"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},
    copycode: {"enable":false,"show_result":false,"style":null},
    back2top: {"enable":true,"sidebar":false,"scrollpercent":false},
    bookmark: {"enable":false,"color":"#222","save":"auto"},
    fancybox: false,
    mediumzoom: false,
    lazyload: false,
    pangu: false,
    comments: {"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},
    algolia: {
      appID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"我们没有找到任何搜索结果: ${query}","hits_stats":"找到约${hits}条结果（用时${time}ms）"}
    },
    localsearch: {"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":true},
    path: 'search.xml',
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}
  };
</script>

  <meta property="og:type" content="website">
<meta property="og:title" content="Hexo">
<meta property="og:url" content="https://longzl2015.github.io/page/25/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="zhoul">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="https://longzl2015.github.io/page/25/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome: true,
    isPost: false
  };
</script>

  <title>Hexo</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-meta">

    <div>
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Hexo</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
  </div>

  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>
</div>


<nav class="site-nav">
  
  <ul id="menu" class="menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-fw fa-home"></i>首页</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-fw fa-tags"></i>标签<span class="badge">190</span></a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-fw fa-th"></i>分类<span class="badge">92</span></a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-fw fa-archive"></i>归档<span class="badge">351</span></a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>

</nav>
  <div class="site-search">
    <div class="popup search-popup">
    <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocorrect="off" autocapitalize="none"
           placeholder="搜索..." spellcheck="false"
           type="text" id="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result"></div>

</div>
<div class="search-pop-overlay"></div>

  </div>
</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content">
            

  <div class="posts-expand">
        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://longzl2015.github.io/2018/06/04/spring/%E6%B5%8B%E8%AF%95/%E4%BD%BF%E7%94%A8mock%E6%B5%8B%E8%AF%95/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="zhoul">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2018/06/04/spring/%E6%B5%8B%E8%AF%95/%E4%BD%BF%E7%94%A8mock%E6%B5%8B%E8%AF%95/" class="post-title-link" itemprop="url">mock测试</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2018-06-04 23:22:58" itemprop="dateCreated datePublished" datetime="2018-06-04T23:22:58+08:00">2018-06-04</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-02-27 17:16:07" itemprop="dateModified" datetime="2020-02-27T17:16:07+08:00">2020-02-27</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/spring/" itemprop="url" rel="index">
                    <span itemprop="name">spring</span>
                  </a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/spring/mock/" itemprop="url" rel="index">
                    <span itemprop="name">mock</span>
                  </a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="fa fa-comment-o"></i>
      </span>
      <span class="post-meta-item-text">Disqus：</span>
    
    <a title="disqus" href="/2018/06/04/spring/%E6%B5%8B%E8%AF%95/%E4%BD%BF%E7%94%A8mock%E6%B5%8B%E8%AF%95/#comments" itemprop="discussionUrl">
      <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2018/06/04/spring/测试/使用mock测试/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> zl.tenant.controller.impl;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.junit.Test;</span><br><span class="line"><span class="keyword">import</span> org.junit.runner.RunWith;</span><br><span class="line"><span class="keyword">import</span> org.springframework.beans.factory.annotation.Autowired;</span><br><span class="line"><span class="keyword">import</span> org.springframework.boot.test.autoconfigure.web.servlet.AutoConfigureMockMvc;</span><br><span class="line"><span class="keyword">import</span> org.springframework.boot.test.autoconfigure.web.servlet.WebMvcTest;</span><br><span class="line"><span class="keyword">import</span> org.springframework.boot.test.context.SpringBootTest;</span><br><span class="line"><span class="keyword">import</span> org.springframework.security.test.context.support.WithMockUser;</span><br><span class="line"><span class="keyword">import</span> org.springframework.test.context.ActiveProfiles;</span><br><span class="line"><span class="keyword">import</span> org.springframework.test.context.junit4.SpringRunner;</span><br><span class="line"><span class="keyword">import</span> org.springframework.test.web.servlet.MockMvc;</span><br><span class="line"><span class="keyword">import</span> org.springframework.test.web.servlet.request.MockMvcRequestBuilders;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> <span class="keyword">static</span> org.springframework.test.web.servlet.result.MockMvcResultMatchers.status;</span><br><span class="line"></span><br><span class="line"><span class="meta">@RunWith</span>(SpringRunner<span class="class">.<span class="keyword">class</span>)</span></span><br><span class="line">@ActiveProfiles("zl")</span><br><span class="line"><span class="meta">@SpringBootTest</span>(</span><br><span class="line">        properties = &#123;<span class="string">"frms.workflow.daemon.enable: false"</span>,</span><br><span class="line">                <span class="string">"dev.debug: true"</span>,</span><br><span class="line">                <span class="string">"frms.workflow.SchemaSearch: false"</span>&#125;,</span><br><span class="line">        webEnvironment = SpringBootTest.WebEnvironment.RANDOM_PORT)</span><br><span class="line"><span class="meta">@AutoConfigureMockMvc</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">PlatformApiTest</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Autowired</span></span><br><span class="line">    <span class="keyword">private</span> MockMvc mockMvc;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="meta">@WithMockUser</span>(username = <span class="string">"zl"</span>, password = <span class="string">"qqqq"</span>, authorities = &#123;<span class="string">"TENANT_LIST"</span>&#125;)</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">platformTenantListGet</span><span class="params">()</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        mockMvc.perform(</span><br><span class="line">                MockMvcRequestBuilders.get(<span class="string">"/rs/dm/platform/tenant/list"</span>)</span><br><span class="line">                        .param(<span class="string">"curPage"</span>, <span class="string">"1"</span>)</span><br><span class="line">                        .param(<span class="string">"pageSize"</span>, <span class="string">"20"</span>)</span><br><span class="line">        ).andExpect(status().isOk())</span><br><span class="line">                .andReturn();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>




      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://longzl2015.github.io/2018/06/04/spring/%E7%9B%91%E6%8E%A7/actuator/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="zhoul">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2018/06/04/spring/%E7%9B%91%E6%8E%A7/actuator/" class="post-title-link" itemprop="url">Actuator</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2018-06-04 23:22:58" itemprop="dateCreated datePublished" datetime="2018-06-04T23:22:58+08:00">2018-06-04</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-02-27 17:16:07" itemprop="dateModified" datetime="2020-02-27T17:16:07+08:00">2020-02-27</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/spring/" itemprop="url" rel="index">
                    <span itemprop="name">spring</span>
                  </a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/spring/%E7%9B%91%E6%8E%A7/" itemprop="url" rel="index">
                    <span itemprop="name">监控</span>
                  </a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="fa fa-comment-o"></i>
      </span>
      <span class="post-meta-item-text">Disqus：</span>
    
    <a title="disqus" href="/2018/06/04/spring/%E7%9B%91%E6%8E%A7/actuator/#comments" itemprop="discussionUrl">
      <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2018/06/04/spring/监控/actuator/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="SpringBoot四大神器之-Actuator"><a href="#SpringBoot四大神器之-Actuator" class="headerlink" title="SpringBoot四大神器之 Actuator"></a>SpringBoot四大神器之 Actuator</h1><p>[TOC]</p>
<h2 id="序"><a href="#序" class="headerlink" title="序"></a>序</h2><p>Spring Boot有四大神器，分别是auto-configuration、starters、cli、actuator，本文主要讲actuator。actuator是spring boot提供的对应用系统的自省和监控的集成功能，可以对应用系统进行配置查看、相关功能统计等。</p>
<h2 id="使用actuator"><a href="#使用actuator" class="headerlink" title="使用actuator"></a>使用actuator</h2><ul>
<li>添加依赖</li>
</ul>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.boot<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-boot-starter-actuator<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>

<h2 id="主要暴露的功能"><a href="#主要暴露的功能" class="headerlink" title="主要暴露的功能"></a>主要暴露的功能</h2><table>
<thead>
<tr>
<th>HTTP方法</th>
<th>路径</th>
<th>描述</th>
<th>鉴权</th>
</tr>
</thead>
<tbody><tr>
<td>GET</td>
<td>/autoconfig</td>
<td>查看自动配置的使用情况</td>
<td>true</td>
</tr>
<tr>
<td>GET</td>
<td>/configprops</td>
<td>查看配置属性，包括默认配置</td>
<td>true</td>
</tr>
<tr>
<td>GET</td>
<td>/beans</td>
<td>查看bean及其关系列表</td>
<td>true</td>
</tr>
<tr>
<td>GET</td>
<td>/dump</td>
<td>打印线程栈</td>
<td>true</td>
</tr>
<tr>
<td>GET</td>
<td>/env</td>
<td>查看所有环境变量</td>
<td>true</td>
</tr>
<tr>
<td>GET</td>
<td>/env/{name}</td>
<td>查看具体变量值</td>
<td>true</td>
</tr>
<tr>
<td>GET</td>
<td>/health</td>
<td>查看应用健康指标</td>
<td>false</td>
</tr>
<tr>
<td>GET</td>
<td>/info</td>
<td>查看应用信息</td>
<td>false</td>
</tr>
<tr>
<td>GET</td>
<td>/mappings</td>
<td>查看所有url映射</td>
<td>true</td>
</tr>
<tr>
<td>GET</td>
<td>/metrics</td>
<td>查看应用基本指标</td>
<td>true</td>
</tr>
<tr>
<td>GET</td>
<td>/metrics/{name}</td>
<td>查看具体指标</td>
<td>true</td>
</tr>
<tr>
<td>POST</td>
<td>/shutdown</td>
<td>关闭应用</td>
<td>true</td>
</tr>
<tr>
<td>GET</td>
<td>/trace</td>
<td>查看基本追踪信息</td>
<td>true</td>
</tr>
</tbody></table>
<h3 id="autoconfig"><a href="#autoconfig" class="headerlink" title="/autoconfig"></a>/autoconfig</h3><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="attr">"positiveMatches"</span>: &#123;</span><br><span class="line">        <span class="attr">"AuditAutoConfiguration.AuditEventRepositoryConfiguration"</span>: [</span><br><span class="line">            &#123;</span><br><span class="line">                <span class="attr">"condition"</span>: <span class="string">"OnBeanCondition"</span>, </span><br><span class="line">                <span class="attr">"message"</span>: <span class="string">"@ConditionalOnMissingBean (types: org.springframework.boot.actuate.audit.AuditEventRepository; SearchStrategy: all) found no beans"</span></span><br><span class="line">            &#125;</span><br><span class="line">        ]</span><br><span class="line">    &#125;, </span><br><span class="line">    <span class="attr">"negativeMatches"</span>: &#123;</span><br><span class="line">        <span class="attr">"CacheStatisticsAutoConfiguration"</span>: [</span><br><span class="line">            &#123;</span><br><span class="line">                <span class="attr">"condition"</span>: <span class="string">"OnBeanCondition"</span>, </span><br><span class="line">                <span class="attr">"message"</span>: <span class="string">"@ConditionalOnBean (types: org.springframework.cache.CacheManager; SearchStrategy: all) found no beans"</span></span><br><span class="line">            &#125;</span><br><span class="line">        ]</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="configprops"><a href="#configprops" class="headerlink" title="/configprops"></a>/configprops</h3><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="attr">"management.health.status.CONFIGURATION_PROPERTIES"</span>: &#123;</span><br><span class="line">        <span class="attr">"prefix"</span>: <span class="string">"management.health.status"</span>, </span><br><span class="line">        <span class="attr">"properties"</span>: &#123;</span><br><span class="line">            <span class="attr">"order"</span>: <span class="literal">null</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;, </span><br><span class="line">    <span class="attr">"multipart.CONFIGURATION_PROPERTIES"</span>: &#123;</span><br><span class="line">        <span class="attr">"prefix"</span>: <span class="string">"multipart"</span>, </span><br><span class="line">        <span class="attr">"properties"</span>: &#123;</span><br><span class="line">            <span class="attr">"enabled"</span>: <span class="literal">false</span>, </span><br><span class="line">            <span class="attr">"maxRequestSize"</span>: <span class="string">"10Mb"</span>, </span><br><span class="line">            <span class="attr">"location"</span>: <span class="literal">null</span>, </span><br><span class="line">            <span class="attr">"fileSizeThreshold"</span>: <span class="string">"0"</span>, </span><br><span class="line">            <span class="attr">"maxFileSize"</span>: <span class="string">"1Mb"</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;, </span><br><span class="line">    <span class="attr">"environmentEndpoint"</span>: &#123;</span><br><span class="line">        <span class="attr">"prefix"</span>: <span class="string">"endpoints.env"</span>, </span><br><span class="line">        <span class="attr">"properties"</span>: &#123;</span><br><span class="line">            <span class="attr">"id"</span>: <span class="string">"env"</span>, </span><br><span class="line">            <span class="attr">"enabled"</span>: <span class="literal">true</span>, </span><br><span class="line">            <span class="attr">"sensitive"</span>: <span class="literal">true</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="beans"><a href="#beans" class="headerlink" title="/beans"></a>/beans</h3><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">[</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="attr">"context"</span>: <span class="string">"application:8080"</span>, </span><br><span class="line">        <span class="attr">"parent"</span>: <span class="literal">null</span>, </span><br><span class="line">        <span class="attr">"beans"</span>: [</span><br><span class="line">            &#123;</span><br><span class="line">                <span class="attr">"bean"</span>: <span class="string">"appMain"</span>, </span><br><span class="line">                <span class="attr">"scope"</span>: <span class="string">"singleton"</span>, </span><br><span class="line">                <span class="attr">"type"</span>: <span class="string">"com.xixicat.AppMain$$EnhancerBySpringCGLIB$$29382b14"</span>, </span><br><span class="line">                <span class="attr">"resource"</span>: <span class="string">"null"</span>, </span><br><span class="line">                <span class="attr">"dependencies"</span>: [ ]</span><br><span class="line">            &#125;, </span><br><span class="line">            &#123;</span><br><span class="line">                <span class="attr">"bean"</span>: <span class="string">"videoInfoMapper"</span>, </span><br><span class="line">                <span class="attr">"scope"</span>: <span class="string">"singleton"</span>, </span><br><span class="line">                <span class="attr">"type"</span>: <span class="string">"com.xixicat.dao.VideoInfoMapper"</span>, </span><br><span class="line">                <span class="attr">"resource"</span>: <span class="string">"file [/Users/xixicat/workspace/video-uber/target/classes/com/xixicat/dao/VideoInfoMapper.class]"</span>, </span><br><span class="line">                <span class="attr">"dependencies"</span>: [</span><br><span class="line">                    <span class="string">"sqlSessionFactory"</span></span><br><span class="line">                ]</span><br><span class="line">            &#125;</span><br><span class="line">        ]</span><br><span class="line">    &#125;</span><br><span class="line">]</span><br></pre></td></tr></table></figure>

<h3 id="dump"><a href="#dump" class="headerlink" title="/dump"></a>/dump</h3><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line">[</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="attr">"threadName"</span>: <span class="string">"Signal Dispatcher"</span>, </span><br><span class="line">        <span class="attr">"threadId"</span>: <span class="number">4</span>, </span><br><span class="line">        <span class="attr">"blockedTime"</span>: <span class="number">-1</span>, </span><br><span class="line">        <span class="attr">"blockedCount"</span>: <span class="number">0</span>, </span><br><span class="line">        <span class="attr">"waitedTime"</span>: <span class="number">-1</span>, </span><br><span class="line">        <span class="attr">"waitedCount"</span>: <span class="number">0</span>, </span><br><span class="line">        <span class="attr">"lockName"</span>: <span class="literal">null</span>, </span><br><span class="line">        <span class="attr">"lockOwnerId"</span>: <span class="number">-1</span>, </span><br><span class="line">        <span class="attr">"lockOwnerName"</span>: <span class="literal">null</span>, </span><br><span class="line">        <span class="attr">"inNative"</span>: <span class="literal">false</span>, </span><br><span class="line">        <span class="attr">"suspended"</span>: <span class="literal">false</span>, </span><br><span class="line">        <span class="attr">"threadState"</span>: <span class="string">"RUNNABLE"</span>, </span><br><span class="line">        <span class="attr">"stackTrace"</span>: [ ], </span><br><span class="line">        <span class="attr">"lockedMonitors"</span>: [ ], </span><br><span class="line">        <span class="attr">"lockedSynchronizers"</span>: [ ], </span><br><span class="line">        <span class="attr">"lockInfo"</span>: <span class="literal">null</span></span><br><span class="line">    &#125;, </span><br><span class="line">    &#123;</span><br><span class="line">        <span class="attr">"threadName"</span>: <span class="string">"Reference Handler"</span>, </span><br><span class="line">        <span class="attr">"threadId"</span>: <span class="number">2</span>, </span><br><span class="line">        <span class="attr">"blockedTime"</span>: <span class="number">-1</span>, </span><br><span class="line">        <span class="attr">"blockedCount"</span>: <span class="number">217</span>, </span><br><span class="line">        <span class="attr">"waitedTime"</span>: <span class="number">-1</span>, </span><br><span class="line">        <span class="attr">"waitedCount"</span>: <span class="number">9</span>, </span><br><span class="line">        <span class="attr">"lockName"</span>: <span class="string">"java.lang.ref.Reference$Lock@45de945"</span>, </span><br><span class="line">        <span class="attr">"lockOwnerId"</span>: <span class="number">-1</span>, </span><br><span class="line">        <span class="attr">"lockOwnerName"</span>: <span class="literal">null</span>, </span><br><span class="line">        <span class="attr">"inNative"</span>: <span class="literal">false</span>, </span><br><span class="line">        <span class="attr">"suspended"</span>: <span class="literal">false</span>, </span><br><span class="line">        <span class="attr">"threadState"</span>: <span class="string">"WAITING"</span>, </span><br><span class="line">        <span class="attr">"stackTrace"</span>: [</span><br><span class="line">            &#123;</span><br><span class="line">                <span class="attr">"methodName"</span>: <span class="string">"wait"</span>, </span><br><span class="line">                <span class="attr">"fileName"</span>: <span class="string">"Object.java"</span>, </span><br><span class="line">                <span class="attr">"lineNumber"</span>: <span class="number">-2</span>, </span><br><span class="line">                <span class="attr">"className"</span>: <span class="string">"java.lang.Object"</span>, </span><br><span class="line">                <span class="attr">"nativeMethod"</span>: <span class="literal">true</span></span><br><span class="line">            &#125;, </span><br><span class="line">            &#123;</span><br><span class="line">                <span class="attr">"methodName"</span>: <span class="string">"wait"</span>, </span><br><span class="line">                <span class="attr">"fileName"</span>: <span class="string">"Object.java"</span>, </span><br><span class="line">                <span class="attr">"lineNumber"</span>: <span class="number">503</span>, </span><br><span class="line">                <span class="attr">"className"</span>: <span class="string">"java.lang.Object"</span>, </span><br><span class="line">                <span class="attr">"nativeMethod"</span>: <span class="literal">false</span></span><br><span class="line">            &#125;, </span><br><span class="line">            &#123;</span><br><span class="line">                <span class="attr">"methodName"</span>: <span class="string">"run"</span>, </span><br><span class="line">                <span class="attr">"fileName"</span>: <span class="string">"Reference.java"</span>, </span><br><span class="line">                <span class="attr">"lineNumber"</span>: <span class="number">133</span>, </span><br><span class="line">                <span class="attr">"className"</span>: <span class="string">"java.lang.ref.Reference$ReferenceHandler"</span>, </span><br><span class="line">                <span class="attr">"nativeMethod"</span>: <span class="literal">false</span></span><br><span class="line">            &#125;</span><br><span class="line">        ], </span><br><span class="line">        <span class="attr">"lockedMonitors"</span>: [ ], </span><br><span class="line">        <span class="attr">"lockedSynchronizers"</span>: [ ], </span><br><span class="line">        <span class="attr">"lockInfo"</span>: &#123;</span><br><span class="line">            <span class="attr">"className"</span>: <span class="string">"java.lang.ref.Reference$Lock"</span>, </span><br><span class="line">            <span class="attr">"identityHashCode"</span>: <span class="number">73263429</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">]</span><br></pre></td></tr></table></figure>

<h3 id="env"><a href="#env" class="headerlink" title="/env"></a>/env</h3><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  profiles: [],</span><br><span class="line">  server.ports: &#123;</span><br><span class="line">    local.server.port: 8080</span><br><span class="line">  &#125;,</span><br><span class="line">  servletContextInitParams: &#123;&#125;,</span><br><span class="line">  systemProperties: &#123;</span><br><span class="line">    java.runtime.name: "Java(TM) SE Runtime Environment",</span><br><span class="line">      sun.boot.library.path: "/Library/Java/JavaVirtualMachines/jdk1.7.0_79.jdk/Contents/Home/jre/lib",</span><br><span class="line">      java.vm.version: "24.79-b02",</span><br><span class="line">      gopherProxySet: "false",</span><br><span class="line">      maven.multiModuleProjectDirectory: "/Users/xixicat/workspace/video-uber",</span><br><span class="line">      java.vm.vendor: "Oracle Corporation",</span><br><span class="line">      java.vendor.url: "http://java.oracle.com/",</span><br><span class="line">      guice.disable.misplaced.annotation.check: "true",</span><br><span class="line">      path.separator: ":",</span><br><span class="line">      java.vm.name: "Java HotSpot(TM) 64-Bit Server VM",</span><br><span class="line">      file.encoding.pkg: "sun.io",</span><br><span class="line">      user.country: "CN",</span><br><span class="line">      sun.java.launcher: "SUN_STANDARD",</span><br><span class="line">      sun.os.patch.level: "unknown",</span><br><span class="line">      PID: "763",</span><br><span class="line">      java.vm.specification.name: "Java Virtual Machine Specification",</span><br><span class="line">      user.dir: "/Users/xixicat/workspace/video-uber",</span><br><span class="line">      java.runtime.version: "1.7.0_79-b15",</span><br><span class="line">      java.awt.graphicsenv: "sun.awt.CGraphicsEnvironment",</span><br><span class="line">      java.endorsed.dirs: "/Library/Java/JavaVirtualMachines/jdk1.7.0_79.jdk/Contents/Home/jre/lib/endorsed",</span><br><span class="line">      os.arch: "x86_64",</span><br><span class="line">      java.io.tmpdir: "/var/folders/tl/xkf4nr61033gd6lk5d3llz080000gn/T/",</span><br><span class="line">      line.separator: " ",</span><br><span class="line">      java.vm.specification.vendor: "Oracle Corporation",</span><br><span class="line">      os.name: "Mac OS X",</span><br><span class="line">      classworlds.conf: "/Users/xixicat/devtool/maven-3.3.3/bin/m2.conf",</span><br><span class="line">      sun.jnu.encoding: "UTF-8",</span><br><span class="line">      spring.beaninfo.ignore: "true",</span><br><span class="line">      java.library.path: "/Users/xixicat/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:.",</span><br><span class="line">      java.specification.name: "Java Platform API Specification",</span><br><span class="line">      java.class.version: "51.0",</span><br><span class="line">      sun.management.compiler: "HotSpot 64-Bit Tiered Compilers",</span><br><span class="line">      os.version: "10.10.5",</span><br><span class="line">      user.home: "/Users/xixicat",</span><br><span class="line">      user.timezone: "Asia/Shanghai",</span><br><span class="line">      java.awt.printerjob: "sun.lwawt.macosx.CPrinterJob",</span><br><span class="line">      file.encoding: "UTF-8",</span><br><span class="line">      java.specification.version: "1.7",</span><br><span class="line">      java.class.path: "/Users/xixicat/devtool/maven-3.3.3/boot/plexus-classworlds-2.5.2.jar",</span><br><span class="line">      user.name: "xixicat",</span><br><span class="line">      java.vm.specification.version: "1.7",</span><br><span class="line">      sun.java.command: "org.codehaus.plexus.classworlds.launcher.Launcher spring-boot:run",</span><br><span class="line">      java.home: "/Library/Java/JavaVirtualMachines/jdk1.7.0_79.jdk/Contents/Home/jre",</span><br><span class="line">      sun.arch.data.model: "64",</span><br><span class="line">      user.language: "zh",</span><br><span class="line">      java.specification.vendor: "Oracle Corporation",</span><br><span class="line">      awt.toolkit: "sun.lwawt.macosx.LWCToolkit",</span><br><span class="line">      java.vm.info: "mixed mode",</span><br><span class="line">      java.version: "1.7.0_79",</span><br><span class="line">      java.ext.dirs: "/Users/xixicat/Library/Java/Extensions:/Library/Java/JavaVirtualMachines/jdk1.7.0_79.jdk/Contents/Home/jre/lib/ext:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java",</span><br><span class="line">      sun.boot.class.path: "/Library/Java/JavaVirtualMachines/jdk1.7.0_79.jdk/Contents/Home/jre/lib/resources.jar:/Library/Java/JavaVirtualMachines/jdk1.7.0_79.jdk/Contents/Home/jre/lib/rt.jar:/Library/Java/JavaVirtualMachines/jdk1.7.0_79.jdk/Contents/Home/jre/lib/sunrsasign.jar:/Library/Java/JavaVirtualMachines/jdk1.7.0_79.jdk/Contents/Home/jre/lib/jsse.jar:/Library/Java/JavaVirtualMachines/jdk1.7.0_79.jdk/Contents/Home/jre/lib/jce.jar:/Library/Java/JavaVirtualMachines/jdk1.7.0_79.jdk/Contents/Home/jre/lib/charsets.jar:/Library/Java/JavaVirtualMachines/jdk1.7.0_79.jdk/Contents/Home/jre/lib/jfr.jar:/Library/Java/JavaVirtualMachines/jdk1.7.0_79.jdk/Contents/Home/jre/classes",</span><br><span class="line">      java.awt.headless: "true",</span><br><span class="line">      java.vendor: "Oracle Corporation",</span><br><span class="line">      maven.home: "/Users/xixicat/devtool/maven-3.3.3",</span><br><span class="line">      file.separator: "/",</span><br><span class="line">      LOG_EXCEPTION_CONVERSION_WORD: "%wEx",</span><br><span class="line">      java.vendor.url.bug: "http://bugreport.sun.com/bugreport/",</span><br><span class="line">      sun.io.unicode.encoding: "UnicodeBig",</span><br><span class="line">      sun.cpu.endian: "little",</span><br><span class="line">      sun.cpu.isalist: ""</span><br><span class="line">  &#125;,</span><br><span class="line">  systemEnvironment: &#123;</span><br><span class="line">    TERM: "xterm-256color",</span><br><span class="line">    ZSH: "/Users/xixicat/.oh-my-zsh",</span><br><span class="line">    GVM_BROKER_SERVICE: "http://release.gvm.io",</span><br><span class="line">    GRIFFON_HOME: "/Users/xixicat/.gvm/griffon/current",</span><br><span class="line">    JAVA_MAIN_CLASS_763: "org.codehaus.plexus.classworlds.launcher.Launcher",</span><br><span class="line">    JAVA_HOME: "/Library/Java/JavaVirtualMachines/jdk1.7.0_79.jdk/Contents/Home",</span><br><span class="line">    SHLVL: "1",</span><br><span class="line">    MAVEN_CMD_LINE_ARGS: " spring-boot:run",</span><br><span class="line">    __CF_USER_TEXT_ENCODING: "0x1F5:0x19:0x34",</span><br><span class="line">    GROOVY_HOME: "/Users/xixicat/.gvm/groovy/current",</span><br><span class="line">    XPC_FLAGS: "0x0",</span><br><span class="line">    GVM_INIT: "true",</span><br><span class="line">    JBAKE_HOME: "/Users/xixicat/.gvm/jbake/current",</span><br><span class="line">    PWD: "/Users/xixicat/workspace/video-uber",</span><br><span class="line">    GVM_DIR: "/Users/xixicat/.gvm",</span><br><span class="line">    GVM_VERSION: "2.4.3",</span><br><span class="line">    MAVEN_PROJECTBASEDIR: "/Users/xixicat/workspace/video-uber",</span><br><span class="line">    LOGNAME: "xixicat",</span><br><span class="line">    SSH_AUTH_SOCK: "/private/tmp/com.apple.launchd.93xr1duECQ/Listeners",</span><br><span class="line">    SPRINGBOOT_HOME: "/Users/xixicat/.gvm/springboot/current",</span><br><span class="line">    GAIDEN_HOME: "/Users/xixicat/.gvm/gaiden/current",</span><br><span class="line">    LAZYBONES_HOME: "/Users/xixicat/.gvm/lazybones/current",</span><br><span class="line">    OLDPWD: "/Users/xixicat/workspace/video-uber",</span><br><span class="line">    SHELL: "/bin/zsh",</span><br><span class="line">    JBOSSFORGE_HOME: "/Users/xixicat/.gvm/jbossforge/current",</span><br><span class="line">    LC_CTYPE: "zh_CN.UTF-8",</span><br><span class="line">    TMPDIR: "/var/folders/tl/xkf4nr61033gd6lk5d3llz080000gn/T/",</span><br><span class="line">    GVM_SERVICE: "http://api.gvmtool.net",</span><br><span class="line">    GVM_PLATFORM: "Darwin",</span><br><span class="line">    CLASSPATH: ".:/Users/xixicat/.m2/repository/co/paralleluniverse/quasar-core/0.7.2/quasar-core-0.7.2.jar",</span><br><span class="line">    GLIDE_HOME: "/Users/xixicat/.gvm/glide/current",</span><br><span class="line">    PATH: "/Users/xixicat/.gvm/vertx/current/bin:/Users/xixicat/.gvm/springboot/current/bin:/Users/xixicat/.gvm/lazybones/current/bin:/Users/xixicat/.gvm/jbossforge/current/bin:/Users/xixicat/.gvm/jbake/current/bin:/Users/xixicat/.gvm/groovyserv/current/bin:/Users/xixicat/.gvm/groovy/current/bin:/Users/xixicat/.gvm/griffon/current/bin:/Users/xixicat/.gvm/grails/current/bin:/Users/xixicat/.gvm/gradle/current/bin:/Users/xixicat/.gvm/glide/current/bin:/Users/xixicat/.gvm/gaiden/current/bin:/Users/xixicat/.gvm/crash/current/bin:/Users/xixicat/.gvm/asciidoctorj/current/bin:/Users/xixicat/bin:/usr/local/bin:/usr/local/bin:/usr/bin:/bin:/usr/sbin:/sbin:/usr/local/git/bin:/Users/xixicat/devtool/maven-3.3.3/bin:/Users/xixicat/devtool/gradle-2.6/bin:/Users/xixicat/devtool/android-sdk/platform-tools",</span><br><span class="line">    GRADLE_HOME: "/Users/xixicat/.gvm/gradle/current",</span><br><span class="line">    GROOVYSERV_HOME: "/Users/xixicat/.gvm/groovyserv/current",</span><br><span class="line">    GRAILS_HOME: "/Users/xixicat/.gvm/grails/current",</span><br><span class="line">    USER: "xixicat",</span><br><span class="line">    LESS: "-R",</span><br><span class="line">    PAGER: "less",</span><br><span class="line">    HOME: "/Users/xixicat",</span><br><span class="line">    CRASH_HOME: "/Users/xixicat/.gvm/crash/current",</span><br><span class="line">    XPC_SERVICE_NAME: "0",</span><br><span class="line">    VERTX_HOME: "/Users/xixicat/.gvm/vertx/current",</span><br><span class="line">    GVM_BROADCAST_SERVICE: "http://cast.gvm.io",</span><br><span class="line">    Apple_PubSub_Socket_Render: "/private/tmp/com.apple.launchd.y6fNwP8Sk6/Render",</span><br><span class="line">    LSCOLORS: "Gxfxcxdxbxegedabagacad",</span><br><span class="line">    ASCIIDOCTORJ_HOME: "/Users/xixicat/.gvm/asciidoctorj/current"</span><br><span class="line">  &#125;,</span><br><span class="line">  applicationConfig: [classpath: /application.properties]: &#123;</span><br><span class="line">    pool.acquireIncrement: "1",</span><br><span class="line">    pool.minPoolSize: "5",</span><br><span class="line">    pool.initialPoolSize: "1",</span><br><span class="line">    database.username: "root",</span><br><span class="line">    pool.maxIdleTime: "60",</span><br><span class="line">    database.url: "jdbc:mysql://127.0.0.1:3307/video_uber?autoReconnect=true&amp;useUnicode=true&amp;characterEncoding=UTF-8&amp;zeroDateTimeBehavior=convertToNull",</span><br><span class="line">    spring.jackson.dateFormat: "yyyy-MM-dd'T'HH:mm:ss",</span><br><span class="line">    database.slave.username: "root",</span><br><span class="line">    spring.jackson.serialization.write - dates - as - timestamps: "false",</span><br><span class="line">    pool.idleTimeout: "30000",</span><br><span class="line">    database.slave.url: "jdbc:mysql://127.0.0.1:3307/demo?autoReconnect=true&amp;useUnicode=true&amp;characterEncoding=UTF-8&amp;zeroDateTimeBehavior=convertToNull",</span><br><span class="line">    server.port: "8080",</span><br><span class="line">    database.slave.password: "******",</span><br><span class="line">    database.password: "******",</span><br><span class="line">    database.driverClassName: "com.mysql.jdbc.Driver",</span><br><span class="line">    pool.maxPoolSize: "50",</span><br><span class="line">    database.dataSourceClassName: "com.mysql.jdbc.jdbc2.optional.MysqlDataSource"</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="health"><a href="#health" class="headerlink" title="/health"></a>/health</h3><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  status: "UP",</span><br><span class="line">  diskSpace: &#123;</span><br><span class="line">    status: "UP",</span><br><span class="line">    total: 249779191808,</span><br><span class="line">    free: 193741590528,</span><br><span class="line">    threshold: 10485760</span><br><span class="line">  &#125;,</span><br><span class="line">  db: &#123;</span><br><span class="line">    status: "UP",</span><br><span class="line">    database: "MySQL",</span><br><span class="line">    hello: 1</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="info"><a href="#info" class="headerlink" title="/info"></a>/info</h3><p>需要自己在application.properties里头添加信息，比如</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">info:</span><br><span class="line">  contact:</span><br><span class="line">    email: xixicat@gmail.com</span><br><span class="line">    phone: 0755-82890987</span><br></pre></td></tr></table></figure>

<p>然后请求就可以出来了</p>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="attr">"contact"</span>: &#123;</span><br><span class="line">     <span class="attr">"phone"</span>: <span class="string">"0755-82890987"</span>,</span><br><span class="line">     <span class="attr">"email"</span>: <span class="string">"xixicat@gmail.com"</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="mappings"><a href="#mappings" class="headerlink" title="/mappings"></a>/mappings</h3><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">   &#123;</span><br><span class="line">     [/metrics || /metrics.json], methods = [GET], produces = [application / json]</span><br><span class="line">   &#125;: &#123;</span><br><span class="line">     bean: "endpointHandlerMapping",</span><br><span class="line">     method: "public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()"</span><br><span class="line">   &#125;, &#123;</span><br><span class="line">     [/beans || /beans.json], methods = [GET], produces = [application / json]</span><br><span class="line">   &#125;: &#123;</span><br><span class="line">     bean: "endpointHandlerMapping",</span><br><span class="line">     method: "public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()"</span><br><span class="line">   &#125;, &#123;</span><br><span class="line">     [/health || /health.json], produces = [application / json]</span><br><span class="line">   &#125;: &#123;</span><br><span class="line">     bean: "endpointHandlerMapping",</span><br><span class="line">     method: "public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.HealthMvcEndpoint.invoke(java.security.Principal)"</span><br><span class="line">   &#125;, &#123;</span><br><span class="line">     [/info || /info.json], methods = [GET], produces = [application / json]</span><br><span class="line">   &#125;: &#123;</span><br><span class="line">     bean: "endpointHandlerMapping",</span><br><span class="line">     method: "public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()"</span><br><span class="line">   &#125;, &#123;</span><br><span class="line">     [/trace || /trace.json], methods = [GET], produces = [application / json]</span><br><span class="line">   &#125;: &#123;</span><br><span class="line">     bean: "endpointHandlerMapping",</span><br><span class="line">     method: "public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()"</span><br><span class="line">   &#125;, &#123;</span><br><span class="line">     [/autoconfig || /autoconfig.json], methods = [GET], produces = [application / json]</span><br><span class="line">   &#125;: &#123;</span><br><span class="line">     bean: "endpointHandlerMapping",</span><br><span class="line">     method: "public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()"</span><br><span class="line">   &#125;</span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure>

<h3 id="metrics"><a href="#metrics" class="headerlink" title="/metrics"></a>/metrics</h3><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">mem: 499404,</span><br><span class="line">mem.free: 257591,</span><br><span class="line">processors: 8,</span><br><span class="line">instance.uptime: 4284997,</span><br><span class="line">uptime: 4294909,</span><br><span class="line">systemload.average: 1.84521484375,</span><br><span class="line">heap.committed: 437248,</span><br><span class="line">heap.init: 262144,</span><br><span class="line">heap.used: 179656,</span><br><span class="line">heap: 3728384,</span><br><span class="line">nonheap.committed: 62848,</span><br><span class="line">nonheap.init: 24000,</span><br><span class="line">nonheap.used: 62156,</span><br><span class="line">nonheap: 133120,</span><br><span class="line">threads.peak: 18,</span><br><span class="line">threads.daemon: 6,</span><br><span class="line">threads.totalStarted: 176,</span><br><span class="line">threads: 16,</span><br><span class="line">classes: 10294,</span><br><span class="line">classes.loaded: 10294,</span><br><span class="line">classes.unloaded: 0,</span><br><span class="line">gc.ps_scavenge.count: 11,</span><br><span class="line">gc.ps_scavenge.time: 405,</span><br><span class="line">gc.ps_marksweep.count: 0,</span><br><span class="line">gc.ps_marksweep.time: 0,</span><br><span class="line">datasource.primary.active: 0,</span><br><span class="line">datasource.primary.usage: 0,</span><br><span class="line">counter.status.200.autoconfig: 1,</span><br><span class="line">counter.status.200.beans: 1,</span><br><span class="line">counter.status.200.configprops: 1,</span><br><span class="line">counter.status.200.dump: 1,</span><br><span class="line">counter.status.200.env: 1,</span><br><span class="line">counter.status.200.health: 1,</span><br><span class="line">counter.status.200.info: 1,</span><br><span class="line">counter.status.200.mappings: 1,</span><br><span class="line">gauge.response.autoconfig: 81,</span><br><span class="line">gauge.response.beans: 15,</span><br><span class="line">gauge.response.configprops: 105,</span><br><span class="line">gauge.response.dump: 76,</span><br><span class="line">gauge.response.env: 4,</span><br><span class="line">gauge.response.health: 43,</span><br><span class="line">gauge.response.info: 1,</span><br><span class="line">gauge.response.mappings: 4</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="shutdown"><a href="#shutdown" class="headerlink" title="/shutdown"></a>/shutdown</h3><p>要真正生效，得配置文件开启</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">endpoints.shutdown.enabled: true</span><br></pre></td></tr></table></figure>

<h3 id="trace"><a href="#trace" class="headerlink" title="/trace"></a>/trace</h3><p>记录最近100个请求的信息</p>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line">[&#123;</span><br><span class="line">  <span class="attr">"timestamp"</span>: <span class="number">1452955704922</span>,</span><br><span class="line">  <span class="attr">"info"</span>: &#123;</span><br><span class="line">    <span class="attr">"method"</span>: <span class="string">"GET"</span>,</span><br><span class="line">    <span class="attr">"path"</span>: <span class="string">"/metrics"</span>,</span><br><span class="line">    <span class="attr">"headers"</span>: &#123;</span><br><span class="line">      <span class="attr">"request"</span>: &#123;</span><br><span class="line">        <span class="attr">"Accept - Encoding"</span>: <span class="string">"gzip, deflate, sdch"</span>,</span><br><span class="line">          <span class="attr">"Upgrade - Insecure - Requests"</span>: <span class="string">"1"</span>,</span><br><span class="line">          <span class="attr">"Accept - Language"</span>: <span class="string">"zh-CN,zh;q=0.8,en;q=0.6"</span>,</span><br><span class="line">          <span class="attr">"User - Agent"</span>: <span class="string">"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/47.0.2526.111 Safari/537.36"</span>,</span><br><span class="line">          <span class="attr">"Accept"</span>: <span class="string">"text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8"</span>,</span><br><span class="line">          <span class="attr">"Connection"</span>: <span class="string">"keep-alive"</span>,</span><br><span class="line">          <span class="attr">"Host"</span>: <span class="string">"localhost:8080"</span></span><br><span class="line">      &#125;,</span><br><span class="line">      <span class="attr">"response"</span>: &#123;</span><br><span class="line">        <span class="attr">"Content - Type"</span>: <span class="string">"application/json; charset=UTF-8"</span>,</span><br><span class="line">          <span class="attr">"X - Application - Context"</span>: <span class="string">"application:8080"</span>,</span><br><span class="line">          <span class="attr">"Date"</span>: <span class="string">"Sat, 16 Jan 2016 14:48:24 GMT"</span>,</span><br><span class="line">          <span class="attr">"status"</span>: <span class="string">"200"</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;, &#123;</span><br><span class="line">  <span class="attr">"timestamp"</span>: <span class="number">1452951489549</span>,</span><br><span class="line">  <span class="attr">"info"</span>: &#123;</span><br><span class="line">    <span class="attr">"method"</span>: <span class="string">"GET"</span>,</span><br><span class="line">    <span class="attr">"path"</span>: <span class="string">"/autoconfig"</span>,</span><br><span class="line">    <span class="attr">"headers"</span>: &#123;</span><br><span class="line">      <span class="attr">"request"</span>: &#123;</span><br><span class="line">        <span class="attr">"Accept - Encoding"</span>: <span class="string">"gzip, deflate, sdch"</span>,</span><br><span class="line">          <span class="attr">"Upgrade - Insecure - Requests"</span>: <span class="string">"1"</span>,</span><br><span class="line">          <span class="attr">"Accept - Language"</span>: <span class="string">"zh-CN,zh;q=0.8,en;q=0.6"</span>,</span><br><span class="line">          <span class="attr">"User - Agent"</span>: <span class="string">"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/47.0.2526.111 Safari/537.36"</span>,</span><br><span class="line">          <span class="attr">"Accept"</span>: <span class="string">"text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8"</span>,</span><br><span class="line">          <span class="attr">"Connection"</span>: <span class="string">"keep-alive"</span>,</span><br><span class="line">          <span class="attr">"Host"</span>: <span class="string">"localhost:8080"</span></span><br><span class="line">      &#125;,</span><br><span class="line">      <span class="attr">"response"</span>: &#123;</span><br><span class="line">        <span class="attr">"Content - Type"</span>: <span class="string">"application/json; charset=UTF-8"</span>,</span><br><span class="line">          <span class="attr">"X - Application - Context"</span>: <span class="string">"application:8080"</span>,</span><br><span class="line">          <span class="attr">"Date"</span>: <span class="string">"Sat, 16 Jan 2016 13:38:09 GMT"</span>,</span><br><span class="line">          <span class="attr">"status"</span>: <span class="string">"200"</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;]</span><br></pre></td></tr></table></figure>
<h2 id="安全设置"><a href="#安全设置" class="headerlink" title="安全设置"></a>安全设置</h2><p>actuator暴露的health接口权限是由两个配置： <code>management.security.enabled</code> 和 <code>endpoints.health.sensitive</code>组合的结果进行返回的。</p>
<table>
<thead>
<tr>
<th>management.security.enabled</th>
<th>endpoints.health.sensitive</th>
<th>Unauthenticated</th>
<th>Authenticated (with right role)</th>
</tr>
</thead>
<tbody><tr>
<td>false</td>
<td>*</td>
<td>Full content</td>
<td>Full content</td>
</tr>
<tr>
<td>true</td>
<td><strong>false</strong></td>
<td>Status only</td>
<td>Full content</td>
</tr>
<tr>
<td>true</td>
<td>true</td>
<td>No content</td>
<td>Full content</td>
</tr>
</tbody></table>
<h2 id="常用配置"><a href="#常用配置" class="headerlink" title="常用配置"></a>常用配置</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">management.security.enabled: false  # 是否启用安全认证</span><br><span class="line">management.context-path: &#x2F;actuator  # actuator url base路径</span><br></pre></td></tr></table></figure>

<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p><a href="https://docs.spring.io/spring-boot/docs/current/reference/html/production-ready-endpoints.html" target="_blank" rel="noopener">官方文档</a></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://longzl2015.github.io/2018/06/04/spark/Spark%E6%89%A7%E8%A1%8C%E9%80%BB%E8%BE%91/SparkContext%E5%88%9D%E5%A7%8B%E5%8C%96%E8%BF%87%E7%A8%8B/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="zhoul">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2018/06/04/spark/Spark%E6%89%A7%E8%A1%8C%E9%80%BB%E8%BE%91/SparkContext%E5%88%9D%E5%A7%8B%E5%8C%96%E8%BF%87%E7%A8%8B/" class="post-title-link" itemprop="url">SparkContext初始化过程</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2018-06-04 23:22:10" itemprop="dateCreated datePublished" datetime="2018-06-04T23:22:10+08:00">2018-06-04</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-02-27 17:16:07" itemprop="dateModified" datetime="2020-02-27T17:16:07+08:00">2020-02-27</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/spark/" itemprop="url" rel="index">
                    <span itemprop="name">spark</span>
                  </a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/spark/%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/" itemprop="url" rel="index">
                    <span itemprop="name">源码解析</span>
                  </a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="fa fa-comment-o"></i>
      </span>
      <span class="post-meta-item-text">Disqus：</span>
    
    <a title="disqus" href="/2018/06/04/spark/Spark%E6%89%A7%E8%A1%8C%E9%80%BB%E8%BE%91/SparkContext%E5%88%9D%E5%A7%8B%E5%8C%96%E8%BF%87%E7%A8%8B/#comments" itemprop="discussionUrl">
      <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2018/06/04/spark/Spark执行逻辑/SparkContext初始化过程/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="SparkContext初始化过程"><a href="#SparkContext初始化过程" class="headerlink" title="SparkContext初始化过程"></a>SparkContext初始化过程</h1><p>SparkContext是程序执行的入口，一个SparkContext代表一个应用，深入理解spark运行时机制，首先要了解SparkContext初始化过程。</p>
<h3 id="一、SparkContext的定义"><a href="#一、SparkContext的定义" class="headerlink" title="一、SparkContext的定义"></a>一、SparkContext的定义</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//Spark程序的入口</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SparkContext</span>(<span class="params">config: <span class="type">SparkConf</span></span>) <span class="keyword">extends</span> <span class="title">Logging</span> </span>&#123;</span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">val</span> creationSite: <span class="type">CallSite</span> = <span class="type">Utils</span>.getCallSite()</span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">val</span> allowMultipleContexts: <span class="type">Boolean</span> =</span><br><span class="line">    config.getBoolean(<span class="string">"spark.driver.allowMultipleContexts"</span>, <span class="literal">false</span>)</span><br></pre></td></tr></table></figure>

<p>构造参数为SparkConf，SparkConf内部用ConcurrentHashMap存储各种配置信息，初始化时会加载所有以<strong>spark.</strong>开头的环境变量。 </p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Spark程序的配置信息</span></span><br><span class="line"><span class="comment">// 加载所有以Spark开头的环境变量</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SparkConf</span>(<span class="params">loadDefaults: <span class="type">Boolean</span></span>) <span class="keyword">extends</span> <span class="title">Cloneable</span> <span class="keyword">with</span> <span class="title">Logging</span> <span class="keyword">with</span> <span class="title">Serializable</span> </span>&#123;</span><br><span class="line">  <span class="keyword">import</span> <span class="type">SparkConf</span>._</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">this</span></span>() = <span class="keyword">this</span>(<span class="literal">true</span>)</span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">val</span> settings = <span class="keyword">new</span> <span class="type">ConcurrentHashMap</span>[<span class="type">String</span>, <span class="type">String</span>]()</span><br><span class="line"></span><br><span class="line">  <span class="meta">@transient</span> <span class="keyword">private</span> <span class="keyword">lazy</span> <span class="keyword">val</span> reader: <span class="type">ConfigReader</span> = &#123;</span><br><span class="line">    <span class="keyword">val</span> _reader = <span class="keyword">new</span> <span class="type">ConfigReader</span>(<span class="keyword">new</span> <span class="type">SparkConfigProvider</span>(settings))</span><br><span class="line">    _reader.bindEnv(<span class="keyword">new</span> <span class="type">ConfigProvider</span> &#123;</span><br><span class="line">      <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">get</span></span>(key: <span class="type">String</span>): <span class="type">Option</span>[<span class="type">String</span>] = <span class="type">Option</span>(getenv(key))</span><br><span class="line">    &#125;)</span><br><span class="line">    _reader</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (loadDefaults) &#123;</span><br><span class="line">    loadFromSystemProperties(<span class="literal">false</span>)</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>



<h3 id="二、SparkContext初始化"><a href="#二、SparkContext初始化" class="headerlink" title="二、SparkContext初始化"></a>二、SparkContext初始化</h3><p>查看初始化对应代码 (位于374行)</p>
<p>克隆和校验SparkConf的变量，接着判断spark.master和spark.app.name是否存在，如果是YARN cluster模式则必须设置spark.yarn.app.id，然后是driver的host，port信息，最后是jars和files，</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line">    _conf = config.clone()</span><br><span class="line">    _conf.validateSettings()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (!_conf.contains(<span class="string">"spark.master"</span>)) &#123;</span><br><span class="line">      <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">SparkException</span>(<span class="string">"A master URL must be set in your configuration"</span>)</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (!_conf.contains(<span class="string">"spark.app.name"</span>)) &#123;</span><br><span class="line">      <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">SparkException</span>(<span class="string">"An application name must be set in your configuration"</span>)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// System property spark.yarn.app.id must be set if user code ran by AM on a YARN cluster</span></span><br><span class="line">    <span class="keyword">if</span> (master == <span class="string">"yarn"</span> &amp;&amp; deployMode == <span class="string">"cluster"</span> &amp;&amp; !_conf.contains(<span class="string">"spark.yarn.app.id"</span>)) &#123;</span><br><span class="line">      <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">SparkException</span>(<span class="string">"Detected yarn cluster mode, but isn't running on a cluster. "</span> +</span><br><span class="line">        <span class="string">"Deployment to YARN is not supported directly by SparkContext. Please use spark-submit."</span>)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (_conf.getBoolean(<span class="string">"spark.logConf"</span>, <span class="literal">false</span>)) &#123;</span><br><span class="line">      logInfo(<span class="string">"Spark configuration:\n"</span> + _conf.toDebugString)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Set Spark driver host and port system properties. This explicitly sets the configuration</span></span><br><span class="line">    <span class="comment">// instead of relying on the default value of the config constant.</span></span><br><span class="line">    _conf.set(<span class="type">DRIVER_HOST_ADDRESS</span>, _conf.get(<span class="type">DRIVER_HOST_ADDRESS</span>))</span><br><span class="line">    _conf.setIfMissing(<span class="string">"spark.driver.port"</span>, <span class="string">"0"</span>)</span><br><span class="line"></span><br><span class="line">    _conf.set(<span class="string">"spark.executor.id"</span>, <span class="type">SparkContext</span>.<span class="type">DRIVER_IDENTIFIER</span>)</span><br><span class="line"></span><br><span class="line">    _jars = <span class="type">Utils</span>.getUserJars(_conf)</span><br><span class="line">    _files = _conf.getOption(<span class="string">"spark.files"</span>).map(_.split(<span class="string">","</span>)).map(_.filter(_.nonEmpty))</span><br><span class="line">      .toSeq.flatten</span><br></pre></td></tr></table></figure>

<p>_eventLogDir 是否记录运行时信息，由<strong>spark.eventLog.enabled</strong>和<strong>spark.eventLog.dir</strong>控制</p>
<p>_eventLogCodec 是否压缩该信息</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">_eventLogDir =</span><br><span class="line">  <span class="keyword">if</span> (isEventLogEnabled) &#123;</span><br><span class="line">    <span class="keyword">val</span> unresolvedDir = conf.get(<span class="string">"spark.eventLog.dir"</span>, <span class="type">EventLoggingListener</span>.<span class="type">DEFAULT_LOG_DIR</span>)</span><br><span class="line">      .stripSuffix(<span class="string">"/"</span>)</span><br><span class="line">    <span class="type">Some</span>(<span class="type">Utils</span>.resolveURI(unresolvedDir))</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="type">None</span></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">_eventLogCodec = &#123;</span><br><span class="line">  <span class="keyword">val</span> compress = _conf.getBoolean(<span class="string">"spark.eventLog.compress"</span>, <span class="literal">false</span>)</span><br><span class="line">  <span class="keyword">if</span> (compress &amp;&amp; isEventLogEnabled) &#123;</span><br><span class="line">    <span class="type">Some</span>(<span class="type">CompressionCodec</span>.getCodecName(_conf)).map(<span class="type">CompressionCodec</span>.getShortName)</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="type">None</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>如果为yarn-client模式，设置SPARK_YARN_MODE=true</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (master == <span class="string">"yarn"</span> &amp;&amp; deployMode == <span class="string">"client"</span>) <span class="type">System</span>.setProperty(<span class="string">"SPARK_YARN_MODE"</span>, <span class="string">"true"</span>)</span><br></pre></td></tr></table></figure>

<p>使用JobProgressListener跟踪运行时信息，用于UI展示，最后创建<strong>SparkEnv</strong>对象，创建SparkEnv的过程涉及到非常多spark-core中的核心类。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">_jobProgressListener = <span class="keyword">new</span> <span class="type">JobProgressListener</span>(_conf)</span><br><span class="line">listenerBus.addListener(jobProgressListener)</span><br><span class="line"></span><br><span class="line"><span class="comment">// Create the Spark execution environment (cache, map output tracker, etc)</span></span><br><span class="line">_env = createSparkEnv(_conf, isLocal, listenerBus)</span><br><span class="line"><span class="type">SparkEnv</span>.set(_env)</span><br><span class="line"></span><br><span class="line"><span class="comment">// If running the REPL, register the repl's output dir with the file server.</span></span><br><span class="line">_conf.getOption(<span class="string">"spark.repl.class.outputDir"</span>).foreach &#123; path =&gt;</span><br><span class="line">  <span class="keyword">val</span> replUri = _env.rpcEnv.fileServer.addDirectory(<span class="string">"/classes"</span>, <span class="keyword">new</span> <span class="type">File</span>(path))</span><br><span class="line">  _conf.set(<span class="string">"spark.repl.class.uri"</span>, replUri)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>有关UI的信息展示</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">_statusTracker = <span class="keyword">new</span> <span class="type">SparkStatusTracker</span>(<span class="keyword">this</span>)</span><br><span class="line"></span><br><span class="line">_progressBar =</span><br><span class="line">  <span class="keyword">if</span> (_conf.getBoolean(<span class="string">"spark.ui.showConsoleProgress"</span>, <span class="literal">true</span>) &amp;&amp; !log.isInfoEnabled) &#123;</span><br><span class="line">    <span class="type">Some</span>(<span class="keyword">new</span> <span class="type">ConsoleProgressBar</span>(<span class="keyword">this</span>))</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="type">None</span></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">_ui =</span><br><span class="line">  <span class="keyword">if</span> (conf.getBoolean(<span class="string">"spark.ui.enabled"</span>, <span class="literal">true</span>)) &#123;</span><br><span class="line">    <span class="type">Some</span>(<span class="type">SparkUI</span>.createLiveUI(<span class="keyword">this</span>, _conf, listenerBus, _jobProgressListener,</span><br><span class="line">      _env.securityManager, appName, startTime = startTime))</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="comment">// For tests, do not enable the UI</span></span><br><span class="line">    <span class="type">None</span></span><br><span class="line">  &#125;</span><br><span class="line"><span class="comment">// Bind the UI before starting the task scheduler to communicate</span></span><br><span class="line"><span class="comment">// the bound port to the cluster manager properly</span></span><br><span class="line">_ui.foreach(_.bind())</span><br></pre></td></tr></table></figure>

<p>读取hadoop配置，将jar和file的路径添加到rpcEnv的fileServer，读取Executor相关变量，重要的参数为ExecutorMemory </p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">_hadoopConfiguration = <span class="type">SparkHadoopUtil</span>.get.newConfiguration(_conf)</span><br><span class="line"></span><br><span class="line"><span class="comment">// Add each JAR given through the constructor</span></span><br><span class="line"><span class="keyword">if</span> (jars != <span class="literal">null</span>) &#123;</span><br><span class="line">  jars.foreach(addJar)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (files != <span class="literal">null</span>) &#123;</span><br><span class="line">  files.foreach(addFile)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">_executorMemory = _conf.getOption(<span class="string">"spark.executor.memory"</span>)</span><br><span class="line">  .orElse(<span class="type">Option</span>(<span class="type">System</span>.getenv(<span class="string">"SPARK_EXECUTOR_MEMORY"</span>)))</span><br><span class="line">  .orElse(<span class="type">Option</span>(<span class="type">System</span>.getenv(<span class="string">"SPARK_MEM"</span>))</span><br><span class="line">  .map(warnSparkMem))</span><br><span class="line">  .map(<span class="type">Utils</span>.memoryStringToMb)</span><br><span class="line">  .getOrElse(<span class="number">1024</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// Convert java options to env vars as a work around</span></span><br><span class="line"><span class="comment">// since we can't set env vars directly in sbt.</span></span><br><span class="line"><span class="keyword">for</span> &#123; (envKey, propKey) &lt;- <span class="type">Seq</span>((<span class="string">"SPARK_TESTING"</span>, <span class="string">"spark.testing"</span>))</span><br><span class="line">  value &lt;- <span class="type">Option</span>(<span class="type">System</span>.getenv(envKey)).orElse(<span class="type">Option</span>(<span class="type">System</span>.getProperty(propKey)))&#125; &#123;</span><br><span class="line">  executorEnvs(envKey) = value</span><br><span class="line">&#125;</span><br><span class="line"><span class="type">Option</span>(<span class="type">System</span>.getenv(<span class="string">"SPARK_PREPEND_CLASSES"</span>)).foreach &#123; v =&gt;</span><br><span class="line">  executorEnvs(<span class="string">"SPARK_PREPEND_CLASSES"</span>) = v</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// The Mesos scheduler backend relies on this environment variable to set executor memory.</span></span><br><span class="line"><span class="comment">// <span class="doctag">TODO:</span> Set this only in the Mesos scheduler.</span></span><br><span class="line">executorEnvs(<span class="string">"SPARK_EXECUTOR_MEMORY"</span>) = executorMemory + <span class="string">"m"</span></span><br><span class="line">executorEnvs ++= _conf.getExecutorEnv</span><br><span class="line">executorEnvs(<span class="string">"SPARK_USER"</span>) = sparkUser</span><br></pre></td></tr></table></figure>

<p>_heartbeatReceiver是默认基于netty实现的心跳机制，创建schedulerBackend用于提交任务，创建taskScheduler和dagScheduler，获取applicationId，启动度量系统，获取eventLogger </p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line">_heartbeatReceiver = env.rpcEnv.setupEndpoint(</span><br><span class="line">  <span class="type">HeartbeatReceiver</span>.<span class="type">ENDPOINT_NAME</span>, <span class="keyword">new</span> <span class="type">HeartbeatReceiver</span>(<span class="keyword">this</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment">// Create and start the scheduler</span></span><br><span class="line"><span class="keyword">val</span> (sched, ts) = <span class="type">SparkContext</span>.createTaskScheduler(<span class="keyword">this</span>, master, deployMode)</span><br><span class="line">_schedulerBackend = sched</span><br><span class="line">_taskScheduler = ts</span><br><span class="line">_dagScheduler = <span class="keyword">new</span> <span class="type">DAGScheduler</span>(<span class="keyword">this</span>)</span><br><span class="line">_heartbeatReceiver.ask[<span class="type">Boolean</span>](<span class="type">TaskSchedulerIsSet</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// start TaskScheduler after taskScheduler sets DAGScheduler reference in DAGScheduler's</span></span><br><span class="line"><span class="comment">// constructor</span></span><br><span class="line">_taskScheduler.start()</span><br><span class="line"></span><br><span class="line">_applicationId = _taskScheduler.applicationId()</span><br><span class="line">_applicationAttemptId = taskScheduler.applicationAttemptId()</span><br><span class="line">_conf.set(<span class="string">"spark.app.id"</span>, _applicationId)</span><br><span class="line"><span class="keyword">if</span> (_conf.getBoolean(<span class="string">"spark.ui.reverseProxy"</span>, <span class="literal">false</span>)) &#123;</span><br><span class="line">  <span class="type">System</span>.setProperty(<span class="string">"spark.ui.proxyBase"</span>, <span class="string">"/proxy/"</span> + _applicationId)</span><br><span class="line">&#125;</span><br><span class="line">_ui.foreach(_.setAppId(_applicationId))</span><br><span class="line">_env.blockManager.initialize(_applicationId)</span><br><span class="line"></span><br><span class="line"><span class="comment">// The metrics system for Driver need to be set spark.app.id to app ID.</span></span><br><span class="line"><span class="comment">// So it should start after we get app ID from the task scheduler and set spark.app.id.</span></span><br><span class="line">_env.metricsSystem.start()</span><br><span class="line"><span class="comment">// Attach the driver metrics servlet handler to the web ui after the metrics system is started.</span></span><br><span class="line">_env.metricsSystem.getServletHandlers.foreach(handler =&gt; ui.foreach(_.attachHandler(handler)))</span><br><span class="line"></span><br><span class="line">_eventLogger =</span><br><span class="line">  <span class="keyword">if</span> (isEventLogEnabled) &#123;</span><br><span class="line">    <span class="keyword">val</span> logger =</span><br><span class="line">      <span class="keyword">new</span> <span class="type">EventLoggingListener</span>(_applicationId, _applicationAttemptId, _eventLogDir.get,</span><br><span class="line">        _conf, _hadoopConfiguration)</span><br><span class="line">    logger.start()</span><br><span class="line">    listenerBus.addListener(logger)</span><br><span class="line">    <span class="type">Some</span>(logger)</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="type">None</span></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Optionally scale number of executors dynamically based on workload. Exposed for testing.</span></span><br><span class="line"><span class="keyword">val</span> dynamicAllocationEnabled = <span class="type">Utils</span>.isDynamicAllocationEnabled(_conf)</span><br></pre></td></tr></table></figure>

<p>executorAllocationManager关于Executor动态资源分配，通过spark.dynamicAllocation.enabled设置，创建contextcleaner用于清理过期的RDD, shuffle和broadcast ，启动ListenerBus，并post环境信息和应用信息，最后添加确保context停止的hook，至此整个sparkcontext的初始化流程结束。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line">  _executorAllocationManager =</span><br><span class="line">    <span class="keyword">if</span> (dynamicAllocationEnabled) &#123;</span><br><span class="line">      schedulerBackend <span class="keyword">match</span> &#123;</span><br><span class="line">        <span class="keyword">case</span> b: <span class="type">ExecutorAllocationClient</span> =&gt;</span><br><span class="line">          <span class="type">Some</span>(<span class="keyword">new</span> <span class="type">ExecutorAllocationManager</span>(</span><br><span class="line">            schedulerBackend.asInstanceOf[<span class="type">ExecutorAllocationClient</span>], listenerBus, _conf))</span><br><span class="line">        <span class="keyword">case</span> _ =&gt;</span><br><span class="line">          <span class="type">None</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="type">None</span></span><br><span class="line">    &#125;</span><br><span class="line">  _executorAllocationManager.foreach(_.start())</span><br><span class="line"></span><br><span class="line">  _cleaner =</span><br><span class="line">    <span class="keyword">if</span> (_conf.getBoolean(<span class="string">"spark.cleaner.referenceTracking"</span>, <span class="literal">true</span>)) &#123;</span><br><span class="line">      <span class="type">Some</span>(<span class="keyword">new</span> <span class="type">ContextCleaner</span>(<span class="keyword">this</span>))</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="type">None</span></span><br><span class="line">    &#125;</span><br><span class="line">  _cleaner.foreach(_.start())</span><br><span class="line"></span><br><span class="line">  setupAndStartListenerBus()</span><br><span class="line">  postEnvironmentUpdate()</span><br><span class="line">  postApplicationStart()</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Post init</span></span><br><span class="line">  _taskScheduler.postStartHook()</span><br><span class="line">  _env.metricsSystem.registerSource(_dagScheduler.metricsSource)</span><br><span class="line">  _env.metricsSystem.registerSource(<span class="keyword">new</span> <span class="type">BlockManagerSource</span>(_env.blockManager))</span><br><span class="line">  _executorAllocationManager.foreach &#123; e =&gt;</span><br><span class="line">    _env.metricsSystem.registerSource(e.executorAllocationManagerSource)</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Make sure the context is stopped if the user forgets about it. This avoids leaving</span></span><br><span class="line">  <span class="comment">// unfinished event logs around after the JVM exits cleanly. It doesn't help if the JVM</span></span><br><span class="line">  <span class="comment">// is killed, though.</span></span><br><span class="line">  logDebug(<span class="string">"Adding shutdown hook"</span>) <span class="comment">// force eager creation of logger</span></span><br><span class="line">  _shutdownHookRef = <span class="type">ShutdownHookManager</span>.addShutdownHook(</span><br><span class="line">    <span class="type">ShutdownHookManager</span>.<span class="type">SPARK_CONTEXT_SHUTDOWN_PRIORITY</span>) &#123; () =&gt;</span><br><span class="line">    logInfo(<span class="string">"Invoking stop() from shutdown hook"</span>)</span><br><span class="line">    stop()</span><br><span class="line">  &#125;</span><br><span class="line">&#125; <span class="keyword">catch</span> &#123;</span><br><span class="line">  <span class="keyword">case</span> <span class="type">NonFatal</span>(e) =&gt;</span><br><span class="line">    logError(<span class="string">"Error initializing SparkContext."</span>, e)</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      stop()</span><br><span class="line">    &#125; <span class="keyword">catch</span> &#123;</span><br><span class="line">      <span class="keyword">case</span> <span class="type">NonFatal</span>(inner) =&gt;</span><br><span class="line">        logError(<span class="string">"Error stopping SparkContext after init error."</span>, inner)</span><br><span class="line">    &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">      <span class="keyword">throw</span> e</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="三、总结"><a href="#三、总结" class="headerlink" title="三、总结"></a>三、总结</h3><p>通过对sparkcontext初始化过程的跟踪，主要涉及到的内容如下</p>
<ol>
<li>SparkConf读取配置和校验，log和UI相关的度量系统。</li>
<li>创建SparkEnv，涉及到众多重要对象，如rpcEnv, actorSystem, serializer, closureSerializer, cacheManager, mapOutputTracker, shuffleManager, broadcastManager, blockTransferService, blockManager, securityManager, sparkFilesDir, metricsSystem, memoryManager等。</li>
<li>心跳机制，taskScheduler和dagScheduler的创建。</li>
</ol>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://longzl2015.github.io/2018/06/04/spark/Spark%E6%89%A7%E8%A1%8C%E9%80%BB%E8%BE%91/spark%E6%8F%90%E4%BA%A4%E4%BB%BB%E5%8A%A1%E5%90%8E%20linux%E4%B8%AD%E7%9A%84%E7%BA%BF%E7%A8%8B%E8%AF%B4%E6%98%8E/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="zhoul">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2018/06/04/spark/Spark%E6%89%A7%E8%A1%8C%E9%80%BB%E8%BE%91/spark%E6%8F%90%E4%BA%A4%E4%BB%BB%E5%8A%A1%E5%90%8E%20linux%E4%B8%AD%E7%9A%84%E7%BA%BF%E7%A8%8B%E8%AF%B4%E6%98%8E/" class="post-title-link" itemprop="url">spark 提交任务后，Linux中java 进程说明</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2018-06-04 23:22:09" itemprop="dateCreated datePublished" datetime="2018-06-04T23:22:09+08:00">2018-06-04</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-02-27 17:16:07" itemprop="dateModified" datetime="2020-02-27T17:16:07+08:00">2020-02-27</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/spark/" itemprop="url" rel="index">
                    <span itemprop="name">spark</span>
                  </a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/spark/%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/" itemprop="url" rel="index">
                    <span itemprop="name">源码解析</span>
                  </a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="fa fa-comment-o"></i>
      </span>
      <span class="post-meta-item-text">Disqus：</span>
    
    <a title="disqus" href="/2018/06/04/spark/Spark%E6%89%A7%E8%A1%8C%E9%80%BB%E8%BE%91/spark%E6%8F%90%E4%BA%A4%E4%BB%BB%E5%8A%A1%E5%90%8E%20linux%E4%B8%AD%E7%9A%84%E7%BA%BF%E7%A8%8B%E8%AF%B4%E6%98%8E/#comments" itemprop="discussionUrl">
      <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2018/06/04/spark/Spark执行逻辑/spark提交任务后 linux中的线程说明/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="spark-提交任务后，Linux中java-进程说明"><a href="#spark-提交任务后，Linux中java-进程说明" class="headerlink" title="spark 提交任务后，Linux中java 进程说明"></a>spark 提交任务后，Linux中java 进程说明</h1><p>[TOC]</p>
<h2 id="一、简述"><a href="#一、简述" class="headerlink" title="一、简述"></a>一、简述</h2><p>当使用 spark 提交任务后，可在hadoop集群中的一台Linux里 使用 <code>ps -ef | grep jdk1.8</code> 可查看到对应的任务进程信息。</p>
<p>注、本例中使用的是单机模式</p>
<h2 id="二、进程分析"><a href="#二、进程分析" class="headerlink" title="二、进程分析"></a>二、进程分析</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">hadoop   110334 110332  0 13:40 ?        00:00:00 &#x2F;bin&#x2F;bash -c .&#x2F;jdk-8u161-linux-x64.tar.gz&#x2F;jdk1.8.0_161&#x2F;bin&#x2F;java -server -Xmx1024m -Djava.io.tmpdir&#x3D;&#x2F;home&#x2F;hadoop&#x2F;tmp&#x2F;nm-local-dir&#x2F;usercache&#x2F;xxxxx&#x2F;appcache&#x2F;application_1519271509270_0745&#x2F;container_1519271509270_0745_01_000001&#x2F;tmp &#39;-XX:MaxPermSize&#x3D;2048m&#39; &#39;-XX:PermSize&#x3D;512m&#39; -Dspark.yarn.app.container.log.dir&#x3D;&#x2F;home&#x2F;hadoop&#x2F;hadoop-2.7.3&#x2F;logs&#x2F;userlogs&#x2F;application_1519271509270_0745&#x2F;container_1519271509270_0745_01_000001 org.apache.spark.deploy.yarn.ApplicationMaster --class &#39;org.apache.spark.ml.alogrithm.SmartRules&#39; --jar hdfs:&#x2F;&#x2F;slave131:9000&#x2F;user&#x2F;mls_zl&#x2F;lib2&#x2F;cmpt&#x2F;xxxxx-workflow-component-0.3.2-20180320-1101.jar --arg &#39;hdfs:&#x2F;&#x2F;slave131:9000&#x2F;user&#x2F;mls_3.5&#x2F;proc&#x2F;1&#x2F;11&#x2F;92&#x2F;submit_SmartRules_37Client.json&#39; --properties-file &#x2F;home&#x2F;hadoop&#x2F;tmp&#x2F;nm-local-dir&#x2F;usercache&#x2F;xxxxx&#x2F;appcache&#x2F;application_1519271509270_0745&#x2F;container_1519271509270_0745_01_000001&#x2F;__spark_conf__&#x2F;__spark_conf__.properties 1&gt; &#x2F;home&#x2F;hadoop&#x2F;hadoop-2.7.3&#x2F;logs&#x2F;userlogs&#x2F;application_1519271509270_0745&#x2F;container_1519271509270_0745_01_000001&#x2F;stdout 2&gt; &#x2F;home&#x2F;hadoop&#x2F;hadoop-2.7.3&#x2F;logs&#x2F;userlogs&#x2F;application_1519271509270_0745&#x2F;container_1519271509270_0745_01_000001&#x2F;stderr</span><br><span class="line">hadoop   110891 110334 99 13:40 ?        00:00:34 .&#x2F;jdk-8u161-linux-x64.tar.gz&#x2F;jdk1.8.0_161&#x2F;bin&#x2F;java -server -Xmx1024m -Djava.io.tmpdir&#x3D;&#x2F;home&#x2F;hadoop&#x2F;tmp&#x2F;nm-local-dir&#x2F;usercache&#x2F;xxxxx&#x2F;appcache&#x2F;application_1519271509270_0745&#x2F;container_1519271509270_0745_01_000001&#x2F;tmp -XX:MaxPermSize&#x3D;2048m -XX:PermSize&#x3D;512m -Dspark.yarn.app.container.log.dir&#x3D;&#x2F;home&#x2F;hadoop&#x2F;hadoop-2.7.3&#x2F;logs&#x2F;userlogs&#x2F;application_1519271509270_0745&#x2F;container_1519271509270_0745_01_000001 org.apache.spark.deploy.yarn.ApplicationMaster --class org.apache.spark.ml.alogrithm.SmartRules --jar hdfs:&#x2F;&#x2F;slave131:9000&#x2F;user&#x2F;mls_zl&#x2F;lib2&#x2F;cmpt&#x2F;xxxxx-workflow-component-0.3.2-20180320-1101.jar --arg hdfs:&#x2F;&#x2F;slave131:9000&#x2F;user&#x2F;mls_3.5&#x2F;proc&#x2F;1&#x2F;11&#x2F;92&#x2F;submit_SmartRules_37Client.json --properties-file &#x2F;home&#x2F;hadoop&#x2F;tmp&#x2F;nm-local-dir&#x2F;usercache&#x2F;xxxxx&#x2F;appcache&#x2F;application_1519271509270_0745&#x2F;container_1519271509270_0745_01_000001&#x2F;__spark_conf__&#x2F;__spark_conf__.properties</span><br><span class="line">hadoop   111013 111010  0 13:40 ?        00:00:00 &#x2F;bin&#x2F;bash -c .&#x2F;jdk-8u161-linux-x64.tar.gz&#x2F;jdk1.8.0_161&#x2F;bin&#x2F;java -server -Xmx4096m -Djava.io.tmpdir&#x3D;&#x2F;home&#x2F;hadoop&#x2F;tmp&#x2F;nm-local-dir&#x2F;usercache&#x2F;xxxxx&#x2F;appcache&#x2F;application_1519271509270_0745&#x2F;container_1519271509270_0745_01_000002&#x2F;tmp &#39;-Dspark.ui.port&#x3D;0&#39; &#39;-Dspark.driver.port&#x3D;37011&#39; -Dspark.yarn.app.container.log.dir&#x3D;&#x2F;home&#x2F;hadoop&#x2F;hadoop-2.7.3&#x2F;logs&#x2F;userlogs&#x2F;application_1519271509270_0745&#x2F;container_1519271509270_0745_01_000002 -XX:OnOutOfMemoryError&#x3D;&#39;kill %p&#39; org.apache.spark.executor.CoarseGrainedExecutorBackend --driver-url spark:&#x2F;&#x2F;CoarseGrainedScheduler@10.100.1.131:37011 --executor-id 1 --hostname slave131 --cores 8 --app-id application_1519271509270_0745 --user-class-path file:&#x2F;home&#x2F;hadoop&#x2F;tmp&#x2F;nm-local-dir&#x2F;usercache&#x2F;xxxxx&#x2F;appcache&#x2F;application_1519271509270_0745&#x2F;container_1519271509270_0745_01_000002&#x2F;__app__.jar 1&gt;&#x2F;home&#x2F;hadoop&#x2F;hadoop-2.7.3&#x2F;logs&#x2F;userlogs&#x2F;application_1519271509270_0745&#x2F;container_1519271509270_0745_01_000002&#x2F;stdout 2&gt;&#x2F;home&#x2F;hadoop&#x2F;hadoop-2.7.3&#x2F;logs&#x2F;userlogs&#x2F;application_1519271509270_0745&#x2F;container_1519271509270_0745_01_000002&#x2F;stderr</span><br><span class="line">hadoop   111567 111013 99 13:40 ?        00:00:32 .&#x2F;jdk-8u161-linux-x64.tar.gz&#x2F;jdk1.8.0_161&#x2F;bin&#x2F;java -server -Xmx4096m -Djava.io.tmpdir&#x3D;&#x2F;home&#x2F;hadoop&#x2F;tmp&#x2F;nm-local-dir&#x2F;usercache&#x2F;xxxxx&#x2F;appcache&#x2F;application_1519271509270_0745&#x2F;container_1519271509270_0745_01_000002&#x2F;tmp -Dspark.ui.port&#x3D;0 -Dspark.driver.port&#x3D;37011 -Dspark.yarn.app.container.log.dir&#x3D;&#x2F;home&#x2F;hadoop&#x2F;hadoop-2.7.3&#x2F;logs&#x2F;userlogs&#x2F;application_1519271509270_0745&#x2F;container_1519271509270_0745_01_000002 -XX:OnOutOfMemoryError&#x3D;kill %p org.apache.spark.executor.CoarseGrainedExecutorBackend --driver-url spark:&#x2F;&#x2F;CoarseGrainedScheduler@10.100.1.131:37011 --executor-id 1 --hostname slave131 --cores 8 --app-id application_1519271509270_0745 --user-class-path file:&#x2F;home&#x2F;hadoop&#x2F;tmp&#x2F;nm-local-dir&#x2F;usercache&#x2F;xxxxx&#x2F;appcache&#x2F;application_1519271509270_0745&#x2F;container_1519271509270_0745_01_000002&#x2F;__app__.jar</span><br><span class="line">hadoop   111619 111616  0 13:40 ?        00:00:00 &#x2F;bin&#x2F;bash -c .&#x2F;jdk-8u161-linux-x64.tar.gz&#x2F;jdk1.8.0_161&#x2F;bin&#x2F;java -server -Xmx4096m -Djava.io.tmpdir&#x3D;&#x2F;home&#x2F;hadoop&#x2F;tmp&#x2F;nm-local-dir&#x2F;usercache&#x2F;xxxxx&#x2F;appcache&#x2F;application_1519271509270_0745&#x2F;container_1519271509270_0745_01_000003&#x2F;tmp &#39;-Dspark.ui.port&#x3D;0&#39; &#39;-Dspark.driver.port&#x3D;37011&#39; -Dspark.yarn.app.container.log.dir&#x3D;&#x2F;home&#x2F;hadoop&#x2F;hadoop-2.7.3&#x2F;logs&#x2F;userlogs&#x2F;application_1519271509270_0745&#x2F;container_1519271509270_0745_01_000003 -XX:OnOutOfMemoryError&#x3D;&#39;kill %p&#39; org.apache.spark.executor.CoarseGrainedExecutorBackend --driver-url spark:&#x2F;&#x2F;CoarseGrainedScheduler@10.100.1.131:37011 --executor-id 2 --hostname slave131 --cores 8 --app-id application_1519271509270_0745 --user-class-path file:&#x2F;home&#x2F;hadoop&#x2F;tmp&#x2F;nm-local-dir&#x2F;usercache&#x2F;xxxxx&#x2F;appcache&#x2F;application_1519271509270_0745&#x2F;container_1519271509270_0745_01_000003&#x2F;__app__.jar 1&gt;&#x2F;home&#x2F;hadoop&#x2F;hadoop-2.7.3&#x2F;logs&#x2F;userlogs&#x2F;application_1519271509270_0745&#x2F;container_1519271509270_0745_01_000003&#x2F;stdout 2&gt;&#x2F;home&#x2F;hadoop&#x2F;hadoop-2.7.3&#x2F;logs&#x2F;userlogs&#x2F;application_1519271509270_0745&#x2F;container_1519271509270_0745_01_000003&#x2F;stderr</span><br><span class="line">hadoop   112178 111619 99 13:40 ?        00:00:50 .&#x2F;jdk-8u161-linux-x64.tar.gz&#x2F;jdk1.8.0_161&#x2F;bin&#x2F;java -server -Xmx4096m -Djava.io.tmpdir&#x3D;&#x2F;home&#x2F;hadoop&#x2F;tmp&#x2F;nm-local-dir&#x2F;usercache&#x2F;xxxxx&#x2F;appcache&#x2F;application_1519271509270_0745&#x2F;container_1519271509270_0745_01_000003&#x2F;tmp -Dspark.ui.port&#x3D;0 -Dspark.driver.port&#x3D;37011 -Dspark.yarn.app.container.log.dir&#x3D;&#x2F;home&#x2F;hadoop&#x2F;hadoop-2.7.3&#x2F;logs&#x2F;userlogs&#x2F;application_1519271509270_0745&#x2F;container_1519271509270_0745_01_000003 -XX:OnOutOfMemoryError&#x3D;kill %p org.apache.spark.executor.CoarseGrainedExecutorBackend --driver-url spark:&#x2F;&#x2F;CoarseGrainedScheduler@10.100.1.131:37011 --executor-id 2 --hostname slave131 --cores 8 --app-id application_1519271509270_0745 --user-class-path file:&#x2F;home&#x2F;hadoop&#x2F;tmp&#x2F;nm-local-dir&#x2F;usercache&#x2F;xxxxx&#x2F;appcache&#x2F;application_1519271509270_0745&#x2F;container_1519271509270_0745_01_000003&#x2F;__app__.jar</span><br></pre></td></tr></table></figure>



<p>下面逐条解释上面java进程： </p>
<h3 id="2-1-进程一"><a href="#2-1-进程一" class="headerlink" title="2.1 进程一"></a>2.1 进程一</h3><p>进程一表示使用bash -c 启动进程二，并将进程二的信息重定向到指定位置。这里直接说重定向命令参数，其他参数见进程二说明</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop   110334 110332  0 13:40 ?        00:00:00 &#x2F;bin&#x2F;bash -c .&#x2F;jdk-8u161-linux-x64.tar.gz&#x2F;jdk1.8.0_161&#x2F;bin&#x2F;java -server -Xmx1024m -Djava.io.tmpdir&#x3D;&#x2F;home&#x2F;hadoop&#x2F;tmp&#x2F;nm-local-dir&#x2F;usercache&#x2F;xxxxx&#x2F;appcache&#x2F;application_1519271509270_0745&#x2F;container_1519271509270_0745_01_000001&#x2F;tmp &#39;-XX:MaxPermSize&#x3D;2048m&#39; &#39;-XX:PermSize&#x3D;512m&#39; -Dspark.yarn.app.container.log.dir&#x3D;&#x2F;home&#x2F;hadoop&#x2F;hadoop-2.7.3&#x2F;logs&#x2F;userlogs&#x2F;application_1519271509270_0745&#x2F;container_1519271509270_0745_01_000001 org.apache.spark.deploy.yarn.ApplicationMaster --class &#39;org.apache.spark.ml.alogrithm.SmartRules&#39; --jar hdfs:&#x2F;&#x2F;slave131:9000&#x2F;user&#x2F;mls_zl&#x2F;lib2&#x2F;cmpt&#x2F;xxxxx-workflow-component-0.3.2-20180320-1101.jar --arg &#39;hdfs:&#x2F;&#x2F;slave131:9000&#x2F;user&#x2F;mls_3.5&#x2F;proc&#x2F;1&#x2F;11&#x2F;92&#x2F;submit_SmartRules_37Client.json&#39; --properties-file &#x2F;home&#x2F;hadoop&#x2F;tmp&#x2F;nm-local-dir&#x2F;usercache&#x2F;xxxxx&#x2F;appcache&#x2F;application_1519271509270_0745&#x2F;container_1519271509270_0745_01_000001&#x2F;__spark_conf__&#x2F;__spark_conf__.properties 1&gt; &#x2F;home&#x2F;hadoop&#x2F;hadoop-2.7.3&#x2F;logs&#x2F;userlogs&#x2F;application_1519271509270_0745&#x2F;container_1519271509270_0745_01_000001&#x2F;stdout 2&gt; &#x2F;home&#x2F;hadoop&#x2F;hadoop-2.7.3&#x2F;logs&#x2F;userlogs&#x2F;application_1519271509270_0745&#x2F;container_1519271509270_0745_01_000001&#x2F;stderr</span><br></pre></td></tr></table></figure>

<h4 id="信息重定向命令"><a href="#信息重定向命令" class="headerlink" title="信息重定向命令"></a>信息重定向命令</h4><blockquote>
<p>1&gt; /home/hadoop/hadoop-2.7.3/logs/userlogs/application_1519271509270_0745/container_1519271509270_0745_01_000001/stdout</p>
<p> 2&gt; /home/hadoop/hadoop-2.7.3/logs/userlogs/application_1519271509270_0745/container_1519271509270_0745_01_000001/stderr</p>
</blockquote>
<h3 id="2-2-进程二：-ApplicationMaster"><a href="#2-2-进程二：-ApplicationMaster" class="headerlink" title="2.2 进程二： ApplicationMaster"></a>2.2 进程二： ApplicationMaster</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop   110891 110334 99 13:40 ?        00:00:34 .&#x2F;jdk-8u161-linux-x64.tar.gz&#x2F;jdk1.8.0_161&#x2F;bin&#x2F;java -server -Xmx1024m -Djava.io.tmpdir&#x3D;&#x2F;home&#x2F;hadoop&#x2F;tmp&#x2F;nm-local-dir&#x2F;usercache&#x2F;xxxxx&#x2F;appcache&#x2F;application_1519271509270_0745&#x2F;container_1519271509270_0745_01_000001&#x2F;tmp -XX:MaxPermSize&#x3D;2048m -XX:PermSize&#x3D;512m -Dspark.yarn.app.container.log.dir&#x3D;&#x2F;home&#x2F;hadoop&#x2F;hadoop-2.7.3&#x2F;logs&#x2F;userlogs&#x2F;application_1519271509270_0745&#x2F;container_1519271509270_0745_01_000001 org.apache.spark.deploy.yarn.ApplicationMaster --class org.apache.spark.ml.alogrithm.SmartRules --jar hdfs:&#x2F;&#x2F;slave131:9000&#x2F;user&#x2F;mls_zl&#x2F;lib2&#x2F;cmpt&#x2F;xxxxx-workflow-component-0.3.2-20180320-1101.jar --arg hdfs:&#x2F;&#x2F;slave131:9000&#x2F;user&#x2F;mls_3.5&#x2F;proc&#x2F;1&#x2F;11&#x2F;92&#x2F;submit_SmartRules_37Client.json --properties-file &#x2F;home&#x2F;hadoop&#x2F;tmp&#x2F;nm-local-dir&#x2F;usercache&#x2F;xxxxx&#x2F;appcache&#x2F;application_1519271509270_0745&#x2F;container_1519271509270_0745_01_000001&#x2F;__spark_conf__&#x2F;__spark_conf__.properties</span><br></pre></td></tr></table></figure>

<p>该进程有 进程一 产生，参数配置和一近乎相当</p>
<h4 id="1-jdk-8u161-linux-x64-tar-gz-jdk1-8-0-161-bin-java"><a href="#1-jdk-8u161-linux-x64-tar-gz-jdk1-8-0-161-bin-java" class="headerlink" title="1. ./jdk-8u161-linux-x64.tar.gz/jdk1.8.0_161/bin/java"></a>1. ./jdk-8u161-linux-x64.tar.gz/jdk1.8.0_161/bin/java</h4><p>使用 jdk1.8 运行</p>
<h4 id="2-server"><a href="#2-server" class="headerlink" title="2. -server"></a>2. -server</h4><p> java 有2种启动方式 client 和 server 启动方式 ，client模式启动比较快，但运行时性能和内存管理效率不如server模式，通常用于客户端应用程序。相反，server模式启动比client慢，但可获得更高的运行性能。<br>在 windows上，缺省的虚拟机类型为client模式，如果要使用 server模式，就需要在启动虚拟机时加-server参数，以获得更高性能，对服务器端应用，推荐采用server模式，尤其是多个CPU的系统。在 Linux，Solaris上缺省采用server模式。 </p>
<h4 id="3-Xmx1024m"><a href="#3-Xmx1024m" class="headerlink" title="3. -Xmx1024m"></a>3. -Xmx1024m</h4><p>设置虚拟机内存堆的最大可用大小</p>
<h4 id="4-Djava-io-tmpdir"><a href="#4-Djava-io-tmpdir" class="headerlink" title="4. -Djava.io.tmpdir"></a>4. -Djava.io.tmpdir</h4><p>设置java 临时目录 为 <code>/home/hadoop/tmp/nm-local-dir/usercache/xxxxx/appcache/application_1519271509270_0745/container_1519271509270_0745_01_000001/tmp</code></p>
<h4 id="5-XX-MaxPermSize-2048m-XX-PermSize-512m"><a href="#5-XX-MaxPermSize-2048m-XX-PermSize-512m" class="headerlink" title="5. -XX:MaxPermSize=2048m -XX:PermSize=512m"></a>5. -XX:MaxPermSize=2048m -XX:PermSize=512m</h4><p>-XX:PermSize=64M JVM初始分配的非堆内存</p>
<p>-XX:MaxPermSize=128M JVM最大允许分配的非堆内存，按需分配</p>
<h4 id="6-Dspark-yarn-app-container-log-dir"><a href="#6-Dspark-yarn-app-container-log-dir" class="headerlink" title="6. -Dspark.yarn.app.container.log.dir"></a>6. -Dspark.yarn.app.container.log.dir</h4><p>设置容器 日志目录 为 <code>/home/hadoop/hadoop-2.7.3/logs/userlogs/application_1519271509270_0745/container_1519271509270_0745_01_000001</code></p>
<h4 id="7-org-apache-spark-deploy-yarn-ApplicationMaster"><a href="#7-org-apache-spark-deploy-yarn-ApplicationMaster" class="headerlink" title="7. org.apache.spark.deploy.yarn.ApplicationMaster"></a>7. org.apache.spark.deploy.yarn.ApplicationMaster</h4><p>Java 程序入口类</p>
<h4 id="8-–class"><a href="#8-–class" class="headerlink" title="8. –class"></a>8. –class</h4><p>指定spark任务需要执行任务主类 <code>org.apache.spark.ml.alogrithm.SmartRules</code></p>
<h4 id="9-–jar"><a href="#9-–jar" class="headerlink" title="9. –jar"></a>9. –jar</h4><p>指定spark需要的jar包路径  <code>hdfs://slave131:9000/user/mls_zl/lib2/cmpt/xxxxx-workflow-component-0.3.2-20180320-1101.jar</code></p>
<h4 id="10-–arg"><a href="#10-–arg" class="headerlink" title="10. –arg"></a>10. –arg</h4><p>指定spark任务（客户端编写的代码）所需的参数</p>
<p><code>&#39;hdfs://slave131:9000/user/mls_3.5/proc/1/11/92/submit_SmartRules_37Client.json&#39;</code> </p>
<h4 id="11-–properties-file"><a href="#11-–properties-file" class="headerlink" title="11. –properties-file"></a>11. –properties-file</h4><p> <code>/home/hadoop/tmp/nm-local-dir/usercache/xxxxx/appcache/application_1519271509270_0745/container_1519271509270_0745_01_000001/__spark_conf__/__spark_conf__.properties</code> </p>
<h3 id="2-3-进程三"><a href="#2-3-进程三" class="headerlink" title="2.3 进程三"></a>2.3 进程三</h3><p>使用 bash -c 启动 executor 守护进程 即进程四</p>
<p><a href="http://blog.sina.com.cn/s/blog_9ca9623b0102w7p9.html" target="_blank" rel="noopener">spark executor内幕</a></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop   111013 111010  0 13:40 ?        00:00:00 &#x2F;bin&#x2F;bash -c .&#x2F;jdk-8u161-linux-x64.tar.gz&#x2F;jdk1.8.0_161&#x2F;bin&#x2F;java -server -Xmx4096m -Djava.io.tmpdir&#x3D;&#x2F;home&#x2F;hadoop&#x2F;tmp&#x2F;nm-local-dir&#x2F;usercache&#x2F;xxxxx&#x2F;appcache&#x2F;application_1519271509270_0745&#x2F;container_1519271509270_0745_01_000002&#x2F;tmp &#39;-Dspark.ui.port&#x3D;0&#39; &#39;-Dspark.driver.port&#x3D;37011&#39; -Dspark.yarn.app.container.log.dir&#x3D;&#x2F;home&#x2F;hadoop&#x2F;hadoop-2.7.3&#x2F;logs&#x2F;userlogs&#x2F;application_1519271509270_0745&#x2F;container_1519271509270_0745_01_000002 -XX:OnOutOfMemoryError&#x3D;&#39;kill %p&#39; org.apache.spark.executor.CoarseGrainedExecutorBackend --driver-url spark:&#x2F;&#x2F;CoarseGrainedScheduler@10.100.1.131:37011 --executor-id 1 --hostname slave131 --cores 8 --app-id application_1519271509270_0745 --user-class-path file:&#x2F;home&#x2F;hadoop&#x2F;tmp&#x2F;nm-local-dir&#x2F;usercache&#x2F;xxxxx&#x2F;appcache&#x2F;application_1519271509270_0745&#x2F;container_1519271509270_0745_01_000002&#x2F;__app__.jar 1&gt;&#x2F;home&#x2F;hadoop&#x2F;hadoop-2.7.3&#x2F;logs&#x2F;userlogs&#x2F;application_1519271509270_0745&#x2F;container_1519271509270_0745_01_000002&#x2F;stdout 2&gt;&#x2F;home&#x2F;hadoop&#x2F;hadoop-2.7.3&#x2F;logs&#x2F;userlogs&#x2F;application_1519271509270_0745&#x2F;container_1519271509270_0745_01_000002&#x2F;stderr</span><br></pre></td></tr></table></figure>

<h3 id="2-4-进程四：CoarseGrainedExecutorBackend"><a href="#2-4-进程四：CoarseGrainedExecutorBackend" class="headerlink" title="2.4 进程四：CoarseGrainedExecutorBackend"></a>2.4 进程四：CoarseGrainedExecutorBackend</h3><p>在spark中，executor是负责计算任务的，而CoarseGrainedExecutorBackend 则是负责Executor对象的创建和维护的</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop   111567 111013 99 13:40 ?        00:00:32 .&#x2F;jdk-8u161-linux-x64.tar.gz&#x2F;jdk1.8.0_161&#x2F;bin&#x2F;java -server -Xmx4096m -Djava.io.tmpdir&#x3D;&#x2F;home&#x2F;hadoop&#x2F;tmp&#x2F;nm-local-dir&#x2F;usercache&#x2F;xxxxx&#x2F;appcache&#x2F;application_1519271509270_0745&#x2F;container_1519271509270_0745_01_000002&#x2F;tmp -Dspark.ui.port&#x3D;0 -Dspark.driver.port&#x3D;37011 -Dspark.yarn.app.container.log.dir&#x3D;&#x2F;home&#x2F;hadoop&#x2F;hadoop-2.7.3&#x2F;logs&#x2F;userlogs&#x2F;application_1519271509270_0745&#x2F;container_1519271509270_0745_01_000002 -XX:OnOutOfMemoryError&#x3D;kill %p org.apache.spark.executor.CoarseGrainedExecutorBackend --driver-url spark:&#x2F;&#x2F;CoarseGrainedScheduler@10.100.1.131:37011 --executor-id 1 --hostname slave131 --cores 8 --app-id application_1519271509270_0745 --user-class-path file:&#x2F;home&#x2F;hadoop&#x2F;tmp&#x2F;nm-local-dir&#x2F;usercache&#x2F;xxxxx&#x2F;appcache&#x2F;application_1519271509270_0745&#x2F;container_1519271509270_0745_01_000002&#x2F;__app__.jar</span><br></pre></td></tr></table></figure>

<h4 id="1-Dspark-ui-port"><a href="#1-Dspark-ui-port" class="headerlink" title="1. -Dspark.ui.port"></a>1. -Dspark.ui.port</h4><p>0 代表随机选择一个可用的端口</p>
<h4 id="2-Dspark-driver-port"><a href="#2-Dspark-driver-port" class="headerlink" title="2. -Dspark.driver.port"></a>2. -Dspark.driver.port</h4><p>驱动器监听端口号 37011 </p>
<h4 id="3-Dspark-yarn-app-container-log-dir"><a href="#3-Dspark-yarn-app-container-log-dir" class="headerlink" title="3. -Dspark.yarn.app.container.log.dir"></a>3. -Dspark.yarn.app.container.log.dir</h4><p>指定app.container 的日志位置：<code>/home/hadoop/hadoop-2.7.3/logs/userlogs/application_1519271509270_0745/container_1519271509270_0745_01_000002</code></p>
<h4 id="4-XX-OnOutOfMemoryError-kill-p"><a href="#4-XX-OnOutOfMemoryError-kill-p" class="headerlink" title="4. -XX:OnOutOfMemoryError=kill %p"></a>4. -XX:OnOutOfMemoryError=kill %p</h4><p>出现OutOfMemoryError 时，启动 运行kill命令</p>
<h4 id="5-org-apache-spark-executor-CoarseGrainedExecutorBackend"><a href="#5-org-apache-spark-executor-CoarseGrainedExecutorBackend" class="headerlink" title="5. org.apache.spark.executor.CoarseGrainedExecutorBackend"></a>5. org.apache.spark.executor.CoarseGrainedExecutorBackend</h4><p>java 命令 主类</p>
<h4 id="6-–driver-url"><a href="#6-–driver-url" class="headerlink" title="6. –driver-url"></a>6. –driver-url</h4><p> <code>spark://CoarseGrainedScheduler@10.100.1.131:37011</code></p>
<p>指定CoarseGrainedScheduler对外暴露的url</p>
<h4 id="7-–executor-id"><a href="#7-–executor-id" class="headerlink" title="7. –executor-id"></a>7. –executor-id</h4><p>执行器的id，1</p>
<h4 id="8-–hostname"><a href="#8-–hostname" class="headerlink" title="8. –hostname"></a>8. –hostname</h4><p>主机名 slave131,谁的主机名，待查？</p>
<h4 id="9-–cores-8"><a href="#9-–cores-8" class="headerlink" title="9. –cores 8"></a>9. –cores 8</h4><p>执行核心数</p>
<h4 id="10-–app-id"><a href="#10-–app-id" class="headerlink" title="10. –app-id"></a>10. –app-id</h4><p>应用的id application_1519271509270_0745</p>
<p>由时间戳加id组成。</p>
<h4 id="–user-class-path"><a href="#–user-class-path" class="headerlink" title="–user-class-path"></a>–user-class-path</h4><p><code>file:/home/hadoop/tmp/nm-local-dir/usercache/xxxxx/appcache/application_1519271509270_0745/container_1519271509270_0745_01_000002/__app__.jar</code></p>
<h3 id="2-5-进程五"><a href="#2-5-进程五" class="headerlink" title="2.5 进程五"></a>2.5 进程五</h3><p>使用 bash -c 启动 进程五</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop   111619 111616  0 13:40 ?        00:00:00 &#x2F;bin&#x2F;bash -c .&#x2F;jdk-8u161-linux-x64.tar.gz&#x2F;jdk1.8.0_161&#x2F;bin&#x2F;java -server -Xmx4096m -Djava.io.tmpdir&#x3D;&#x2F;home&#x2F;hadoop&#x2F;tmp&#x2F;nm-local-dir&#x2F;usercache&#x2F;xxxxx&#x2F;appcache&#x2F;application_1519271509270_0745&#x2F;container_1519271509270_0745_01_000003&#x2F;tmp &#39;-Dspark.ui.port&#x3D;0&#39; &#39;-Dspark.driver.port&#x3D;37011&#39; -Dspark.yarn.app.container.log.dir&#x3D;&#x2F;home&#x2F;hadoop&#x2F;hadoop-2.7.3&#x2F;logs&#x2F;userlogs&#x2F;application_1519271509270_0745&#x2F;container_1519271509270_0745_01_000003 -XX:OnOutOfMemoryError&#x3D;&#39;kill %p&#39; org.apache.spark.executor.CoarseGrainedExecutorBackend --driver-url spark:&#x2F;&#x2F;CoarseGrainedScheduler@10.100.1.131:37011 --executor-id 2 --hostname slave131 --cores 8 --app-id application_1519271509270_0745 --user-class-path file:&#x2F;home&#x2F;hadoop&#x2F;tmp&#x2F;nm-local-dir&#x2F;usercache&#x2F;xxxxx&#x2F;appcache&#x2F;application_1519271509270_0745&#x2F;container_1519271509270_0745_01_000003&#x2F;__app__.jar 1&gt;&#x2F;home&#x2F;hadoop&#x2F;hadoop-2.7.3&#x2F;logs&#x2F;userlogs&#x2F;application_1519271509270_0745&#x2F;container_1519271509270_0745_01_000003&#x2F;stdout 2&gt;&#x2F;home&#x2F;hadoop&#x2F;hadoop-2.7.3&#x2F;logs&#x2F;userlogs&#x2F;application_1519271509270_0745&#x2F;container_1519271509270_0745_01_000003&#x2F;stderr</span><br></pre></td></tr></table></figure>

<h3 id="2-6-进程六：CoarseGrainedExecutorBackend"><a href="#2-6-进程六：CoarseGrainedExecutorBackend" class="headerlink" title="2.6 进程六：CoarseGrainedExecutorBackend"></a>2.6 进程六：CoarseGrainedExecutorBackend</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop   112178 111619 99 13:40 ?        00:00:50 .&#x2F;jdk-8u161-linux-x64.tar.gz&#x2F;jdk1.8.0_161&#x2F;bin&#x2F;java -server -Xmx4096m -Djava.io.tmpdir&#x3D;&#x2F;home&#x2F;hadoop&#x2F;tmp&#x2F;nm-local-dir&#x2F;usercache&#x2F;xxxxx&#x2F;appcache&#x2F;application_1519271509270_0745&#x2F;container_1519271509270_0745_01_000003&#x2F;tmp -Dspark.ui.port&#x3D;0 -Dspark.driver.port&#x3D;37011 -Dspark.yarn.app.container.log.dir&#x3D;&#x2F;home&#x2F;hadoop&#x2F;hadoop-2.7.3&#x2F;logs&#x2F;userlogs&#x2F;application_1519271509270_0745&#x2F;container_1519271509270_0745_01_000003 -XX:OnOutOfMemoryError&#x3D;kill %p org.apache.spark.executor.CoarseGrainedExecutorBackend --driver-url spark:&#x2F;&#x2F;CoarseGrainedScheduler@10.100.1.131:37011 --executor-id 2 --hostname slave131 --cores 8 --app-id application_1519271509270_0745 --user-class-path file:&#x2F;home&#x2F;hadoop&#x2F;tmp&#x2F;nm-local-dir&#x2F;usercache&#x2F;xxxxx&#x2F;appcache&#x2F;application_1519271509270_0745&#x2F;container_1519271509270_0745_01_000003&#x2F;__app__.jar</span><br></pre></td></tr></table></figure>

<h2 id="三、总结"><a href="#三、总结" class="headerlink" title="三、总结"></a>三、总结</h2><p>从上面的结果分析，提交某任务后，spark 启动的3个进程：一个 ApplicationMaster、两个CoarseGrainedExecutorBackend。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://longzl2015.github.io/2018/06/04/spark/Spark%E6%89%A7%E8%A1%8C%E9%80%BB%E8%BE%91/8_Executor%20%E6%89%A7%E8%A1%8Ctask%E5%B9%B6%E8%BF%94%E5%9B%9E%E7%BB%93%E6%9E%9C/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="zhoul">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2018/06/04/spark/Spark%E6%89%A7%E8%A1%8C%E9%80%BB%E8%BE%91/8_Executor%20%E6%89%A7%E8%A1%8Ctask%E5%B9%B6%E8%BF%94%E5%9B%9E%E7%BB%93%E6%9E%9C/" class="post-title-link" itemprop="url">spark8-executor执行task比返回结果</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2018-06-04 23:22:08" itemprop="dateCreated datePublished" datetime="2018-06-04T23:22:08+08:00">2018-06-04</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-02-27 17:16:07" itemprop="dateModified" datetime="2020-02-27T17:16:07+08:00">2020-02-27</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/spark/" itemprop="url" rel="index">
                    <span itemprop="name">spark</span>
                  </a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/spark/%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/" itemprop="url" rel="index">
                    <span itemprop="name">源码解析</span>
                  </a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="fa fa-comment-o"></i>
      </span>
      <span class="post-meta-item-text">Disqus：</span>
    
    <a title="disqus" href="/2018/06/04/spark/Spark%E6%89%A7%E8%A1%8C%E9%80%BB%E8%BE%91/8_Executor%20%E6%89%A7%E8%A1%8Ctask%E5%B9%B6%E8%BF%94%E5%9B%9E%E7%BB%93%E6%9E%9C/#comments" itemprop="discussionUrl">
      <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2018/06/04/spark/Spark执行逻辑/8_Executor 执行task并返回结果/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="概要"><a href="#概要" class="headerlink" title="概要"></a>概要</h1><p>本篇博客是<a href="http://blog.csdn.net/u011564172/article/details/65653617" target="_blank" rel="noopener">Spark 任务调度概述</a>详细流程中的最后一部分，介绍Executor执行task并返回result给Driver。</p>
<h1 id="receive-task"><a href="#receive-task" class="headerlink" title="receive task"></a>receive task</h1><p>上一篇博客<a href="http://blog.csdn.net/u011564172/article/details/69706510" target="_blank" rel="noopener">Spark 任务调度之Driver send Task</a>，最后讲到Executor接收Task，如下 </p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">case</span> <span class="type">LaunchTask</span>(data) =&gt;</span><br><span class="line">     <span class="keyword">if</span> (executor == <span class="literal">null</span>) &#123;</span><br><span class="line">       exitExecutor(<span class="number">1</span>, <span class="string">"Received LaunchTask command but executor was null"</span>)</span><br><span class="line">     &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">       <span class="keyword">val</span> taskDesc = <span class="type">TaskDescription</span>.decode(data.value)</span><br><span class="line">       logInfo(<span class="string">"Got assigned task "</span> + taskDesc.taskId)</span><br><span class="line">       executor.launchTask(<span class="keyword">this</span>, taskDesc)</span><br><span class="line">     &#125;</span><br></pre></td></tr></table></figure>

<p>Executor的launchTask方法将收到的信息封装为TaskRunner对象，TaskRunner继承自Runnable，Executor使用线程池threadPool调度TaskRunner，如下 </p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">launchTask</span></span>(context: <span class="type">ExecutorBackend</span>, taskDescription: <span class="type">TaskDescription</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">val</span> tr = <span class="keyword">new</span> <span class="type">TaskRunner</span>(context, taskDescription)</span><br><span class="line">    runningTasks.put(taskDescription.taskId, tr)</span><br><span class="line">    threadPool.execute(tr)</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>

<p>接下来查看TaskRunner中run方法对应的逻辑，我将其分为<strong>deserialize task</strong>、<strong>run task</strong>、<strong>sendback result</strong>三部分。</p>
<h1 id="deserialize-task"><a href="#deserialize-task" class="headerlink" title="deserialize task"></a>deserialize task</h1><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">run</span></span>(): <span class="type">Unit</span> = &#123;</span><br><span class="line">     threadId = <span class="type">Thread</span>.currentThread.getId</span><br><span class="line">     <span class="type">Thread</span>.currentThread.setName(threadName)</span><br><span class="line">     <span class="keyword">val</span> threadMXBean = <span class="type">ManagementFactory</span>.getThreadMXBean</span><br><span class="line">    <span class="comment">//taskMemoryManager 管理每个task的内存</span></span><br><span class="line">     <span class="keyword">val</span> taskMemoryManager = <span class="keyword">new</span> <span class="type">TaskMemoryManager</span>(env.memoryManager, taskId)</span><br><span class="line">     <span class="keyword">val</span> deserializeStartTime = <span class="type">System</span>.currentTimeMillis()</span><br><span class="line">     <span class="keyword">val</span> deserializeStartCpuTime = <span class="keyword">if</span> (threadMXBean.isCurrentThreadCpuTimeSupported) &#123;</span><br><span class="line">       threadMXBean.getCurrentThreadCpuTime</span><br><span class="line">     &#125; <span class="keyword">else</span> <span class="number">0</span>L</span><br><span class="line">     <span class="type">Thread</span>.currentThread.setContextClassLoader(replClassLoader)</span><br><span class="line">     <span class="keyword">val</span> ser = env.closureSerializer.newInstance()</span><br><span class="line">     logInfo(<span class="string">s"Running <span class="subst">$taskName</span> (TID <span class="subst">$taskId</span>)"</span>)</span><br><span class="line">    <span class="comment">//给Driver发送消息，通知task状态为运行中</span></span><br><span class="line">     execBackend.statusUpdate(taskId, <span class="type">TaskState</span>.<span class="type">RUNNING</span>, <span class="type">EMPTY_BYTE_BUFFER</span>)</span><br><span class="line">     <span class="keyword">var</span> taskStart: <span class="type">Long</span> = <span class="number">0</span></span><br><span class="line">     <span class="keyword">var</span> taskStartCpu: <span class="type">Long</span> = <span class="number">0</span></span><br><span class="line">     startGCTime = computeTotalGcTime()</span><br><span class="line"></span><br><span class="line">     <span class="keyword">try</span> &#123;</span><br><span class="line">       <span class="comment">// Must be set before updateDependencies() is called, in case fetching dependencies</span></span><br><span class="line">       <span class="comment">// requires access to properties contained within (e.g. for access control).</span></span><br><span class="line">       <span class="type">Executor</span>.taskDeserializationProps.set(taskDescription.properties)</span><br><span class="line">       <span class="comment">// 反序列化收到的task消息，结果为file和jar路劲，以及task对应的ByteBuffer</span></span><br><span class="line">       <span class="comment">// 从Driver下载相应的file和jar，并使用replClassLoader加载jar</span></span><br><span class="line">       <span class="comment">// 反序列化task对应的ByteBuffer，得到Task对象</span></span><br><span class="line">       updateDependencies(taskDescription.addedFiles, taskDescription.addedJars)</span><br><span class="line">       task = ser.deserialize[<span class="type">Task</span>[<span class="type">Any</span>]](</span><br><span class="line">         taskDescription.serializedTask, <span class="type">Thread</span>.currentThread.getContextClassLoader)</span><br><span class="line">       task.localProperties = taskDescription.properties</span><br><span class="line">       task.setTaskMemoryManager(taskMemoryManager)</span><br></pre></td></tr></table></figure>

<p>如上图注释，反序列化得到Task对象。</p>
<h1 id="run-task"><a href="#run-task" class="headerlink" title="run task"></a>run task</h1><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> value = <span class="keyword">try</span> &#123;</span><br><span class="line">         <span class="keyword">val</span> res = task.run(</span><br><span class="line">           taskAttemptId = taskId,</span><br><span class="line">           attemptNumber = taskDescription.attemptNumber,</span><br><span class="line">           metricsSystem = env.metricsSystem)</span><br><span class="line">         threwException = <span class="literal">false</span></span><br><span class="line">         res</span><br><span class="line">       &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">         <span class="keyword">val</span> releasedLocks = env.blockManager.releaseAllLocksForTask(taskId)</span><br><span class="line">         <span class="keyword">val</span> freedMemory = taskMemoryManager.cleanUpAllAllocatedMemory()</span><br><span class="line"></span><br><span class="line">         <span class="keyword">if</span> (freedMemory &gt; <span class="number">0</span> &amp;&amp; !threwException) &#123;</span><br><span class="line">           <span class="keyword">val</span> errMsg = <span class="string">s"Managed memory leak detected; size = <span class="subst">$freedMemory</span> bytes, TID = <span class="subst">$taskId</span>"</span></span><br><span class="line">           <span class="keyword">if</span> (conf.getBoolean(<span class="string">"spark.unsafe.exceptionOnMemoryLeak"</span>, <span class="literal">false</span>)) &#123;</span><br><span class="line">             <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">SparkException</span>(errMsg)</span><br><span class="line">           &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">             logWarning(errMsg)</span><br><span class="line">           &#125;</span><br><span class="line">         &#125;</span><br><span class="line"></span><br><span class="line">         <span class="keyword">if</span> (releasedLocks.nonEmpty &amp;&amp; !threwException) &#123;</span><br><span class="line">           <span class="keyword">val</span> errMsg =</span><br><span class="line">             <span class="string">s"<span class="subst">$&#123;releasedLocks.size&#125;</span> block locks were not released by TID = <span class="subst">$taskId</span>:\n"</span> +</span><br><span class="line">               releasedLocks.mkString(<span class="string">"["</span>, <span class="string">", "</span>, <span class="string">"]"</span>)</span><br><span class="line">           <span class="keyword">if</span> (conf.getBoolean(<span class="string">"spark.storage.exceptionOnPinLeak"</span>, <span class="literal">false</span>)) &#123;</span><br><span class="line">             <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">SparkException</span>(errMsg)</span><br><span class="line">           &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">             logInfo(errMsg)</span><br><span class="line">           &#125;</span><br><span class="line">         &#125;</span><br><span class="line">       &#125;</span><br></pre></td></tr></table></figure>


<p>如上图注释，调用Task的run方法执行计算，Task是抽象类，其实现类有两个，<strong>ShuffleMapTask</strong>和<strong>ResultTask</strong>，分别对应shuffle和非shuffle任务。</p>
<p>Task的run方法调用其runTask方法执行task，我们以Task的子类<strong>ResultTask</strong>为例(ShuffleMapTask相比ResultTask多了一个步骤，使用<strong>ShuffleWriter</strong>将结果写到本地)，如下<br><img src="8_Executor%E6%89%A7%E8%A1%8Ctask%E5%B9%B6%E8%BF%94%E5%9B%9E%E7%BB%93%E6%9E%9C/SouthEast-20180531115515975.png" alt="这里写图片描述"><br>为了说明上图中的<strong>func</strong>，我们以RDD的map方法为例，如下<br><img src="8_Executor%E6%89%A7%E8%A1%8Ctask%E5%B9%B6%E8%BF%94%E5%9B%9E%E7%BB%93%E6%9E%9C/SouthEast-20180531115521822.png" alt="这里写图片描述"><br>至此，task的计算就完成了，task的run方法返回计算结果。</p>
<h1 id="sendback-result"><a href="#sendback-result" class="headerlink" title="sendback result"></a>sendback result</h1><p><img src="8_Executor%E6%89%A7%E8%A1%8Ctask%E5%B9%B6%E8%BF%94%E5%9B%9E%E7%BB%93%E6%9E%9C/SouthEast-20180531115525240.png" alt="这里写图片描述"><br>如上图注释，对计算结果进行序列化，再根据其大小采取相应方式处理，最后调用<strong>CoarseGrainedExecutorBackend</strong>的statusUpdate方法返回result给Driver。</p>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>从</p>
<ol>
<li>上图①所示路径，执行task任务。</li>
<li>上图②所示路径，将执行结果返回给Driver，后续Driver调用<strong>TaskScheduler</strong>处理返回结果，不再介绍。</li>
</ol>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://longzl2015.github.io/2018/06/04/spark/Spark%E6%89%A7%E8%A1%8C%E9%80%BB%E8%BE%91/7_driver%20%E6%8F%90%E4%BA%A4%20task/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="zhoul">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2018/06/04/spark/Spark%E6%89%A7%E8%A1%8C%E9%80%BB%E8%BE%91/7_driver%20%E6%8F%90%E4%BA%A4%20task/" class="post-title-link" itemprop="url">spark7-driver提交task</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2018-06-04 23:22:07" itemprop="dateCreated datePublished" datetime="2018-06-04T23:22:07+08:00">2018-06-04</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-02-27 17:16:07" itemprop="dateModified" datetime="2020-02-27T17:16:07+08:00">2020-02-27</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/spark/" itemprop="url" rel="index">
                    <span itemprop="name">spark</span>
                  </a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/spark/%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/" itemprop="url" rel="index">
                    <span itemprop="name">源码解析</span>
                  </a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="fa fa-comment-o"></i>
      </span>
      <span class="post-meta-item-text">Disqus：</span>
    
    <a title="disqus" href="/2018/06/04/spark/Spark%E6%89%A7%E8%A1%8C%E9%80%BB%E8%BE%91/7_driver%20%E6%8F%90%E4%BA%A4%20task/#comments" itemprop="discussionUrl">
      <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2018/06/04/spark/Spark执行逻辑/7_driver 提交 task/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="概要"><a href="#概要" class="headerlink" title="概要"></a>概要</h1><p>本篇博客是<a href="http://blog.csdn.net/u011564172/article/details/65653617" target="_blank" rel="noopener">Spark 任务调度概述</a>详细流程中的第七部分，介绍Driver发送task到Executor的过程。</p>
<h1 id="执行用户编写代码"><a href="#执行用户编写代码" class="headerlink" title="执行用户编写代码"></a>执行用户编写代码</h1><p><a href="http://blog.csdn.net/u011564172/article/details/69062339" target="_blank" rel="noopener">Spark 任务调度之Register App</a>中介绍了Driver中初始化SparkContext对象及注册APP的流程，SparkContext初始化完毕后，执行用户编写代码，仍以SparkPi为例，如下 </p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">SparkPi</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]) &#123;</span><br><span class="line">    <span class="keyword">val</span> spark = <span class="type">SparkSession</span></span><br><span class="line">      .builder</span><br><span class="line">      .appName(<span class="string">"Spark Pi"</span>)</span><br><span class="line">      .getOrCreate()</span><br><span class="line">    <span class="keyword">val</span> slices = <span class="keyword">if</span> (args.length &gt; <span class="number">0</span>) args(<span class="number">0</span>).toInt <span class="keyword">else</span> <span class="number">2</span></span><br><span class="line">    <span class="keyword">val</span> n = math.min(<span class="number">100000</span>L * slices, <span class="type">Int</span>.<span class="type">MaxValue</span>).toInt <span class="comment">// avoid overflow</span></span><br><span class="line">    <span class="keyword">val</span> count = spark.sparkContext.parallelize(<span class="number">1</span> until n, slices).map &#123; i =&gt;</span><br><span class="line">      <span class="keyword">val</span> x = random * <span class="number">2</span> - <span class="number">1</span></span><br><span class="line">      <span class="keyword">val</span> y = random * <span class="number">2</span> - <span class="number">1</span></span><br><span class="line">      <span class="keyword">if</span> (x*x + y*y &lt;= <span class="number">1</span>) <span class="number">1</span> <span class="keyword">else</span> <span class="number">0</span></span><br><span class="line">    &#125;.reduce(_ + _)</span><br><span class="line">    println(<span class="string">s"Pi is roughly <span class="subst">$&#123;4.0 * count / (n - 1)&#125;</span>"</span>)</span><br><span class="line">    spark.stop()</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>如上图，SparkPi中调用RDD的<strong>reduce</strong>，reduce中<br>调用SparkContext.runJob方法提交任务，SparkContext.runJob方法调用DAGScheduler.runJob方法，如下</p>
 <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">reduce</span></span>(f: (<span class="type">T</span>, <span class="type">T</span>) =&gt; <span class="type">T</span>): <span class="type">T</span> = withScope &#123;</span><br><span class="line">   <span class="keyword">val</span> cleanF = sc.clean(f)</span><br><span class="line">   <span class="keyword">val</span> reducePartition: <span class="type">Iterator</span>[<span class="type">T</span>] =&gt; <span class="type">Option</span>[<span class="type">T</span>] = iter =&gt; &#123;</span><br><span class="line">     <span class="keyword">if</span> (iter.hasNext) &#123;</span><br><span class="line">       <span class="type">Some</span>(iter.reduceLeft(cleanF))</span><br><span class="line">     &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">       <span class="type">None</span></span><br><span class="line">     &#125;</span><br><span class="line">   &#125;</span><br><span class="line">   <span class="keyword">var</span> jobResult: <span class="type">Option</span>[<span class="type">T</span>] = <span class="type">None</span></span><br><span class="line">   <span class="keyword">val</span> mergeResult = (index: <span class="type">Int</span>, taskResult: <span class="type">Option</span>[<span class="type">T</span>]) =&gt; &#123;</span><br><span class="line">     <span class="keyword">if</span> (taskResult.isDefined) &#123;</span><br><span class="line">       jobResult = jobResult <span class="keyword">match</span> &#123;</span><br><span class="line">         <span class="keyword">case</span> <span class="type">Some</span>(value) =&gt; <span class="type">Some</span>(f(value, taskResult.get))</span><br><span class="line">         <span class="keyword">case</span> <span class="type">None</span> =&gt; taskResult</span><br><span class="line">       &#125;</span><br><span class="line">     &#125;</span><br><span class="line">   &#125;</span><br><span class="line">   sc.runJob(<span class="keyword">this</span>, reducePartition, mergeResult)</span><br><span class="line">   <span class="comment">// Get the final result out of our Option, or throw an exception if the RDD was empty</span></span><br><span class="line">   jobResult.getOrElse(<span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">UnsupportedOperationException</span>(<span class="string">"empty collection"</span>))</span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">runJob</span></span>[<span class="type">T</span>, <span class="type">U</span>: <span class="type">ClassTag</span>](</span><br><span class="line">      rdd: <span class="type">RDD</span>[<span class="type">T</span>],</span><br><span class="line">      func: (<span class="type">TaskContext</span>, <span class="type">Iterator</span>[<span class="type">T</span>]) =&gt; <span class="type">U</span>,</span><br><span class="line">      partitions: <span class="type">Seq</span>[<span class="type">Int</span>],</span><br><span class="line">      resultHandler: (<span class="type">Int</span>, <span class="type">U</span>) =&gt; <span class="type">Unit</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">if</span> (stopped.get()) &#123;</span><br><span class="line">      <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">IllegalStateException</span>(<span class="string">"SparkContext has been shutdown"</span>)</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">val</span> callSite = getCallSite</span><br><span class="line">    <span class="keyword">val</span> cleanedFunc = clean(func)</span><br><span class="line">    logInfo(<span class="string">"Starting job: "</span> + callSite.shortForm)</span><br><span class="line">    <span class="keyword">if</span> (conf.getBoolean(<span class="string">"spark.logLineage"</span>, <span class="literal">false</span>)) &#123;</span><br><span class="line">      logInfo(<span class="string">"RDD's recursive dependencies:\n"</span> + rdd.toDebugString)</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//生成task并提交</span></span><br><span class="line">    dagScheduler.runJob(rdd, cleanedFunc, partitions, callSite, resultHandler, localProperties.get)</span><br><span class="line">    progressBar.foreach(_.finishAll())</span><br><span class="line">    rdd.doCheckpoint()</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>

<h1 id="DAGScheduler生成task"><a href="#DAGScheduler生成task" class="headerlink" title="DAGScheduler生成task"></a>DAGScheduler生成task</h1><p>DAGScheduler中，根据rdd的<a href="http://blog.csdn.net/u011564172/article/details/54312200" target="_blank" rel="noopener">Dependency</a>生成stage，stage分为ShuffleMapStage和ResultStage两种类型，根据stage类型生成对应的task，分别是ShuffleMapTask、ResultTask，最后调用TaskScheduler提交任务</p>
<h1 id="TaskScheduler提交task"><a href="#TaskScheduler提交task" class="headerlink" title="TaskScheduler提交task"></a>TaskScheduler提交task</h1><p>TaskScheduler中使用<strong>TaskSetManager</strong>管理TaskSet，submitTasks方法最终调用<strong>CoarseGrainedSchedulerBackend</strong>的launchTasks方法将task发送到Executor，如下 </p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">launchTasks</span></span>(tasks: <span class="type">Seq</span>[<span class="type">Seq</span>[<span class="type">TaskDescription</span>]]) &#123;</span><br><span class="line">      <span class="keyword">for</span> (task &lt;- tasks.flatten) &#123;</span><br><span class="line">        <span class="keyword">val</span> serializedTask = <span class="type">TaskDescription</span>.encode(task)</span><br><span class="line">        <span class="keyword">if</span> (serializedTask.limit() &gt;= maxRpcMessageSize) &#123;</span><br><span class="line">          scheduler.taskIdToTaskSetManager.get(task.taskId).foreach &#123; taskSetMgr =&gt;</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">              <span class="keyword">var</span> msg = <span class="string">"Serialized task %s:%d was %d bytes, which exceeds max allowed: "</span> +</span><br><span class="line">                <span class="string">"spark.rpc.message.maxSize (%d bytes). Consider increasing "</span> +</span><br><span class="line">                <span class="string">"spark.rpc.message.maxSize or using broadcast variables for large values."</span></span><br><span class="line">              msg = msg.format(task.taskId, task.index, serializedTask.limit(), maxRpcMessageSize)</span><br><span class="line">              taskSetMgr.abort(msg)</span><br><span class="line">            &#125; <span class="keyword">catch</span> &#123;</span><br><span class="line">              <span class="keyword">case</span> e: <span class="type">Exception</span> =&gt; logError(<span class="string">"Exception in error callback"</span>, e)</span><br><span class="line">            &#125;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">else</span> &#123;</span><br><span class="line">          <span class="comment">// executorDataMap 保存Executor的连接方式</span></span><br><span class="line">          <span class="keyword">val</span> executorData = executorDataMap(task.executorId)</span><br><span class="line">          executorData.freeCores -= scheduler.<span class="type">CPUS_PER_TASK</span></span><br><span class="line"></span><br><span class="line">          logDebug(<span class="string">s"Launching task <span class="subst">$&#123;task.taskId&#125;</span> on executor id: <span class="subst">$&#123;task.executorId&#125;</span> hostname: "</span> +</span><br><span class="line">            <span class="string">s"<span class="subst">$&#123;executorData.executorHost&#125;</span>."</span>)</span><br><span class="line"></span><br><span class="line">          executorData.executorEndpoint.send(<span class="type">LaunchTask</span>(<span class="keyword">new</span> <span class="type">SerializableBuffer</span>(serializedTask)))</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>

<p><strong>executorDataMap</strong>中保存了Executor的连接方式，关于Executor如何注册到<strong>executorDataMap</strong>中，参考<a href="http://blog.csdn.net/u011564172/article/details/69922241" target="_blank" rel="noopener">Spark 任务调度之创建Executor</a>。</p>
<h1 id="Executor接收Task"><a href="#Executor接收Task" class="headerlink" title="Executor接收Task"></a>Executor接收Task</h1><p>Worker节点的<strong>CoarseGrainedExecutorBackend</strong>进程接收Driver发送的task，交给Executor对象处理，如下 </p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">case</span> <span class="type">LaunchTask</span>(data) =&gt;</span><br><span class="line">    <span class="keyword">if</span> (executor == <span class="literal">null</span>) &#123;</span><br><span class="line">      exitExecutor(<span class="number">1</span>, <span class="string">"Received LaunchTask command but executor was null"</span>)</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="keyword">val</span> taskDesc = <span class="type">TaskDescription</span>.decode(data.value)</span><br><span class="line">      logInfo(<span class="string">"Got assigned task "</span> + taskDesc.taskId)</span><br><span class="line">      executor.launchTask(<span class="keyword">this</span>, taskDesc)</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>

<p>Executor的创建过程请参考<a href="http://blog.csdn.net/u011564172/article/details/69922241" target="_blank" rel="noopener">Spark 任务调度之创建Executor</a>。</p>
<p>至此从RDD的action开始，至Executor对象接收任务的流程就结束了。</p>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>介绍了从RDD的action开始，到Executor接收到task的流程，其中省略了DAG相关的部分，后续单独介绍，整理流程大致如下 </p>
<p><img src="7_driver%E6%8F%90%E4%BA%A4task/SouthEast.png" alt="img"></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://longzl2015.github.io/2018/06/04/spark/Spark%E6%89%A7%E8%A1%8C%E9%80%BB%E8%BE%91/6_%E5%88%9B%E5%BB%BAexecutor%E8%BF%87%E7%A8%8B/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="zhoul">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2018/06/04/spark/Spark%E6%89%A7%E8%A1%8C%E9%80%BB%E8%BE%91/6_%E5%88%9B%E5%BB%BAexecutor%E8%BF%87%E7%A8%8B/" class="post-title-link" itemprop="url">spark6-创建executor 过程</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2018-06-04 23:22:06" itemprop="dateCreated datePublished" datetime="2018-06-04T23:22:06+08:00">2018-06-04</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-02-27 17:16:07" itemprop="dateModified" datetime="2020-02-27T17:16:07+08:00">2020-02-27</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/spark/" itemprop="url" rel="index">
                    <span itemprop="name">spark</span>
                  </a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/spark/%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/" itemprop="url" rel="index">
                    <span itemprop="name">源码解析</span>
                  </a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="fa fa-comment-o"></i>
      </span>
      <span class="post-meta-item-text">Disqus：</span>
    
    <a title="disqus" href="/2018/06/04/spark/Spark%E6%89%A7%E8%A1%8C%E9%80%BB%E8%BE%91/6_%E5%88%9B%E5%BB%BAexecutor%E8%BF%87%E7%A8%8B/#comments" itemprop="discussionUrl">
      <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2018/06/04/spark/Spark执行逻辑/6_创建executor过程/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="spark-创建executor-过程"><a href="#spark-创建executor-过程" class="headerlink" title="spark 创建executor 过程"></a>spark 创建executor 过程</h1><p>[TOC]</p>
<h2 id="一、uml-图"><a href="#一、uml-图" class="headerlink" title="一、uml 图"></a>一、uml 图</h2><p>下面的简单过程是 </p>
<ol>
<li>CoarseGrainedExecutorBackend 介绍Executor 给Drive</li>
<li>Drive注册完成Executor</li>
<li>CoarseGrainedExecutorBackend 创建Executor</li>
</ol>
<p>注： Drive 在类CoarseGrainedSchedulerBackend.scala中</p>
<img src='data:image/svg+xml;base64,<?xml version="1.0" encoding="UTF-8" standalone="no"?><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" contentScriptType="application/ecmascript" contentStyleType="text/css" height="595px" preserveAspectRatio="none" style="width:672px;height:595px;" version="1.1" viewBox="0 0 672 595" width="672px" zoomAndPan="magnify"><defs><filter height="300%" id="f1s6zd3kfyp2p7" width="300%" x="-1" y="-1"><feGaussianBlur result="blurOut" stdDeviation="2.0"/><feColorMatrix in="blurOut" result="blurOut2" type="matrix" values="0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 .4 0"/><feOffset dx="4.0" dy="4.0" in="blurOut2" result="blurOut3"/><feBlend in="SourceGraphic" in2="blurOut3" mode="normal"/></filter></defs><g><text fill="#000000" font-family="sans-serif" font-size="18" lengthAdjust="spacingAndGlyphs" textLength="210" x="231" y="26.708">spark 创建executor 过程</text><line style="stroke: #A80036; stroke-width: 1.0; stroke-dasharray: 5.0,5.0;" x1="129" x2="129" y1="73.25" y2="554.9766"/><line style="stroke: #A80036; stroke-width: 1.0; stroke-dasharray: 5.0,5.0;" x1="296" x2="296" y1="73.25" y2="554.9766"/><line style="stroke: #A80036; stroke-width: 1.0; stroke-dasharray: 5.0,5.0;" x1="370" x2="370" y1="73.25" y2="554.9766"/><line style="stroke: #A80036; stroke-width: 1.0; stroke-dasharray: 5.0,5.0;" x1="618.5" x2="618.5" y1="73.25" y2="554.9766"/><rect fill="#FEFECE" filter="url(#f1s6zd3kfyp2p7)" height="30.2969" style="stroke: #A80036; stroke-width: 1.5;" width="239" x="8" y="37.9531"/><text fill="#000000" font-family="sans-serif" font-size="14" lengthAdjust="spacingAndGlyphs" textLength="225" x="15" y="57.9482">CoarseGrainedExecutorBackend</text><rect fill="#FEFECE" filter="url(#f1s6zd3kfyp2p7)" height="30.2969" style="stroke: #A80036; stroke-width: 1.5;" width="239" x="8" y="553.9766"/><text fill="#000000" font-family="sans-serif" font-size="14" lengthAdjust="spacingAndGlyphs" textLength="225" x="15" y="573.9717">CoarseGrainedExecutorBackend</text><rect fill="#FEFECE" filter="url(#f1s6zd3kfyp2p7)" height="30.2969" style="stroke: #A80036; stroke-width: 1.5;" width="66" x="261" y="37.9531"/><text fill="#000000" font-family="sans-serif" font-size="14" lengthAdjust="spacingAndGlyphs" textLength="52" x="268" y="57.9482">RpcEnv</text><rect fill="#FEFECE" filter="url(#f1s6zd3kfyp2p7)" height="30.2969" style="stroke: #A80036; stroke-width: 1.5;" width="66" x="261" y="553.9766"/><text fill="#000000" font-family="sans-serif" font-size="14" lengthAdjust="spacingAndGlyphs" textLength="52" x="268" y="573.9717">RpcEnv</text><rect fill="#FEFECE" filter="url(#f1s6zd3kfyp2p7)" height="30.2969" style="stroke: #A80036; stroke-width: 1.5;" width="54" x="341" y="37.9531"/><text fill="#000000" font-family="sans-serif" font-size="14" lengthAdjust="spacingAndGlyphs" textLength="40" x="348" y="57.9482">Driver</text><rect fill="#FEFECE" filter="url(#f1s6zd3kfyp2p7)" height="30.2969" style="stroke: #A80036; stroke-width: 1.5;" width="54" x="341" y="553.9766"/><text fill="#000000" font-family="sans-serif" font-size="14" lengthAdjust="spacingAndGlyphs" textLength="40" x="348" y="573.9717">Driver</text><rect fill="#FEFECE" filter="url(#f1s6zd3kfyp2p7)" height="30.2969" style="stroke: #A80036; stroke-width: 1.5;" width="75" x="579.5" y="37.9531"/><text fill="#000000" font-family="sans-serif" font-size="14" lengthAdjust="spacingAndGlyphs" textLength="61" x="586.5" y="57.9482">Executor</text><rect fill="#FEFECE" filter="url(#f1s6zd3kfyp2p7)" height="30.2969" style="stroke: #A80036; stroke-width: 1.5;" width="75" x="579.5" y="553.9766"/><text fill="#000000" font-family="sans-serif" font-size="14" lengthAdjust="spacingAndGlyphs" textLength="61" x="586.5" y="573.9717">Executor</text><path d="M101,88.25 L101,113.25 L154,113.25 L154,98.25 L144,88.25 L101,88.25 " fill="#FBFB77" filter="url(#f1s6zd3kfyp2p7)" style="stroke: #A80036; stroke-width: 1.0;"/><path d="M144,88.25 L144,98.25 L154,98.25 L144,88.25 " fill="#FBFB77" style="stroke: #A80036; stroke-width: 1.0;"/><text fill="#000000" font-family="sans-serif" font-size="13" lengthAdjust="spacingAndGlyphs" textLength="32" x="107" y="105.3169">main</text><path d="M106,127.3828 L106,152.3828 L148,152.3828 L148,137.3828 L138,127.3828 L106,127.3828 " fill="#FBFB77" filter="url(#f1s6zd3kfyp2p7)" style="stroke: #A80036; stroke-width: 1.0;"/><path d="M138,127.3828 L138,137.3828 L148,137.3828 L138,127.3828 " fill="#FBFB77" style="stroke: #A80036; stroke-width: 1.0;"/><text fill="#000000" font-family="sans-serif" font-size="13" lengthAdjust="spacingAndGlyphs" textLength="21" x="112" y="144.4497">run</text><polygon fill="#A80036" points="284,178.6484,294,182.6484,284,186.6484,288,182.6484" style="stroke: #A80036; stroke-width: 1.0;"/><line style="stroke: #A80036; stroke-width: 1.0;" x1="129.5" x2="290" y1="182.6484" y2="182.6484"/><text fill="#000000" font-family="sans-serif" font-size="13" lengthAdjust="spacingAndGlyphs" textLength="26" x="136.5" y="177.5825">调用</text><path d="M237,195.6484 L237,220.6484 L350,220.6484 L350,205.6484 L340,195.6484 L237,195.6484 " fill="#FBFB77" filter="url(#f1s6zd3kfyp2p7)" style="stroke: #A80036; stroke-width: 1.0;"/><path d="M340,195.6484 L340,205.6484 L350,205.6484 L340,195.6484 " fill="#FBFB77" style="stroke: #A80036; stroke-width: 1.0;"/><text fill="#000000" font-family="sans-serif" font-size="13" lengthAdjust="spacingAndGlyphs" textLength="92" x="243" y="212.7153">setupEndpoint</text><polygon fill="#A80036" points="140.5,246.9141,130.5,250.9141,140.5,254.9141,136.5,250.9141" style="stroke: #A80036; stroke-width: 1.0;"/><line style="stroke: #A80036; stroke-width: 1.0;" x1="134.5" x2="295" y1="250.9141" y2="250.9141"/><text fill="#000000" font-family="sans-serif" font-size="13" lengthAdjust="spacingAndGlyphs" textLength="26" x="146.5" y="245.8481">调用</text><path d="M93,263.9141 L93,288.9141 L162,288.9141 L162,273.9141 L152,263.9141 L93,263.9141 " fill="#FBFB77" filter="url(#f1s6zd3kfyp2p7)" style="stroke: #A80036; stroke-width: 1.0;"/><path d="M152,263.9141 L152,273.9141 L162,273.9141 L152,263.9141 " fill="#FBFB77" style="stroke: #A80036; stroke-width: 1.0;"/><text fill="#000000" font-family="sans-serif" font-size="13" lengthAdjust="spacingAndGlyphs" textLength="48" x="99" y="280.981">onStart</text><polygon fill="#A80036" points="358,315.1797,368,319.1797,358,323.1797,362,319.1797" style="stroke: #A80036; stroke-width: 1.0;"/><line style="stroke: #A80036; stroke-width: 1.0;" x1="129.5" x2="364" y1="319.1797" y2="319.1797"/><text fill="#000000" font-family="sans-serif" font-size="13" lengthAdjust="spacingAndGlyphs" textLength="134" x="136.5" y="314.1138">RegisterExecutor消息</text><path d="M334,332.1797 L334,357.1797 L401,357.1797 L401,342.1797 L391,332.1797 L334,332.1797 " fill="#FBFB77" filter="url(#f1s6zd3kfyp2p7)" style="stroke: #A80036; stroke-width: 1.0;"/><path d="M391,332.1797 L391,342.1797 L401,342.1797 L391,332.1797 " fill="#FBFB77" style="stroke: #A80036; stroke-width: 1.0;"/><text fill="#000000" font-family="sans-serif" font-size="13" lengthAdjust="spacingAndGlyphs" textLength="46" x="340" y="349.2466">receive</text><line style="stroke: #A80036; stroke-width: 1.0;" x1="370" x2="412" y1="387.4453" y2="387.4453"/><line style="stroke: #A80036; stroke-width: 1.0;" x1="412" x2="412" y1="387.4453" y2="400.4453"/><line style="stroke: #A80036; stroke-width: 1.0;" x1="371" x2="412" y1="400.4453" y2="400.4453"/><polygon fill="#A80036" points="381,396.4453,371,400.4453,381,404.4453,377,400.4453" style="stroke: #A80036; stroke-width: 1.0;"/><text fill="#000000" font-family="sans-serif" font-size="13" lengthAdjust="spacingAndGlyphs" textLength="235" x="377" y="382.3794">将Executor注册到executorDataMap中</text><polygon fill="#A80036" points="140.5,425.5781,130.5,429.5781,140.5,433.5781,136.5,429.5781" style="stroke: #A80036; stroke-width: 1.0;"/><line style="stroke: #A80036; stroke-width: 1.0;" x1="134.5" x2="369" y1="429.5781" y2="429.5781"/><text fill="#000000" font-family="sans-serif" font-size="13" lengthAdjust="spacingAndGlyphs" textLength="150" x="146.5" y="424.5122">RegisteredExecutor消息</text><path d="M94,442.5781 L94,467.5781 L161,467.5781 L161,452.5781 L151,442.5781 L94,442.5781 " fill="#FBFB77" filter="url(#f1s6zd3kfyp2p7)" style="stroke: #A80036; stroke-width: 1.0;"/><path d="M151,442.5781 L151,452.5781 L161,452.5781 L151,442.5781 " fill="#FBFB77" style="stroke: #A80036; stroke-width: 1.0;"/><text fill="#000000" font-family="sans-serif" font-size="13" lengthAdjust="spacingAndGlyphs" textLength="46" x="100" y="459.645">receive</text><polygon fill="#A80036" points="607,493.8438,617,497.8438,607,501.8438,611,497.8438" style="stroke: #A80036; stroke-width: 1.0;"/><line style="stroke: #A80036; stroke-width: 1.0;" x1="129.5" x2="613" y1="497.8438" y2="497.8438"/><text fill="#000000" font-family="sans-serif" font-size="13" lengthAdjust="spacingAndGlyphs" textLength="82" x="136.5" y="492.7778">创建Executor</text><path d="M573,510.8438 L573,535.8438 L660,535.8438 L660,520.8438 L650,510.8438 L573,510.8438 " fill="#FBFB77" filter="url(#f1s6zd3kfyp2p7)" style="stroke: #A80036; stroke-width: 1.0;"/><path d="M650,510.8438 L650,520.8438 L660,520.8438 L650,510.8438 " fill="#FBFB77" style="stroke: #A80036; stroke-width: 1.0;"/><text fill="#000000" font-family="sans-serif" font-size="13" lengthAdjust="spacingAndGlyphs" textLength="66" x="579" y="527.9106">contructor</text><!--MD5=[101b6a806084a829e0bb16fba2425e2c]
@startuml
Title: spark 创建executor 过程
Note over CoarseGrainedExecutorBackend: main
Note over CoarseGrainedExecutorBackend: run
CoarseGrainedExecutorBackend->RpcEnv: 调用
Note over RpcEnv: setupEndpoint
RpcEnv->CoarseGrainedExecutorBackend: 调用
Note over CoarseGrainedExecutorBackend: onStart
CoarseGrainedExecutorBackend->Driver: RegisterExecutor消息
Note over Driver: receive
Driver -> Driver: 将Executor注册到executorDataMap中
Driver->CoarseGrainedExecutorBackend: RegisteredExecutor消息
Note over CoarseGrainedExecutorBackend: receive 
CoarseGrainedExecutorBackend->Executor:创建Executor
Note over Executor: contructor
@enduml

PlantUML version 1.2020.02beta5(Unknown compile time)
(GPL source distribution)
Java Runtime: Java(TM) SE Runtime Environment
JVM: Java HotSpot(TM) 64-Bit Server VM
Java Version: 1.7.0_25-b15
Operating System: Linux
Default Encoding: UTF-8
Language: en
Country: US
--></g></svg>'>
<h2 id="二、Executor"><a href="#二、Executor" class="headerlink" title="二、Executor"></a>二、Executor</h2><p>Executor运行在Worker节点，主要负责执行task和cache数据。 </p>
<h3 id="2-1-Executor-类图"><a href="#2-1-Executor-类图" class="headerlink" title="2.1 Executor 类图"></a>2.1 Executor 类图</h3><p><img src="/images/6_%E5%88%9B%E5%BB%BAexecutor%E8%BF%87%E7%A8%8B/sparkExecutor%E7%B1%BB%E5%9B%BE.png" alt="sparkExecutor类图"></p>
<p>介绍TaskRunner和Executor的主要作用</p>
<ol>
<li><strong>TaskRunner</strong>: 运行期Executor收到Driver发送的task信息，将其封装为TaskRunner，同时，TaskRunner继承Runnable，Executor使用线程池threadpool调度TaskRunner。 </li>
<li><strong>Executor</strong>: 有两个重要属性，runningTasks和threadPool，分别用于维护正在运行的TaskRunner和调度TaskRunner线程。将收到的task信息封装为TaskRunner及执行TaskRunner的行为发生在Executor的<strong>launchTask</strong>方法中。</li>
</ol>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">launchTask</span></span>(context: <span class="type">ExecutorBackend</span>, taskDescription: <span class="type">TaskDescription</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">  <span class="keyword">val</span> tr = <span class="keyword">new</span> <span class="type">TaskRunner</span>(context, taskDescription)</span><br><span class="line">  runningTasks.put(taskDescription.taskId, tr)</span><br><span class="line">  threadPool.execute(tr)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="三、创建Executor过程"><a href="#三、创建Executor过程" class="headerlink" title="三、创建Executor过程"></a>三、创建Executor过程</h2><p>在启动 CoarseGrainedExecutorBackend 进程后，CoarseGrainedExecutorBackend会将自己注册到RpcEnv中，注册之后会调用CoarseGrainedExecutorBackend的<code>onStart</code>方法，该方法会向Driver发送<code>RegisterExecutor</code>消息。</p>
<p>CoarseGrainedExecutorBackend.scala</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">onStart</span></span>() &#123;</span><br><span class="line">  logInfo(<span class="string">"Connecting to driver: "</span> + driverUrl)</span><br><span class="line">  rpcEnv.asyncSetupEndpointRefByURI(driverUrl).flatMap &#123; ref =&gt;</span><br><span class="line">    <span class="comment">// This is a very fast action so we can use "ThreadUtils.sameThread"</span></span><br><span class="line">    driver = <span class="type">Some</span>(ref)</span><br><span class="line">    ref.ask[<span class="type">Boolean</span>](<span class="type">RegisterExecutor</span>(executorId, self, hostname, cores, extractLogUrls))</span><br><span class="line">  &#125;(<span class="type">ThreadUtils</span>.sameThread).onComplete &#123;</span><br><span class="line">    <span class="comment">// This is a very fast action so we can use "ThreadUtils.sameThread"</span></span><br><span class="line">    <span class="keyword">case</span> <span class="type">Success</span>(msg) =&gt;</span><br><span class="line">      <span class="comment">// Always receive `true`. Just ignore it</span></span><br><span class="line">    <span class="keyword">case</span> <span class="type">Failure</span>(e) =&gt;</span><br><span class="line">      exitExecutor(<span class="number">1</span>, <span class="string">s"Cannot register with driver: <span class="subst">$driverUrl</span>"</span>, e, notifyDriver = <span class="literal">false</span>)</span><br><span class="line">  &#125;(<span class="type">ThreadUtils</span>.sameThread)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>查看Driver对该消息的处理(CoarseGrainedSchedulerBackend.scala)，Driver中先修改Executor信息有关的集合和变量，即<strong>注册Executor到Driver</strong>，Driver使用<strong>executorDataMap</strong>集合保存Executor信息。然后返回消息<strong>RegisteredExecutor</strong>给CoarseGrainedExecutorBackend。</p>
<p>CoarseGrainedSchedulerBackend.scala</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line"> <span class="class"><span class="keyword">class</span> <span class="title">DriverEndpoint</span>(<span class="params">override val rpcEnv: <span class="type">RpcEnv</span>, sparkProperties: <span class="type">Seq</span>[(<span class="type">String</span>, <span class="type">String</span></span>)])</span></span><br><span class="line"><span class="class">    <span class="keyword">extends</span> <span class="title">ThreadSafeRpcEndpoint</span> <span class="keyword">with</span> <span class="title">Logging</span> </span>&#123;</span><br><span class="line">        .....</span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">receiveAndReply</span></span>(context: <span class="type">RpcCallContext</span>): <span class="type">PartialFunction</span>[<span class="type">Any</span>, <span class="type">Unit</span>] = &#123;</span><br><span class="line"></span><br><span class="line">      <span class="keyword">case</span> <span class="type">RegisterExecutor</span>(executorId, executorRef, hostname, cores, logUrls) =&gt;</span><br><span class="line">        <span class="keyword">if</span> (executorDataMap.contains(executorId)) &#123;</span><br><span class="line">          executorRef.send(<span class="type">RegisterExecutorFailed</span>(<span class="string">"Duplicate executor ID: "</span> + executorId))</span><br><span class="line">          context.reply(<span class="literal">true</span>)</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (scheduler.nodeBlacklist != <span class="literal">null</span> &amp;&amp;</span><br><span class="line">          scheduler.nodeBlacklist.contains(hostname)) &#123;</span><br><span class="line">          <span class="comment">// If the cluster manager gives us an executor on a blacklisted node (because it</span></span><br><span class="line">          <span class="comment">// already started allocating those resources before we informed it of our blacklist,</span></span><br><span class="line">          <span class="comment">// or if it ignored our blacklist), then we reject that executor immediately.</span></span><br><span class="line">          logInfo(<span class="string">s"Rejecting <span class="subst">$executorId</span> as it has been blacklisted."</span>)</span><br><span class="line">          executorRef.send(<span class="type">RegisterExecutorFailed</span>(<span class="string">s"Executor is blacklisted: <span class="subst">$executorId</span>"</span>))</span><br><span class="line">          context.reply(<span class="literal">true</span>)</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">          <span class="comment">// If the executor's rpc env is not listening for incoming connections, `hostPort`</span></span><br><span class="line">          <span class="comment">// will be null, and the client connection should be used to contact the executor.</span></span><br><span class="line">          <span class="comment">// 修改Executor信息有关的集合和变量</span></span><br><span class="line">          <span class="keyword">val</span> executorAddress = <span class="keyword">if</span> (executorRef.address != <span class="literal">null</span>) &#123;</span><br><span class="line">              executorRef.address</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">              context.senderAddress</span><br><span class="line">            &#125;</span><br><span class="line">          logInfo(<span class="string">s"Registered executor <span class="subst">$executorRef</span> (<span class="subst">$executorAddress</span>) with ID <span class="subst">$executorId</span>"</span>)</span><br><span class="line">          addressToExecutorId(executorAddress) = executorId</span><br><span class="line">          totalCoreCount.addAndGet(cores)</span><br><span class="line">          totalRegisteredExecutors.addAndGet(<span class="number">1</span>)</span><br><span class="line">          <span class="keyword">val</span> data = <span class="keyword">new</span> <span class="type">ExecutorData</span>(executorRef, executorRef.address, hostname,</span><br><span class="line">            cores, cores, logUrls)</span><br><span class="line">          <span class="comment">// This must be synchronized because variables mutated</span></span><br><span class="line">          <span class="comment">// in this block are read when requesting executors</span></span><br><span class="line">          <span class="type">CoarseGrainedSchedulerBackend</span>.<span class="keyword">this</span>.synchronized &#123;</span><br><span class="line">            executorDataMap.put(executorId, data)</span><br><span class="line">            <span class="keyword">if</span> (currentExecutorIdCounter &lt; executorId.toInt) &#123;</span><br><span class="line">              currentExecutorIdCounter = executorId.toInt</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">if</span> (numPendingExecutors &gt; <span class="number">0</span>) &#123;</span><br><span class="line">              numPendingExecutors -= <span class="number">1</span></span><br><span class="line">              logDebug(<span class="string">s"Decremented number of pending executors (<span class="subst">$numPendingExecutors</span> left)"</span>)</span><br><span class="line">            &#125;</span><br><span class="line">          &#125;</span><br><span class="line">          <span class="comment">// 给 Executor 返回RegisteredExecutor消息</span></span><br><span class="line">          executorRef.send(<span class="type">RegisteredExecutor</span>)</span><br><span class="line">          <span class="comment">// Note: some tests expect the reply to come after we put the executor in the map</span></span><br><span class="line">          context.reply(<span class="literal">true</span>)</span><br><span class="line">          listenerBus.post(</span><br><span class="line">            <span class="type">SparkListenerExecutorAdded</span>(<span class="type">System</span>.currentTimeMillis(), executorId, data))</span><br><span class="line">          makeOffers()</span><br><span class="line">        &#125;</span><br><span class="line">      ......</span><br><span class="line">    &#125;</span><br><span class="line">     ....</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>查看CoarseGrainedExecutorBackend中对RegisteredExecutor消息的处理 ,CoarseGrainedExecutorBackend创建了Executor对象，创建完毕的Executord对象此后用于执行Driver发送的task。 </p>
<p>CoarseGrainedExecutorBackend.scala</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">receive</span></span>: <span class="type">PartialFunction</span>[<span class="type">Any</span>, <span class="type">Unit</span>] = &#123;</span><br><span class="line">   <span class="keyword">case</span> <span class="type">RegisteredExecutor</span> =&gt;</span><br><span class="line">     logInfo(<span class="string">"Successfully registered with driver"</span>)</span><br><span class="line">     <span class="keyword">try</span> &#123;</span><br><span class="line">       executor = <span class="keyword">new</span> <span class="type">Executor</span>(executorId, hostname, env, userClassPath, isLocal = <span class="literal">false</span>)</span><br><span class="line">     &#125; <span class="keyword">catch</span> &#123;</span><br><span class="line">       <span class="keyword">case</span> <span class="type">NonFatal</span>(e) =&gt;</span><br><span class="line">         exitExecutor(<span class="number">1</span>, <span class="string">"Unable to create executor due to "</span> + e.getMessage, e)</span><br><span class="line">     &#125;</span><br></pre></td></tr></table></figure>


      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://longzl2015.github.io/2018/06/04/spark/Spark%E6%89%A7%E8%A1%8C%E9%80%BB%E8%BE%91/5_%E5%90%AF%E5%8A%A8CoarseGrainedExecutorBackend%E8%BF%9B%E7%A8%8B/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="zhoul">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2018/06/04/spark/Spark%E6%89%A7%E8%A1%8C%E9%80%BB%E8%BE%91/5_%E5%90%AF%E5%8A%A8CoarseGrainedExecutorBackend%E8%BF%9B%E7%A8%8B/" class="post-title-link" itemprop="url">spark5-启动CoarseGrainedExecutorBackend进程</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2018-06-04 23:22:05" itemprop="dateCreated datePublished" datetime="2018-06-04T23:22:05+08:00">2018-06-04</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-02-27 17:16:07" itemprop="dateModified" datetime="2020-02-27T17:16:07+08:00">2020-02-27</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/spark/" itemprop="url" rel="index">
                    <span itemprop="name">spark</span>
                  </a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/spark/%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/" itemprop="url" rel="index">
                    <span itemprop="name">源码解析</span>
                  </a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="fa fa-comment-o"></i>
      </span>
      <span class="post-meta-item-text">Disqus：</span>
    
    <a title="disqus" href="/2018/06/04/spark/Spark%E6%89%A7%E8%A1%8C%E9%80%BB%E8%BE%91/5_%E5%90%AF%E5%8A%A8CoarseGrainedExecutorBackend%E8%BF%9B%E7%A8%8B/#comments" itemprop="discussionUrl">
      <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2018/06/04/spark/Spark执行逻辑/5_启动CoarseGrainedExecutorBackend进程/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="启动CoarseGrainedExecutorBackend进程"><a href="#启动CoarseGrainedExecutorBackend进程" class="headerlink" title="启动CoarseGrainedExecutorBackend进程"></a>启动CoarseGrainedExecutorBackend进程</h1><p><strong>Executor</strong>负责计算任务，即执行task，而Executor对象的创建及维护是由<code>CoarseGrainedExecutorBackend</code>负责的，CoarseGrainedExecutorBackend在spark运行期是一个单独的进程.</p>
<p>##一、CoarseGrainedExecutorBackend类</p>
<p><img src="/images/5_%E5%90%AF%E5%8A%A8CoarseGrainedExecutorBackend%E8%BF%9B%E7%A8%8B/CoarseGrainedExecutorBackend%E7%B1%BB%E5%9B%BE.png" alt="sparkExecutor类图"></p>
<ol>
<li><code>CoarseGrainedExecutorBackend</code>是<strong>RpcEndpoint</strong>的子类，能够和Driver进行RPC通信。</li>
<li><code>CoarseGrainedExecutorBackend</code>维护了两个属性executor和driver，executor负责运行task，driver负责和Driver通信。</li>
<li>ExecutorBackend有抽象方法statusUpdate，负责将Executor的计算结果返回给Driver。</li>
</ol>
<p>最后，CoarseGrainedExecutorBackend是spark运行期的一个进程，Executor运行在该进程内。</p>
<h2 id="二、启动过程"><a href="#二、启动过程" class="headerlink" title="二、启动过程"></a>二、启动过程</h2><h3 id="2-1-uml"><a href="#2-1-uml" class="headerlink" title="2.1 uml"></a>2.1 uml</h3><img src='data:image/svg+xml;base64,<?xml version="1.0" encoding="UTF-8" standalone="no"?><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" contentScriptType="application/ecmascript" contentStyleType="text/css" height="416px" preserveAspectRatio="none" style="width:658px;height:416px;" version="1.1" viewBox="0 0 658 416" width="658px" zoomAndPan="magnify"><defs><filter height="300%" id="f6cssshobinod" width="300%" x="-1" y="-1"><feGaussianBlur result="blurOut" stdDeviation="2.0"/><feColorMatrix in="blurOut" result="blurOut2" type="matrix" values="0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 .4 0"/><feOffset dx="4.0" dy="4.0" in="blurOut2" result="blurOut3"/><feBlend in="SourceGraphic" in2="blurOut3" mode="normal"/></filter></defs><g><text fill="#000000" font-family="sans-serif" font-size="18" lengthAdjust="spacingAndGlyphs" textLength="338" x="160" y="26.708">CoarseGrainedExecutorBackend的启动</text><line style="stroke: #A80036; stroke-width: 1.0; stroke-dasharray: 5.0,5.0;" x1="116" x2="116" y1="73.25" y2="376.3125"/><line style="stroke: #A80036; stroke-width: 1.0; stroke-dasharray: 5.0,5.0;" x1="222.5" x2="222.5" y1="73.25" y2="376.3125"/><line style="stroke: #A80036; stroke-width: 1.0; stroke-dasharray: 5.0,5.0;" x1="358.5" x2="358.5" y1="73.25" y2="376.3125"/><line style="stroke: #A80036; stroke-width: 1.0; stroke-dasharray: 5.0,5.0;" x1="494.5" x2="494.5" y1="73.25" y2="376.3125"/><rect fill="#FEFECE" filter="url(#f6cssshobinod)" height="30.2969" style="stroke: #A80036; stroke-width: 1.5;" width="49" x="90" y="37.9531"/><text fill="#000000" font-family="sans-serif" font-size="14" lengthAdjust="spacingAndGlyphs" textLength="35" x="97" y="57.9482">Work</text><rect fill="#FEFECE" filter="url(#f6cssshobinod)" height="30.2969" style="stroke: #A80036; stroke-width: 1.5;" width="49" x="90" y="375.3125"/><text fill="#000000" font-family="sans-serif" font-size="14" lengthAdjust="spacingAndGlyphs" textLength="35" x="97" y="395.3076">Work</text><rect fill="#FEFECE" filter="url(#f6cssshobinod)" height="30.2969" style="stroke: #A80036; stroke-width: 1.5;" width="126" x="157.5" y="37.9531"/><text fill="#000000" font-family="sans-serif" font-size="14" lengthAdjust="spacingAndGlyphs" textLength="112" x="164.5" y="57.9482">ExecutorRunner</text><rect fill="#FEFECE" filter="url(#f6cssshobinod)" height="30.2969" style="stroke: #A80036; stroke-width: 1.5;" width="126" x="157.5" y="375.3125"/><text fill="#000000" font-family="sans-serif" font-size="14" lengthAdjust="spacingAndGlyphs" textLength="112" x="164.5" y="395.3076">ExecutorRunner</text><rect fill="#FEFECE" filter="url(#f6cssshobinod)" height="30.2969" style="stroke: #A80036; stroke-width: 1.5;" width="118" x="297.5" y="37.9531"/><text fill="#000000" font-family="sans-serif" font-size="14" lengthAdjust="spacingAndGlyphs" textLength="104" x="304.5" y="57.9482">ProcessBuilder</text><rect fill="#FEFECE" filter="url(#f6cssshobinod)" height="30.2969" style="stroke: #A80036; stroke-width: 1.5;" width="118" x="297.5" y="375.3125"/><text fill="#000000" font-family="sans-serif" font-size="14" lengthAdjust="spacingAndGlyphs" textLength="104" x="304.5" y="395.3076">ProcessBuilder</text><rect fill="#FEFECE" filter="url(#f6cssshobinod)" height="30.2969" style="stroke: #A80036; stroke-width: 1.5;" width="127" x="429.5" y="37.9531"/><text fill="#000000" font-family="sans-serif" font-size="14" lengthAdjust="spacingAndGlyphs" textLength="113" x="436.5" y="57.9482">Linux_Command</text><rect fill="#FEFECE" filter="url(#f6cssshobinod)" height="30.2969" style="stroke: #A80036; stroke-width: 1.5;" width="127" x="429.5" y="375.3125"/><text fill="#000000" font-family="sans-serif" font-size="14" lengthAdjust="spacingAndGlyphs" textLength="113" x="436.5" y="395.3076">Linux_Command</text><path d="M8,88.25 L8,113.25 L221,113.25 L221,98.25 L211,88.25 L8,88.25 " fill="#FBFB77" filter="url(#f6cssshobinod)" style="stroke: #A80036; stroke-width: 1.0;"/><path d="M211,88.25 L211,98.25 L221,98.25 L211,88.25 " fill="#FBFB77" style="stroke: #A80036; stroke-width: 1.0;"/><text fill="#000000" font-family="sans-serif" font-size="13" lengthAdjust="spacingAndGlyphs" textLength="192" x="14" y="105.3169">receive(case LaunchExecutor)</text><polygon fill="#A80036" points="210.5,139.5156,220.5,143.5156,210.5,147.5156,214.5,143.5156" style="stroke: #A80036; stroke-width: 1.0;"/><line style="stroke: #A80036; stroke-width: 1.0;" x1="116.5" x2="216.5" y1="143.5156" y2="143.5156"/><text fill="#000000" font-family="sans-serif" font-size="13" lengthAdjust="spacingAndGlyphs" textLength="82" x="123.5" y="138.4497">创建Executor</text><path d="M195,156.5156 L195,181.5156 L246,181.5156 L246,166.5156 L236,156.5156 L195,156.5156 " fill="#FBFB77" filter="url(#f6cssshobinod)" style="stroke: #A80036; stroke-width: 1.0;"/><path d="M236,156.5156 L236,166.5156 L246,166.5156 L236,156.5156 " fill="#FBFB77" style="stroke: #A80036; stroke-width: 1.0;"/><text fill="#000000" font-family="sans-serif" font-size="13" lengthAdjust="spacingAndGlyphs" textLength="30" x="201" y="173.5825">start</text><path d="M141,195.6484 L141,220.6484 L299,220.6484 L299,205.6484 L289,195.6484 L141,195.6484 " fill="#FBFB77" filter="url(#f6cssshobinod)" style="stroke: #A80036; stroke-width: 1.0;"/><path d="M289,195.6484 L289,205.6484 L299,205.6484 L289,195.6484 " fill="#FBFB77" style="stroke: #A80036; stroke-width: 1.0;"/><text fill="#000000" font-family="sans-serif" font-size="13" lengthAdjust="spacingAndGlyphs" textLength="137" x="147" y="212.7153">fetchAndRunExecutor</text><polygon fill="#A80036" points="346.5,246.9141,356.5,250.9141,346.5,254.9141,350.5,250.9141" style="stroke: #A80036; stroke-width: 1.0;"/><line style="stroke: #A80036; stroke-width: 1.0;" x1="222.5" x2="352.5" y1="250.9141" y2="250.9141"/><text fill="#000000" font-family="sans-serif" font-size="13" lengthAdjust="spacingAndGlyphs" textLength="26" x="229.5" y="245.8481">调用</text><path d="M331,263.9141 L331,288.9141 L382,288.9141 L382,273.9141 L372,263.9141 L331,263.9141 " fill="#FBFB77" filter="url(#f6cssshobinod)" style="stroke: #A80036; stroke-width: 1.0;"/><path d="M372,263.9141 L372,273.9141 L382,273.9141 L372,263.9141 " fill="#FBFB77" style="stroke: #A80036; stroke-width: 1.0;"/><text fill="#000000" font-family="sans-serif" font-size="13" lengthAdjust="spacingAndGlyphs" textLength="30" x="337" y="280.981">start</text><polygon fill="#A80036" points="483,315.1797,493,319.1797,483,323.1797,487,319.1797" style="stroke: #A80036; stroke-width: 1.0;"/><line style="stroke: #A80036; stroke-width: 1.0;" x1="358.5" x2="489" y1="319.1797" y2="319.1797"/><text fill="#000000" font-family="sans-serif" font-size="13" lengthAdjust="spacingAndGlyphs" textLength="26" x="365.5" y="314.1138">调用</text><path d="M340,332.1797 L340,357.1797 L646,357.1797 L646,342.1797 L636,332.1797 L340,332.1797 " fill="#FBFB77" filter="url(#f6cssshobinod)" style="stroke: #A80036; stroke-width: 1.0;"/><path d="M636,332.1797 L636,342.1797 L646,342.1797 L636,332.1797 " fill="#FBFB77" style="stroke: #A80036; stroke-width: 1.0;"/><text fill="#000000" font-family="sans-serif" font-size="13" lengthAdjust="spacingAndGlyphs" textLength="285" x="346" y="349.2466">java -server CoarseGrainedExecutorBackend</text><!--MD5=[9d5b8a3ee26235574be19a81be0b6b66]
@startuml
title:CoarseGrainedExecutorBackend的启动

note over Work: receive(case LaunchExecutor)
Work -> ExecutorRunner: 创建Executor
note over ExecutorRunner: start
note over ExecutorRunner: fetchAndRunExecutor
ExecutorRunner -> ProcessBuilder: 调用
note over ProcessBuilder: start
ProcessBuilder -> Linux_Command: 调用
note over Linux_Command: java -server CoarseGrainedExecutorBackend
@enduml

PlantUML version 1.2020.02beta5(Unknown compile time)
(GPL source distribution)
Java Runtime: Java(TM) SE Runtime Environment
JVM: Java HotSpot(TM) 64-Bit Server VM
Java Version: 1.7.0_25-b15
Operating System: Linux
Default Encoding: UTF-8
Language: en
Country: US
--></g></svg>'>

<h3 id="2-2-详细过程"><a href="#2-2-详细过程" class="headerlink" title="2.2 详细过程"></a>2.2 详细过程</h3><p>在Worker进程收到LauncherExecutor消息后，Worker 会将消息封装为<strong>ExecutorRunner</strong>对象，调用其start方法。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">receive</span></span>: <span class="type">PartialFunction</span>[<span class="type">Any</span>, <span class="type">Unit</span>] = synchronized &#123;</span><br><span class="line">   <span class="keyword">case</span> <span class="type">LaunchExecutor</span>(masterUrl, appId, execId, appDesc, cores_, memory_) =&gt;</span><br><span class="line">     <span class="keyword">if</span> (masterUrl != activeMasterUrl) &#123;</span><br><span class="line">       logWarning(<span class="string">"Invalid Master ("</span> + masterUrl + <span class="string">") attempted to launch executor."</span>)</span><br><span class="line">     &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">       <span class="keyword">try</span> &#123;</span><br><span class="line">        ....</span><br><span class="line">         <span class="keyword">val</span> manager = <span class="keyword">new</span> <span class="type">ExecutorRunner</span>(</span><br><span class="line">           appId,</span><br><span class="line">           execId,</span><br><span class="line">           appDesc.copy(command = <span class="type">Worker</span>.maybeUpdateSSLSettings(appDesc.command, conf)),</span><br><span class="line">           cores_,</span><br><span class="line">           memory_,</span><br><span class="line">           self,</span><br><span class="line">           workerId,</span><br><span class="line">           host,</span><br><span class="line">           webUi.boundPort,</span><br><span class="line">           publicAddress,</span><br><span class="line">           sparkHome,</span><br><span class="line">           executorDir,</span><br><span class="line">           workerUri,</span><br><span class="line">           conf,</span><br><span class="line">           appLocalDirs, <span class="type">ExecutorState</span>.<span class="type">RUNNING</span>)</span><br><span class="line">         executors(appId + <span class="string">"/"</span> + execId) = manager</span><br><span class="line">         manager.start()</span><br><span class="line">         coresUsed += cores_</span><br><span class="line">         memoryUsed += memory_</span><br><span class="line">         sendToMaster(<span class="type">ExecutorStateChanged</span>(appId, execId, manager.state, <span class="type">None</span>, <span class="type">None</span>))</span><br><span class="line">       &#125; <span class="keyword">catch</span> &#123;</span><br><span class="line">        ....</span><br><span class="line">       &#125;</span><br><span class="line">     &#125;</span><br><span class="line">    ......</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>start方法启动线程，调用ExecutorRunner的fetchAndRunExecutor方法，</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span>[worker] <span class="function"><span class="keyword">def</span> <span class="title">start</span></span>() &#123;</span><br><span class="line">  workerThread = <span class="keyword">new</span> <span class="type">Thread</span>(<span class="string">"ExecutorRunner for "</span> + fullId) &#123;</span><br><span class="line">    <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">run</span></span>() &#123; fetchAndRunExecutor() &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  workerThread.start()</span><br><span class="line">  shutdownHook = <span class="type">ShutdownHookManager</span>.addShutdownHook &#123; () =&gt;</span><br><span class="line">    <span class="keyword">if</span> (state == <span class="type">ExecutorState</span>.<span class="type">RUNNING</span>) &#123;</span><br><span class="line">      state = <span class="type">ExecutorState</span>.<span class="type">FAILED</span></span><br><span class="line">    &#125;</span><br><span class="line">    killProcess(<span class="type">Some</span>(<span class="string">"Worker shutting down"</span>)) &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>fetchAndRunExecutor方法中将收到的信息拼接为Linux命令，然后使用<strong>ProcessBuilder</strong>执行Linux命令启动CoarseGrainedExecutorBackend</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">fetchAndRunExecutor</span></span>() &#123;</span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">    <span class="comment">// Launch the process</span></span><br><span class="line">    <span class="keyword">val</span> builder = <span class="type">CommandUtils</span>.buildProcessBuilder(appDesc.command, <span class="keyword">new</span> <span class="type">SecurityManager</span>(conf),</span><br><span class="line">      memory, sparkHome.getAbsolutePath, substituteVariables)</span><br><span class="line">    <span class="keyword">val</span> command = builder.command()</span><br><span class="line">    <span class="keyword">val</span> formattedCommand = command.asScala.mkString(<span class="string">"\""</span>, <span class="string">"\" \""</span>, <span class="string">"\""</span>)</span><br><span class="line">    logInfo(<span class="string">s"Launch command: <span class="subst">$formattedCommand</span>"</span>)</span><br><span class="line"></span><br><span class="line">    builder.directory(executorDir)</span><br><span class="line">    builder.environment.put(<span class="string">"SPARK_EXECUTOR_DIRS"</span>, appLocalDirs.mkString(<span class="type">File</span>.pathSeparator))</span><br><span class="line">    <span class="comment">// In case we are running this from within the Spark Shell, avoid creating a "scala"</span></span><br><span class="line">    <span class="comment">// parent process for the executor command</span></span><br><span class="line">    builder.environment.put(<span class="string">"SPARK_LAUNCH_WITH_SCALA"</span>, <span class="string">"0"</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Add webUI log urls</span></span><br><span class="line">    <span class="keyword">val</span> baseUrl =</span><br><span class="line">      <span class="keyword">if</span> (conf.getBoolean(<span class="string">"spark.ui.reverseProxy"</span>, <span class="literal">false</span>)) &#123;</span><br><span class="line">        <span class="string">s"/proxy/<span class="subst">$workerId</span>/logPage/?appId=<span class="subst">$appId</span>&amp;executorId=<span class="subst">$execId</span>&amp;logType="</span></span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="string">s"http://<span class="subst">$publicAddress</span>:<span class="subst">$webUiPort</span>/logPage/?appId=<span class="subst">$appId</span>&amp;executorId=<span class="subst">$execId</span>&amp;logType="</span></span><br><span class="line">      &#125;</span><br><span class="line">    builder.environment.put(<span class="string">"SPARK_LOG_URL_STDERR"</span>, <span class="string">s"<span class="subst">$&#123;baseUrl&#125;</span>stderr"</span>)</span><br><span class="line">    builder.environment.put(<span class="string">"SPARK_LOG_URL_STDOUT"</span>, <span class="string">s"<span class="subst">$&#123;baseUrl&#125;</span>stdout"</span>)</span><br><span class="line"></span><br><span class="line">    process = builder.start()</span><br><span class="line">    <span class="keyword">val</span> header = <span class="string">"Spark Executor Command: %s\n%s\n\n"</span>.format(</span><br><span class="line">      formattedCommand, <span class="string">"="</span> * <span class="number">40</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Redirect its stdout and stderr to files</span></span><br><span class="line">    <span class="keyword">val</span> stdout = <span class="keyword">new</span> <span class="type">File</span>(executorDir, <span class="string">"stdout"</span>)</span><br><span class="line">    stdoutAppender = <span class="type">FileAppender</span>(process.getInputStream, stdout, conf)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> stderr = <span class="keyword">new</span> <span class="type">File</span>(executorDir, <span class="string">"stderr"</span>)</span><br><span class="line">    <span class="type">Files</span>.write(header, stderr, <span class="type">StandardCharsets</span>.<span class="type">UTF_8</span>)</span><br><span class="line">    stderrAppender = <span class="type">FileAppender</span>(process.getErrorStream, stderr, conf)</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Wait for it to exit; executor may exit with code 0 (when driver instructs it to shutdown)</span></span><br><span class="line">    <span class="comment">// or with nonzero exit code</span></span><br><span class="line">    <span class="keyword">val</span> exitCode = process.waitFor()</span><br><span class="line">    state = <span class="type">ExecutorState</span>.<span class="type">EXITED</span></span><br><span class="line">    <span class="keyword">val</span> message = <span class="string">"Command exited with code "</span> + exitCode</span><br><span class="line">    worker.send(<span class="type">ExecutorStateChanged</span>(appId, execId, state, <span class="type">Some</span>(message), <span class="type">Some</span>(exitCode)))</span><br><span class="line">  &#125; <span class="keyword">catch</span> &#123;</span><br><span class="line">    <span class="keyword">case</span> interrupted: <span class="type">InterruptedException</span> =&gt;</span><br><span class="line">      logInfo(<span class="string">"Runner thread for executor "</span> + fullId + <span class="string">" interrupted"</span>)</span><br><span class="line">      state = <span class="type">ExecutorState</span>.<span class="type">KILLED</span></span><br><span class="line">      killProcess(<span class="type">None</span>)</span><br><span class="line">    <span class="keyword">case</span> e: <span class="type">Exception</span> =&gt;</span><br><span class="line">      logError(<span class="string">"Error running executor"</span>, e)</span><br><span class="line">      state = <span class="type">ExecutorState</span>.<span class="type">FAILED</span></span><br><span class="line">      killProcess(<span class="type">Some</span>(e.toString))</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>ProcessBuilder执行的Linux命令大致如下</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">.&#x2F;jdk-8u161-linux-x64.tar.gz&#x2F;jdk1.8.0_161&#x2F;bin&#x2F;java </span><br><span class="line">-server -Xmx4096m </span><br><span class="line">-Djava.io.tmpdir&#x3D;&#x2F;home&#x2F;hadoop&#x2F;tmp&#x2F;nm-local-dir&#x2F;usercache&#x2F;xxxxx&#x2F;appcache&#x2F;application_1519271509270_0745&#x2F;container_1519271509270_0745_01_000003&#x2F;tmp </span><br><span class="line">&#39;-Dspark.ui.port&#x3D;0&#39; </span><br><span class="line">&#39;-Dspark.driver.port&#x3D;37011&#39; </span><br><span class="line">-Dspark.yarn.app.container.log.dir&#x3D;&#x2F;home&#x2F;hadoop&#x2F;hadoop-2.7.3&#x2F;logs&#x2F;userlogs&#x2F;application_1519271509270_0745&#x2F;container_1519271509270_0745_01_000003 </span><br><span class="line">-XX:OnOutOfMemoryError&#x3D;&#39;kill %p&#39; </span><br><span class="line">org.apache.spark.executor.CoarseGrainedExecutorBackend </span><br><span class="line">--driver-url spark:&#x2F;&#x2F;CoarseGrainedScheduler@10.100.1.131:37011 </span><br><span class="line">--executor-id 2 </span><br><span class="line">--hostname slave131 </span><br><span class="line">--cores 8 </span><br><span class="line">--app-id application_1519271509270_0745 </span><br><span class="line">--user-class-path file:&#x2F;home&#x2F;hadoop&#x2F;tmp&#x2F;nm-local-dir&#x2F;usercache&#x2F;xxxxx&#x2F;appcache&#x2F;application_1519271509270_0745&#x2F;container_1519271509270_0745_01_000003&#x2F;__app__.jar </span><br><span class="line">1&gt;&#x2F;home&#x2F;hadoop&#x2F;hadoop-2.7.3&#x2F;logs&#x2F;userlogs&#x2F;application_1519271509270_0745&#x2F;container_1519271509270_0745_01_000003&#x2F;stdout </span><br><span class="line">2&gt;&#x2F;home&#x2F;hadoop&#x2F;hadoop-2.7.3&#x2F;logs&#x2F;userlogs&#x2F;application_1519271509270_0745&#x2F;container_1519271509270_0745_01_000003&#x2F;stderr</span><br></pre></td></tr></table></figure>

<p>java命令会调用CoarseGrainedExecutorBackend的main方法，main方法中处理命令行传入的参数，将参赛传给run方法，然后run方法中创建RpcEnv，并注册CoarseGrainedExecutorBackend</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">run</span></span>(</span><br><span class="line">      driverUrl: <span class="type">String</span>,</span><br><span class="line">      executorId: <span class="type">String</span>,</span><br><span class="line">      hostname: <span class="type">String</span>,</span><br><span class="line">      cores: <span class="type">Int</span>,</span><br><span class="line">      appId: <span class="type">String</span>,</span><br><span class="line">      workerUrl: <span class="type">Option</span>[<span class="type">String</span>],</span><br><span class="line">      userClassPath: <span class="type">Seq</span>[<span class="type">URL</span>]) &#123;</span><br><span class="line"></span><br><span class="line">    <span class="type">Utils</span>.initDaemon(log)</span><br><span class="line"></span><br><span class="line">    <span class="type">SparkHadoopUtil</span>.get.runAsSparkUser &#123; () =&gt;</span><br><span class="line">      <span class="comment">// Debug code</span></span><br><span class="line">      <span class="type">Utils</span>.checkHost(hostname)</span><br><span class="line"></span><br><span class="line">      <span class="comment">// Bootstrap to fetch the driver's Spark properties.</span></span><br><span class="line">      <span class="keyword">val</span> executorConf = <span class="keyword">new</span> <span class="type">SparkConf</span></span><br><span class="line">      <span class="keyword">val</span> port = executorConf.getInt(<span class="string">"spark.executor.port"</span>, <span class="number">0</span>)</span><br><span class="line">      <span class="keyword">val</span> fetcher = <span class="type">RpcEnv</span>.create(</span><br><span class="line">        <span class="string">"driverPropsFetcher"</span>,</span><br><span class="line">        hostname,</span><br><span class="line">        port,</span><br><span class="line">        executorConf,</span><br><span class="line">        <span class="keyword">new</span> <span class="type">SecurityManager</span>(executorConf),</span><br><span class="line">        clientMode = <span class="literal">true</span>)</span><br><span class="line">      <span class="keyword">val</span> driver = fetcher.setupEndpointRefByURI(driverUrl)</span><br><span class="line">      <span class="keyword">val</span> cfg = driver.askSync[<span class="type">SparkAppConfig</span>](<span class="type">RetrieveSparkAppConfig</span>)</span><br><span class="line">      <span class="keyword">val</span> props = cfg.sparkProperties ++ <span class="type">Seq</span>[(<span class="type">String</span>, <span class="type">String</span>)]((<span class="string">"spark.app.id"</span>, appId))</span><br><span class="line">      fetcher.shutdown()</span><br><span class="line"></span><br><span class="line">      <span class="comment">// Create SparkEnv using properties we fetched from the driver.</span></span><br><span class="line">      <span class="keyword">val</span> driverConf = <span class="keyword">new</span> <span class="type">SparkConf</span>()</span><br><span class="line">      <span class="keyword">for</span> ((key, value) &lt;- props) &#123;</span><br><span class="line">        <span class="comment">// this is required for SSL in standalone mode</span></span><br><span class="line">        <span class="keyword">if</span> (<span class="type">SparkConf</span>.isExecutorStartupConf(key)) &#123;</span><br><span class="line">          driverConf.setIfMissing(key, value)</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">          driverConf.set(key, value)</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">if</span> (driverConf.contains(<span class="string">"spark.yarn.credentials.file"</span>)) &#123;</span><br><span class="line">        logInfo(<span class="string">"Will periodically update credentials from: "</span> +</span><br><span class="line">          driverConf.get(<span class="string">"spark.yarn.credentials.file"</span>))</span><br><span class="line">        <span class="type">SparkHadoopUtil</span>.get.startCredentialUpdater(driverConf)</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">      <span class="keyword">val</span> env = <span class="type">SparkEnv</span>.createExecutorEnv(</span><br><span class="line">        driverConf, executorId, hostname, port, cores, cfg.ioEncryptionKey, isLocal = <span class="literal">false</span>)</span><br><span class="line"></span><br><span class="line">      env.rpcEnv.setupEndpoint(<span class="string">"Executor"</span>, <span class="keyword">new</span> <span class="type">CoarseGrainedExecutorBackend</span>(</span><br><span class="line">        env.rpcEnv, driverUrl, executorId, hostname, cores, userClassPath, env))</span><br><span class="line">      workerUrl.foreach &#123; url =&gt;</span><br><span class="line">        env.rpcEnv.setupEndpoint(<span class="string">"WorkerWatcher"</span>, <span class="keyword">new</span> <span class="type">WorkerWatcher</span>(env.rpcEnv, url))</span><br><span class="line">      &#125;</span><br><span class="line">      env.rpcEnv.awaitTermination()</span><br><span class="line">      <span class="type">SparkHadoopUtil</span>.get.stopCredentialUpdater()</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>

<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="http://blog.csdn.net/u011564172/article/details/69703662" target="_blank" rel="noopener">Spark 任务调度之启动CoarseGrainedExecutorBackend</a></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://longzl2015.github.io/2018/06/04/spark/Spark%E6%89%A7%E8%A1%8C%E9%80%BB%E8%BE%91/4_%E5%90%AF%E5%8A%A8Executor/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="zhoul">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2018/06/04/spark/Spark%E6%89%A7%E8%A1%8C%E9%80%BB%E8%BE%91/4_%E5%90%AF%E5%8A%A8Executor/" class="post-title-link" itemprop="url">spark4-启动Executor</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2018-06-04 23:22:04" itemprop="dateCreated datePublished" datetime="2018-06-04T23:22:04+08:00">2018-06-04</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-02-27 17:16:07" itemprop="dateModified" datetime="2020-02-27T17:16:07+08:00">2020-02-27</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/spark/" itemprop="url" rel="index">
                    <span itemprop="name">spark</span>
                  </a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/spark/%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/" itemprop="url" rel="index">
                    <span itemprop="name">源码解析</span>
                  </a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="fa fa-comment-o"></i>
      </span>
      <span class="post-meta-item-text">Disqus：</span>
    
    <a title="disqus" href="/2018/06/04/spark/Spark%E6%89%A7%E8%A1%8C%E9%80%BB%E8%BE%91/4_%E5%90%AF%E5%8A%A8Executor/#comments" itemprop="discussionUrl">
      <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2018/06/04/spark/Spark执行逻辑/4_启动Executor/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="启动Executor"><a href="#启动Executor" class="headerlink" title="启动Executor"></a>启动Executor</h1><h2 id="一、回顾"><a href="#一、回顾" class="headerlink" title="一、回顾"></a>一、回顾</h2><p>在《1、提交driver》已经介绍过，org.apache.spark.deploy.master.Master 的 receiveAndReply方法接收Client发送的消息RequestSubmitDriver。</p>
<p>前面已经介绍了schedule()中launchDriver的流程，即《2、启动driver》。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">receiveAndReply</span></span>(context: <span class="type">RpcCallContext</span>): <span class="type">PartialFunction</span>[<span class="type">Any</span>, <span class="type">Unit</span>] = &#123;</span><br><span class="line">    <span class="keyword">case</span> <span class="type">RequestSubmitDriver</span>(description) =&gt;</span><br><span class="line">      <span class="keyword">if</span> (state != <span class="type">RecoveryState</span>.<span class="type">ALIVE</span>) &#123;</span><br><span class="line">        <span class="keyword">val</span> msg = <span class="string">s"<span class="subst">$&#123;Utils.BACKUP_STANDALONE_MASTER_PREFIX&#125;</span>: <span class="subst">$state</span>. "</span> +</span><br><span class="line">          <span class="string">"Can only accept driver submissions in ALIVE state."</span></span><br><span class="line">        context.reply(<span class="type">SubmitDriverResponse</span>(self, <span class="literal">false</span>, <span class="type">None</span>, msg))</span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        logInfo(<span class="string">"Driver submitted "</span> + description.command.mainClass)</span><br><span class="line">        <span class="keyword">val</span> driver = createDriver(description)</span><br><span class="line">        <span class="comment">// 持久化Driver 用于master recovery 时恢复Driver</span></span><br><span class="line">        persistenceEngine.addDriver(driver)</span><br><span class="line">        <span class="comment">// 注册 Driver</span></span><br><span class="line">        waitingDrivers += driver</span><br><span class="line">        drivers.add(driver)</span><br><span class="line">        <span class="comment">// launch Driver 和 Executor</span></span><br><span class="line">        schedule()</span><br><span class="line">        context.reply(<span class="type">SubmitDriverResponse</span>(self, <span class="literal">true</span>, <span class="type">Some</span>(driver.id),</span><br><span class="line">          <span class="string">s"Driver successfully submitted as <span class="subst">$&#123;driver.id&#125;</span>"</span>))</span><br><span class="line">      &#125;</span><br><span class="line">    ...</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>

<p>本篇继续介绍schedule()方法另一个部分，<strong>Launch Executor</strong></p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">schedule</span></span>(): <span class="type">Unit</span> = &#123;</span><br><span class="line">  <span class="keyword">if</span> (state != <span class="type">RecoveryState</span>.<span class="type">ALIVE</span>) &#123;</span><br><span class="line">    <span class="keyword">return</span></span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// 打乱Worker顺序，避免Driver过度集中</span></span><br><span class="line">  <span class="keyword">val</span> shuffledAliveWorkers = <span class="type">Random</span>.shuffle(workers.toSeq.filter(_.state == <span class="type">WorkerState</span>.<span class="type">ALIVE</span>))</span><br><span class="line">  <span class="keyword">val</span> numWorkersAlive = shuffledAliveWorkers.size</span><br><span class="line">  <span class="keyword">var</span> curPos = <span class="number">0</span></span><br><span class="line">  <span class="comment">// 遍历Worker。如果Work节点剩余内存和core足够，启动Driver</span></span><br><span class="line">  <span class="comment">// deploy-mode=cluster模式下，注册的Driver信息都在waitingDrivers中</span></span><br><span class="line">  <span class="keyword">for</span> (driver &lt;- waitingDrivers.toList) &#123; <span class="comment">// iterate over a copy of waitingDrivers</span></span><br><span class="line">    <span class="keyword">var</span> launched = <span class="literal">false</span></span><br><span class="line">    <span class="keyword">var</span> numWorkersVisited = <span class="number">0</span></span><br><span class="line">    <span class="keyword">while</span> (numWorkersVisited &lt; numWorkersAlive &amp;&amp; !launched) &#123;</span><br><span class="line">      <span class="keyword">val</span> worker = shuffledAliveWorkers(curPos)</span><br><span class="line">      numWorkersVisited += <span class="number">1</span></span><br><span class="line">      <span class="keyword">if</span> (worker.memoryFree &gt;= driver.desc.mem &amp;&amp; worker.coresFree &gt;= driver.desc.cores) &#123;</span><br><span class="line">        <span class="comment">//启动Driver  </span></span><br><span class="line">        launchDriver(worker, driver)</span><br><span class="line">        waitingDrivers -= driver</span><br><span class="line">        launched = <span class="literal">true</span></span><br><span class="line">      &#125;</span><br><span class="line">      curPos = (curPos + <span class="number">1</span>) % numWorkersAlive</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">//启动 Executor</span></span><br><span class="line">  startExecutorsOnWorkers()</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="二、启动Executor前的准备"><a href="#二、启动Executor前的准备" class="headerlink" title="二、启动Executor前的准备"></a>二、启动Executor前的准备</h2><p>查看<strong>startExecutorsOnWorkers</strong>方法 </p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">startExecutorsOnWorkers</span></span>(): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="comment">// waitingApps 就是 《3、注册App》注册的 ApplicationInfo ，主要是core和memory</span></span><br><span class="line">    <span class="comment">// 该过程就是简单的FIFO</span></span><br><span class="line">    <span class="keyword">for</span> (app &lt;- waitingApps <span class="keyword">if</span> app.coresLeft &gt; <span class="number">0</span>) &#123;</span><br><span class="line">      <span class="keyword">val</span> coresPerExecutor: <span class="type">Option</span>[<span class="type">Int</span>] = app.desc.coresPerExecutor</span><br><span class="line">      <span class="comment">// 选出剩余core和memory满足Executor启动参数的work</span></span><br><span class="line">      <span class="keyword">val</span> usableWorkers = workers.toArray.filter(_.state == <span class="type">WorkerState</span>.<span class="type">ALIVE</span>)</span><br><span class="line">        .filter(worker =&gt; worker.memoryFree &gt;= app.desc.memoryPerExecutorMB &amp;&amp;</span><br><span class="line">          worker.coresFree &gt;= coresPerExecutor.getOrElse(<span class="number">1</span>))</span><br><span class="line">        .sortBy(_.coresFree).reverse</span><br><span class="line">      <span class="comment">//spark Executor资源调度</span></span><br><span class="line">      <span class="comment">//assignedCores 为每个Worker分配的core数</span></span><br><span class="line">      <span class="keyword">val</span> assignedCores = scheduleExecutorsOnWorkers(app, usableWorkers, spreadOutApps)</span><br><span class="line"></span><br><span class="line">      <span class="comment">// 根据分配好的assignedCores，在相应的worker节点启动Executor</span></span><br><span class="line">      <span class="keyword">for</span> (pos &lt;- <span class="number">0</span> until usableWorkers.length <span class="keyword">if</span> assignedCores(pos) &gt; <span class="number">0</span>) &#123;</span><br><span class="line">        allocateWorkerResourceToExecutors(</span><br><span class="line">          app, assignedCores(pos), coresPerExecutor, usableWorkers(pos))</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>

<p>如上图注释，waitingApps信息主要是我们通过命令行传入的core和memory信息，startExecutorsOnWorkers方法的职责是调度<strong>waitingApps</strong>，即将core和memory分配到具体的Worker，<a href="http://blog.csdn.net/u011564172/article/details/69062339" target="_blank" rel="noopener">Spark 任务调度之Register App</a>介绍了Driver注册app的流程。 </p>
<p><strong>scheduleExecutorsOnWorkers</strong>方法中，可以使用<strong>spreadOutApps</strong>算法分配资源，即Executor分布在尽可能多的Worker节点上，相反，也支持Executor聚集在某些Worker节点上，通过参数<strong>spark.deploy.spreadOut</strong>配置，默认为true，如下 </p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">val</span> spreadOutApps = conf.getBoolean(<span class="string">"spark.deploy.spreadOut"</span>, <span class="literal">true</span>)</span><br></pre></td></tr></table></figure>

<h2 id="三、Launch-Executor"><a href="#三、Launch-Executor" class="headerlink" title="三、Launch Executor"></a>三、Launch Executor</h2><p><strong>startExecutorsOnWorkers</strong>方法中，最后调用allocateWorkerResourceToExecutors方法，如下 </p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">allocateWorkerResourceToExecutors</span></span>(</span><br><span class="line">     app: <span class="type">ApplicationInfo</span>,</span><br><span class="line">     assignedCores: <span class="type">Int</span>,</span><br><span class="line">     coresPerExecutor: <span class="type">Option</span>[<span class="type">Int</span>],</span><br><span class="line">     worker: <span class="type">WorkerInfo</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">   <span class="comment">// 计算Executor总数，总数= 分配的总core数 / 一个Executor所需的core数</span></span><br><span class="line">   <span class="comment">// 如果Executor所需的core没有指定，这总core数仅分配给一个Executor</span></span><br><span class="line">   <span class="keyword">val</span> numExecutors = coresPerExecutor.map &#123; assignedCores / _ &#125;.getOrElse(<span class="number">1</span>)</span><br><span class="line">   <span class="keyword">val</span> coresToAssign = coresPerExecutor.getOrElse(assignedCores)</span><br><span class="line">   <span class="keyword">for</span> (i &lt;- <span class="number">1</span> to numExecutors) &#123;</span><br><span class="line">     <span class="keyword">val</span> exec = app.addExecutor(worker, coresToAssign)</span><br><span class="line">     <span class="comment">// 启动</span></span><br><span class="line">     launchExecutor(worker, exec)</span><br><span class="line">     app.state = <span class="type">ApplicationState</span>.<span class="type">RUNNING</span></span><br><span class="line">   &#125;</span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure>

<p>上图最后处调用<strong>launchExecutor</strong>方法，如下 </p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">launchExecutor</span></span>(worker: <span class="type">WorkerInfo</span>, exec: <span class="type">ExecutorDesc</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">    logInfo(<span class="string">"Launching executor "</span> + exec.fullId + <span class="string">" on worker "</span> + worker.id)</span><br><span class="line">    worker.addExecutor(exec)</span><br><span class="line">    <span class="comment">//给Worker发送LaunchExecutor信息</span></span><br><span class="line">    worker.endpoint.send(<span class="type">LaunchExecutor</span>(masterUrl,</span><br><span class="line">      exec.application.id, exec.id, exec.application.desc, exec.cores, exec.memory))</span><br><span class="line">    <span class="comment">//给Driver发送Executor信息，用于Driver的4040端口显示</span></span><br><span class="line">    exec.application.driver.send(</span><br><span class="line">      <span class="type">ExecutorAdded</span>(exec.id, worker.id, worker.hostPort, exec.cores, exec.memory))</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>

<p>如上图注释，给Worker节点发送LaunchExecutor消息，Worker节点收到消息，Launch Executor部分就结束了，下一部分具体讲Executor在Worker节点的启动，最后，Worker接收LaunchExecutor消息对应代码如下:</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">case</span> <span class="type">LaunchExecutor</span>(masterUrl, appId, execId, appDesc, cores_, memory_) =&gt;</span><br><span class="line">     <span class="keyword">if</span> (masterUrl != activeMasterUrl) &#123;</span><br><span class="line">       logWarning(<span class="string">"Invalid Master ("</span> + masterUrl + <span class="string">") attempted to launch executor."</span>)</span><br><span class="line">     &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">       <span class="keyword">try</span> &#123;</span><br><span class="line">         logInfo(<span class="string">"Asked to launch executor %s/%d for %s"</span>.format(appId, execId, appDesc.name))</span><br><span class="line"></span><br><span class="line">         <span class="comment">// 创建Executor运行目录</span></span><br><span class="line">         <span class="keyword">val</span> executorDir = <span class="keyword">new</span> <span class="type">File</span>(workDir, appId + <span class="string">"/"</span> + execId)</span><br><span class="line">         <span class="keyword">if</span> (!executorDir.mkdirs()) &#123;</span><br><span class="line">           <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">IOException</span>(<span class="string">"Failed to create directory "</span> + executorDir)</span><br><span class="line">         &#125;</span><br><span class="line">           </span><br><span class="line">         <span class="keyword">val</span> appLocalDirs = appDirectories.getOrElse(appId,</span><br><span class="line">           <span class="type">Utils</span>.getOrCreateLocalRootDirs(conf).map &#123; dir =&gt;</span><br><span class="line">             <span class="keyword">val</span> appDir = <span class="type">Utils</span>.createDirectory(dir, namePrefix = <span class="string">"executor"</span>)</span><br><span class="line">             <span class="type">Utils</span>.chmod700(appDir)</span><br><span class="line">             appDir.getAbsolutePath()</span><br><span class="line">           &#125;.toSeq)</span><br><span class="line">         appDirectories(appId) = appLocalDirs</span><br><span class="line">         <span class="comment">// 构造Executor</span></span><br><span class="line">         <span class="keyword">val</span> manager = <span class="keyword">new</span> <span class="type">ExecutorRunner</span>(</span><br><span class="line">           appId,</span><br><span class="line">           execId,</span><br><span class="line">           appDesc.copy(command = <span class="type">Worker</span>.maybeUpdateSSLSettings(appDesc.command, conf)),</span><br><span class="line">           cores_,</span><br><span class="line">           memory_,</span><br><span class="line">           self,</span><br><span class="line">           workerId,</span><br><span class="line">           host,</span><br><span class="line">           webUi.boundPort,</span><br><span class="line">           publicAddress,</span><br><span class="line">           sparkHome,</span><br><span class="line">           executorDir,</span><br><span class="line">           workerUri,</span><br><span class="line">           conf,</span><br><span class="line">           appLocalDirs, <span class="type">ExecutorState</span>.<span class="type">RUNNING</span>)</span><br><span class="line">         executors(appId + <span class="string">"/"</span> + execId) = manager</span><br><span class="line">         <span class="comment">//启动Executor</span></span><br><span class="line">         manager.start()</span><br><span class="line">         coresUsed += cores_</span><br><span class="line">         memoryUsed += memory_</span><br><span class="line">         sendToMaster(<span class="type">ExecutorStateChanged</span>(appId, execId, manager.state, <span class="type">None</span>, <span class="type">None</span>))</span><br><span class="line">       &#125; <span class="keyword">catch</span> &#123;</span><br><span class="line">        ...</span><br><span class="line">       &#125;</span><br><span class="line">     &#125;</span><br></pre></td></tr></table></figure>



<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>介绍Master节点Launch Executor的过程，分两步</p>
<ol>
<li><strong>schedule waitingApps</strong></li>
<li><strong>launch Executor</strong></li>
</ol>
<p>流程如下 </p>
<img src='data:image/svg+xml;base64,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'>
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://longzl2015.github.io/2018/06/04/spark/Spark%E6%89%A7%E8%A1%8C%E9%80%BB%E8%BE%91/3_%E5%90%AF%E5%8A%A8%E7%94%A8%E6%88%B7%E7%BC%96%E5%86%99%E7%9A%84App/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="zhoul">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2018/06/04/spark/Spark%E6%89%A7%E8%A1%8C%E9%80%BB%E8%BE%91/3_%E5%90%AF%E5%8A%A8%E7%94%A8%E6%88%B7%E7%BC%96%E5%86%99%E7%9A%84App/" class="post-title-link" itemprop="url">spark3-启动用户编写的App</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2018-06-04 23:22:03" itemprop="dateCreated datePublished" datetime="2018-06-04T23:22:03+08:00">2018-06-04</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-02-27 17:16:07" itemprop="dateModified" datetime="2020-02-27T17:16:07+08:00">2020-02-27</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/spark/" itemprop="url" rel="index">
                    <span itemprop="name">spark</span>
                  </a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/spark/%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/" itemprop="url" rel="index">
                    <span itemprop="name">源码解析</span>
                  </a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="fa fa-comment-o"></i>
      </span>
      <span class="post-meta-item-text">Disqus：</span>
    
    <a title="disqus" href="/2018/06/04/spark/Spark%E6%89%A7%E8%A1%8C%E9%80%BB%E8%BE%91/3_%E5%90%AF%E5%8A%A8%E7%94%A8%E6%88%B7%E7%BC%96%E5%86%99%E7%9A%84App/#comments" itemprop="discussionUrl">
      <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2018/06/04/spark/Spark执行逻辑/3_启动用户编写的App/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="启动用户编写的App"><a href="#启动用户编写的App" class="headerlink" title="启动用户编写的App"></a>启动用户编写的App</h1><p>上一篇讲到了Worker进程使用<strong>java.lang.ProcessBuilder</strong>执行<strong>java -cp</strong>命令启动用户编写的程序。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">java -cp <span class="variable">$SPARK_ASSEMBLY_JAR</span> \</span><br><span class="line">  -Xms1024M -Xmx1024M -Dakka.loglevel=WARNING \</span><br><span class="line">  -Dspark.executor.memory=512m \</span><br><span class="line">  -Dspark.driver.supervise=<span class="literal">false</span> \</span><br><span class="line">  -Dspark.submit.deployMode=cluster \</span><br><span class="line">  -Dspark.app.name=org.apache.spark.examples.SparkPi \</span><br><span class="line">  -Dspark.rpc.askTimeout=10 \</span><br><span class="line">  -Dspark.master=<span class="variable">$MasterUrl</span> -XX:MaxPermSize=256m \</span><br><span class="line">  org.apache.spark.deploy.worker.DriverWrapper \</span><br><span class="line">  <span class="variable">$WorkerUrl</span> \</span><br><span class="line">  /path/to/example.jar \</span><br><span class="line">  org.apache.spark.examples.SparkPi \</span><br><span class="line">  1000</span><br></pre></td></tr></table></figure>

<p>通过 DriverWrapper 来启动 用户编写的应用程序(本文为sparkPi程序):</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">DriverWrapper</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]) &#123;</span><br><span class="line">    args.toList <span class="keyword">match</span> &#123;</span><br><span class="line">      <span class="keyword">case</span> workerUrl :: userJar :: mainClass :: extraArgs =&gt;</span><br><span class="line">        <span class="keyword">val</span> conf = <span class="keyword">new</span> <span class="type">SparkConf</span>()</span><br><span class="line">        <span class="keyword">val</span> rpcEnv = <span class="type">RpcEnv</span>.create(<span class="string">"Driver"</span>,</span><br><span class="line">          <span class="type">Utils</span>.localHostName(), <span class="number">0</span>, conf, <span class="keyword">new</span> <span class="type">SecurityManager</span>(conf))</span><br><span class="line">        rpcEnv.setupEndpoint(<span class="string">"workerWatcher"</span>, <span class="keyword">new</span> <span class="type">WorkerWatcher</span>(rpcEnv, workerUrl))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">val</span> currentLoader = <span class="type">Thread</span>.currentThread.getContextClassLoader</span><br><span class="line">        <span class="keyword">val</span> userJarUrl = <span class="keyword">new</span> <span class="type">File</span>(userJar).toURI().toURL()</span><br><span class="line">        <span class="keyword">val</span> loader =</span><br><span class="line">          <span class="keyword">if</span> (sys.props.getOrElse(<span class="string">"spark.driver.userClassPathFirst"</span>, <span class="string">"false"</span>).toBoolean) &#123;</span><br><span class="line">            <span class="keyword">new</span> <span class="type">ChildFirstURLClassLoader</span>(<span class="type">Array</span>(userJarUrl), currentLoader)</span><br><span class="line">          &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="keyword">new</span> <span class="type">MutableURLClassLoader</span>(<span class="type">Array</span>(userJarUrl), currentLoader)</span><br><span class="line">          &#125;</span><br><span class="line">        <span class="type">Thread</span>.currentThread.setContextClassLoader(loader)</span><br><span class="line"></span><br><span class="line">        <span class="comment">// Delegate to supplied main class</span></span><br><span class="line">        <span class="keyword">val</span> clazz = <span class="type">Utils</span>.classForName(mainClass)</span><br><span class="line">        <span class="keyword">val</span> mainMethod = clazz.getMethod(<span class="string">"main"</span>, classOf[<span class="type">Array</span>[<span class="type">String</span>]])</span><br><span class="line">        mainMethod.invoke(<span class="literal">null</span>, extraArgs.toArray[<span class="type">String</span>])</span><br><span class="line"></span><br><span class="line">        rpcEnv.shutdown()</span><br><span class="line"></span><br><span class="line">      <span class="keyword">case</span> _ =&gt;</span><br><span class="line">        <span class="comment">// scalastyle:off println</span></span><br><span class="line">        <span class="type">System</span>.err.println(<span class="string">"Usage: DriverWrapper &lt;workerUrl&gt; &lt;userJar&gt; &lt;driverMainClass&gt; [options]"</span>)</span><br><span class="line">        <span class="comment">// scalastyle:on println</span></span><br><span class="line">        <span class="type">System</span>.exit(<span class="number">-1</span>)</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="SparkPi程序"><a href="#SparkPi程序" class="headerlink" title="SparkPi程序"></a>SparkPi程序</h2><p>SparkPi程序 代码如下:</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scala.math.random</span><br><span class="line"><span class="keyword">import</span> org.apache.spark._</span><br><span class="line"></span><br><span class="line"><span class="comment">/** Computes an approximation to pi */</span></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">SparkPi</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]) &#123;</span><br><span class="line">    <span class="keyword">if</span> (args.length == <span class="number">0</span>) &#123;</span><br><span class="line">      <span class="type">System</span>.err.println(<span class="string">"Usage: SparkPi &lt;master&gt; [&lt;slices&gt;]"</span>)</span><br><span class="line">      <span class="type">System</span>.exit(<span class="number">1</span>)</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">val</span> spark = <span class="keyword">new</span> <span class="type">SparkContext</span>(args(<span class="number">0</span>), <span class="string">"SparkPi"</span>,</span><br><span class="line">      <span class="type">System</span>.getenv(<span class="string">"SPARK_HOME"</span>), <span class="type">SparkContext</span>.jarOfClass(<span class="keyword">this</span>.getClass))</span><br><span class="line">    <span class="keyword">val</span> slices = <span class="keyword">if</span> (args.length &gt; <span class="number">1</span>) args(<span class="number">1</span>).toInt <span class="keyword">else</span> <span class="number">2</span></span><br><span class="line">    <span class="keyword">val</span> n = <span class="number">100000</span> * slices</span><br><span class="line">    <span class="keyword">val</span> count = spark.parallelize(<span class="number">1</span> to n, slices).map &#123; i =&gt;</span><br><span class="line">      <span class="keyword">val</span> x = random * <span class="number">2</span> - <span class="number">1</span></span><br><span class="line">      <span class="keyword">val</span> y = random * <span class="number">2</span> - <span class="number">1</span></span><br><span class="line">      <span class="keyword">if</span> (x*x + y*y &lt; <span class="number">1</span>) <span class="number">1</span> <span class="keyword">else</span> <span class="number">0</span></span><br><span class="line">    &#125;.reduce(_ + _)</span><br><span class="line">    println(<span class="string">"Pi is roughly "</span> + <span class="number">4.0</span> * count / n)</span><br><span class="line">    spark.stop()</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="SparkContext初始化"><a href="#SparkContext初始化" class="headerlink" title="SparkContext初始化"></a>SparkContext初始化</h2><p>该类全类名 org.apache.spark.SparkContext。下面的SparkContext初始化的主要代码过程。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SparkContext</span>(<span class="params">config: <span class="type">SparkConf</span></span>) <span class="keyword">extends</span> <span class="title">Logging</span> </span>&#123;</span><br><span class="line">  <span class="comment">// 将所有参数整合，clone 出一个完整的SparkConf对象(SparkConf会加载所有的以"spark."开头的系统变量),</span></span><br><span class="line">  <span class="comment">// 然后用该SparkConf对象构造SparkContext</span></span><br><span class="line">  <span class="keyword">private</span>[spark] <span class="function"><span class="keyword">def</span> <span class="title">this</span></span>(</span><br><span class="line">      master: <span class="type">String</span>, </span><br><span class="line">      appName: <span class="type">String</span>, </span><br><span class="line">      sparkHome: <span class="type">String</span>, </span><br><span class="line">      jars: <span class="type">Seq</span>[<span class="type">String</span>]) =</span><br><span class="line">    <span class="keyword">this</span>(master, appName, sparkHome, jars, <span class="type">Map</span>())</span><br><span class="line"> <span class="comment">// SparkContext的初始化主要在 try 代码块中</span></span><br><span class="line">  <span class="keyword">try</span>&#123;</span><br><span class="line">	<span class="comment">//校验逻辑和基本配置设置省略</span></span><br><span class="line">      </span><br><span class="line">    <span class="comment">// "_jobProgressListener" should be set up before creating SparkEnv because when creating</span></span><br><span class="line">    <span class="comment">// "SparkEnv", some messages will be posted to "listenerBus" and we should not miss them.</span></span><br><span class="line">    _jobProgressListener = <span class="keyword">new</span> <span class="type">JobProgressListener</span>(_conf)</span><br><span class="line">    listenerBus.addListener(jobProgressListener)</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 该env中包含 serializer, RpcEnv, block manager, map output tracker, etc</span></span><br><span class="line">    _env = createSparkEnv(_conf, isLocal, listenerBus)</span><br><span class="line">    <span class="comment">// 所有线程能够通过 SparkEnv.get()获取相关信息</span></span><br><span class="line">    <span class="type">SparkEnv</span>.set(_env)</span><br><span class="line">      </span><br><span class="line">    <span class="comment">// If running the REPL, register the repl's output dir with the file server.</span></span><br><span class="line">    _conf.getOption(<span class="string">"spark.repl.class.outputDir"</span>).foreach &#123; path =&gt;</span><br><span class="line">      <span class="keyword">val</span> replUri = _env.rpcEnv.fileServer.addDirectory(<span class="string">"/classes"</span>, <span class="keyword">new</span> <span class="type">File</span>(path))</span><br><span class="line">      _conf.set(<span class="string">"spark.repl.class.uri"</span>, replUri)</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//该类用于监控 job and stage progress</span></span><br><span class="line">    _statusTracker = <span class="keyword">new</span> <span class="type">SparkStatusTracker</span>(<span class="keyword">this</span>)</span><br><span class="line">    </span><br><span class="line">    _progressBar =</span><br><span class="line">      <span class="keyword">if</span> (_conf.getBoolean(<span class="string">"spark.ui.showConsoleProgress"</span>, <span class="literal">true</span>) &amp;&amp; !log.isInfoEnabled) &#123;</span><br><span class="line">        <span class="type">Some</span>(<span class="keyword">new</span> <span class="type">ConsoleProgressBar</span>(<span class="keyword">this</span>))</span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="type">None</span></span><br><span class="line">      &#125;</span><br><span class="line">    <span class="comment">// 创建spark-Ui</span></span><br><span class="line">    _ui =</span><br><span class="line">      <span class="keyword">if</span> (conf.getBoolean(<span class="string">"spark.ui.enabled"</span>, <span class="literal">true</span>)) &#123;</span><br><span class="line">        <span class="type">Some</span>(<span class="type">SparkUI</span>.createLiveUI(<span class="keyword">this</span>, _conf, listenerBus, _jobProgressListener,</span><br><span class="line">          _env.securityManager, appName, startTime = startTime))</span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="comment">// For tests, do not enable the UI</span></span><br><span class="line">        <span class="type">None</span></span><br><span class="line">      &#125;</span><br><span class="line">    <span class="comment">// Bind the UI before starting the task scheduler to communicate</span></span><br><span class="line">    <span class="comment">// the bound port to the cluster manager properly</span></span><br><span class="line">    _ui.foreach(_.bind())</span><br><span class="line"></span><br><span class="line">    _hadoopConfiguration = <span class="type">SparkHadoopUtil</span>.get.newConfiguration(_conf)</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 将 jar 添加到 rpc.env.fileServer</span></span><br><span class="line">    <span class="keyword">if</span> (jars != <span class="literal">null</span>) &#123;</span><br><span class="line">      jars.foreach(addJar)</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (files != <span class="literal">null</span>) &#123;</span><br><span class="line">      files.foreach(addFile)</span><br><span class="line">    &#125;</span><br><span class="line">      </span><br><span class="line">    <span class="comment">//校验逻辑和基本配置设置省略</span></span><br><span class="line">    <span class="comment">//...</span></span><br><span class="line">      </span><br><span class="line">    <span class="comment">// register "HeartbeatReceiver" before "createTaskScheduler" because Executor will</span></span><br><span class="line">    <span class="comment">// retrieve "HeartbeatReceiver" in the constructor. (SPARK-6640)</span></span><br><span class="line">    _heartbeatReceiver = env.rpcEnv.setupEndpoint(</span><br><span class="line">      <span class="type">HeartbeatReceiver</span>.<span class="type">ENDPOINT_NAME</span>, <span class="keyword">new</span> <span class="type">HeartbeatReceiver</span>(<span class="keyword">this</span>))</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Create and start the scheduler</span></span><br><span class="line">    <span class="comment">// 在下面的章节会详情讲解TaskScheduler的创建</span></span><br><span class="line">    <span class="keyword">val</span> (sched, ts) = <span class="type">SparkContext</span>.createTaskScheduler(<span class="keyword">this</span>, master, deployMode)</span><br><span class="line">    _schedulerBackend = sched</span><br><span class="line">    _taskScheduler = ts</span><br><span class="line">    _dagScheduler = <span class="keyword">new</span> <span class="type">DAGScheduler</span>(<span class="keyword">this</span>)</span><br><span class="line">    _heartbeatReceiver.ask[<span class="type">Boolean</span>](<span class="type">TaskSchedulerIsSet</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">// start TaskScheduler after taskScheduler sets DAGScheduler reference in DAGScheduler's</span></span><br><span class="line">    <span class="comment">// constructor</span></span><br><span class="line">    _taskScheduler.start()</span><br><span class="line">    </span><br><span class="line">    _applicationId = _taskScheduler.applicationId()</span><br><span class="line">    _applicationAttemptId = taskScheduler.applicationAttemptId()</span><br><span class="line">    _conf.set(<span class="string">"spark.app.id"</span>, _applicationId)</span><br><span class="line">    <span class="keyword">if</span> (_conf.getBoolean(<span class="string">"spark.ui.reverseProxy"</span>, <span class="literal">false</span>)) &#123;</span><br><span class="line">      <span class="type">System</span>.setProperty(<span class="string">"spark.ui.proxyBase"</span>, <span class="string">"/proxy/"</span> + _applicationId)</span><br><span class="line">    &#125;</span><br><span class="line">    _ui.foreach(_.setAppId(_applicationId))</span><br><span class="line">      </span><br><span class="line">    <span class="comment">//  blockManager进行初始化</span></span><br><span class="line">    _env.blockManager.initialize(_applicationId)</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 启动 metricsSystem</span></span><br><span class="line">    _env.metricsSystem.start()</span><br><span class="line">    _env.metricsSystem.getServletHandlers.foreach(handler =&gt; ui.foreach(_.attachHandler(handler)))</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 忽略</span></span><br><span class="line">    <span class="comment">// ...</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// 创建executor分配管理器</span></span><br><span class="line">    <span class="keyword">val</span> dynamicAllocationEnabled = <span class="type">Utils</span>.isDynamicAllocationEnabled(_conf)</span><br><span class="line">    _executorAllocationManager =</span><br><span class="line">      <span class="keyword">if</span> (dynamicAllocationEnabled) &#123;</span><br><span class="line">        schedulerBackend <span class="keyword">match</span> &#123;</span><br><span class="line">          <span class="keyword">case</span> b: <span class="type">ExecutorAllocationClient</span> =&gt;</span><br><span class="line">            <span class="type">Some</span>(<span class="keyword">new</span> <span class="type">ExecutorAllocationManager</span>(</span><br><span class="line">              schedulerBackend.asInstanceOf[<span class="type">ExecutorAllocationClient</span>], listenerBus, _conf))</span><br><span class="line">          <span class="keyword">case</span> _ =&gt;</span><br><span class="line">            <span class="type">None</span></span><br><span class="line">        &#125;</span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="type">None</span></span><br><span class="line">      &#125;</span><br><span class="line">    _executorAllocationManager.foreach(_.start())</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 创建 cleaner for RDD, shuffle, and broadcast state</span></span><br><span class="line">    _cleaner =</span><br><span class="line">      <span class="keyword">if</span> (_conf.getBoolean(<span class="string">"spark.cleaner.referenceTracking"</span>, <span class="literal">true</span>)) &#123;</span><br><span class="line">        <span class="type">Some</span>(<span class="keyword">new</span> <span class="type">ContextCleaner</span>(<span class="keyword">this</span>))</span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="type">None</span></span><br><span class="line">      &#125;</span><br><span class="line">    _cleaner.foreach(_.start())</span><br><span class="line">    <span class="comment">//设置并启动监听总线ListenerBus</span></span><br><span class="line">    setupAndStartListenerBus()</span><br><span class="line">    <span class="comment">//task scheduler准备完毕，更新SparkEnv和将SparkContext标记为激活</span></span><br><span class="line">    postEnvironmentUpdate()</span><br><span class="line">    <span class="comment">//发送应用启动时间</span></span><br><span class="line">    postApplicationStart()</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Post init</span></span><br><span class="line">    _taskScheduler.postStartHook()</span><br><span class="line">    <span class="comment">//注册dagScheduler.metricsSource</span></span><br><span class="line">    _env.metricsSystem.registerSource(_dagScheduler.metricsSource)</span><br><span class="line">    <span class="comment">//注册BlockManagerSource</span></span><br><span class="line">    _env.metricsSystem.registerSource(<span class="keyword">new</span> <span class="type">BlockManagerSource</span>(_env.blockManager))</span><br><span class="line">    <span class="comment">//注册executorAllocationManagerSource</span></span><br><span class="line">    _executorAllocationManager.foreach &#123; e =&gt;</span><br><span class="line">      _env.metricsSystem.registerSource(e.executorAllocationManagerSource)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Make sure the context is stopped if the user forgets about it. This avoids leaving</span></span><br><span class="line">    <span class="comment">// unfinished event logs around after the JVM exits cleanly. It doesn't help if the JVM</span></span><br><span class="line">    <span class="comment">// is killed, though.</span></span><br><span class="line">    logDebug(<span class="string">"Adding shutdown hook"</span>) <span class="comment">// force eager creation of logger</span></span><br><span class="line">    _shutdownHookRef = <span class="type">ShutdownHookManager</span>.addShutdownHook(</span><br><span class="line">      <span class="type">ShutdownHookManager</span>.<span class="type">SPARK_CONTEXT_SHUTDOWN_PRIORITY</span>) &#123; () =&gt;</span><br><span class="line">      logInfo(<span class="string">"Invoking stop() from shutdown hook"</span>)</span><br><span class="line">      stop()</span><br><span class="line">    &#125;</span><br><span class="line">  &#125; <span class="keyword">catch</span> &#123;</span><br><span class="line">    <span class="keyword">case</span> <span class="type">NonFatal</span>(e) =&gt;</span><br><span class="line">      logError(<span class="string">"Error initializing SparkContext."</span>, e)</span><br><span class="line">      <span class="keyword">try</span> &#123;</span><br><span class="line">        stop()</span><br><span class="line">      &#125; <span class="keyword">catch</span> &#123;</span><br><span class="line">        <span class="keyword">case</span> <span class="type">NonFatal</span>(inner) =&gt;</span><br><span class="line">          logError(<span class="string">"Error stopping SparkContext after init error."</span>, inner)</span><br><span class="line">      &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">        <span class="keyword">throw</span> e</span><br><span class="line">      &#125;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>

<h2 id="TaskScheduler的创建与启动"><a href="#TaskScheduler的创建与启动" class="headerlink" title="TaskScheduler的创建与启动"></a>TaskScheduler的创建与启动</h2><p>上文中有这一段代码，在该章节详细讲解。</p>
<p>该小节仅简单介绍了AppClient的注册，详细信息见下一小节。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> (sched, ts) = <span class="type">SparkContext</span>.createTaskScheduler(<span class="keyword">this</span>, master, deployMode)</span><br><span class="line">_schedulerBackend = sched</span><br><span class="line">_taskScheduler = ts</span><br><span class="line">_dagScheduler = <span class="keyword">new</span> <span class="type">DAGScheduler</span>(<span class="keyword">this</span>)</span><br><span class="line">_heartbeatReceiver.ask[<span class="type">Boolean</span>](<span class="type">TaskSchedulerIsSet</span>)</span><br><span class="line"></span><br><span class="line">_taskScheduler.start()</span><br></pre></td></tr></table></figure>



<h3 id="TaskScheduler的创建"><a href="#TaskScheduler的创建" class="headerlink" title="TaskScheduler的创建"></a>TaskScheduler的创建</h3><p>全路径 org.apache.spark.SparkContext 下的 createTaskScheduler 方法</p>
<p><strong>TaskSchedulerImpl</strong>: 继承自TaskScheduler</p>
<ul>
<li>作用在Driver中: 将DAGScheduler生成的task，使用SchedulerBackend和DriverEndpoint发送给Executor。</li>
</ul>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 返回 SchedulerBackend, TaskScheduler</span></span><br><span class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">createTaskScheduler</span></span>(</span><br><span class="line">      sc: <span class="type">SparkContext</span>,</span><br><span class="line">      master: <span class="type">String</span>,</span><br><span class="line">      deployMode: <span class="type">String</span>): (<span class="type">SchedulerBackend</span>, <span class="type">TaskScheduler</span>) = &#123;</span><br><span class="line">    <span class="keyword">import</span> <span class="type">SparkMasterRegex</span>._</span><br><span class="line"></span><br><span class="line">    master <span class="keyword">match</span> &#123;</span><br><span class="line">      <span class="comment">//忽略其他case</span></span><br><span class="line">      <span class="keyword">case</span> <span class="type">SPARK_REGEX</span>(sparkUrl) =&gt;</span><br><span class="line">        <span class="keyword">val</span> scheduler = <span class="keyword">new</span> <span class="type">TaskSchedulerImpl</span>(sc)</span><br><span class="line">        <span class="keyword">val</span> masterUrls = sparkUrl.split(<span class="string">","</span>).map(<span class="string">"spark://"</span> + _)</span><br><span class="line">        <span class="keyword">val</span> backend = <span class="keyword">new</span> <span class="type">StandaloneSchedulerBackend</span>(scheduler, sc, masterUrls)</span><br><span class="line">        scheduler.initialize(backend)</span><br><span class="line">        (backend, scheduler)</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>

<p><strong>TaskScheduler的初始化:</strong> </p>
<p>全路径 org.apache.spark.scheduler.TaskSchedulerImpl</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">initialize</span></span>(backend: <span class="type">SchedulerBackend</span>) &#123;</span><br><span class="line">  <span class="keyword">this</span>.backend = backend</span><br><span class="line">  schedulableBuilder = &#123;</span><br><span class="line">    schedulingMode <span class="keyword">match</span> &#123;</span><br><span class="line">      <span class="comment">//先入先出</span></span><br><span class="line">      <span class="keyword">case</span> <span class="type">SchedulingMode</span>.<span class="type">FIFO</span> =&gt;</span><br><span class="line">        <span class="keyword">new</span> <span class="type">FIFOSchedulableBuilder</span>(rootPool)</span><br><span class="line">      <span class="comment">//公平策略</span></span><br><span class="line">      <span class="keyword">case</span> <span class="type">SchedulingMode</span>.<span class="type">FAIR</span> =&gt;</span><br><span class="line">        <span class="keyword">new</span> <span class="type">FairSchedulableBuilder</span>(rootPool, conf)</span><br><span class="line">      <span class="keyword">case</span> _ =&gt;</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">IllegalArgumentException</span>(<span class="string">s"Unsupported <span class="subst">$SCHEDULER_MODE_PROPERTY</span>: "</span> +</span><br><span class="line">        <span class="string">s"<span class="subst">$schedulingMode</span>"</span>)</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  schedulableBuilder.buildPools()</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="TaskScheduler的启动"><a href="#TaskScheduler的启动" class="headerlink" title="TaskScheduler的启动"></a>TaskScheduler的启动</h3><p>全路径 org.apache.spark.scheduler.TaskSchedulerImpl 下的 start 方法</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">start</span></span>() &#123;</span><br><span class="line">  <span class="comment">//本文为 StandaloneSchedulerBackend </span></span><br><span class="line">  backend.start()</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (!isLocal &amp;&amp; conf.getBoolean(<span class="string">"spark.speculation"</span>, <span class="literal">false</span>)) &#123;</span><br><span class="line">    logInfo(<span class="string">"Starting speculative execution thread"</span>)</span><br><span class="line">    speculationScheduler.scheduleWithFixedDelay(<span class="keyword">new</span> <span class="type">Runnable</span> &#123;</span><br><span class="line">      <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">run</span></span>(): <span class="type">Unit</span> = <span class="type">Utils</span>.tryOrStopSparkContext(sc) &#123;</span><br><span class="line">        checkSpeculatableTasks()</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;, <span class="type">SPECULATION_INTERVAL_MS</span>, <span class="type">SPECULATION_INTERVAL_MS</span>, <span class="type">TimeUnit</span>.<span class="type">MILLISECONDS</span>)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><strong>StandaloneSchedulerBackend</strong>:</p>
<ul>
<li>调用父类<strong>CoarseGrainedSchedulerBackend</strong>的start方法创建<strong>DriverEndPoint</strong></li>
<li>创建 <strong>AppClient</strong> 并向 Master 注册。</li>
</ul>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">start</span></span>() &#123;</span><br><span class="line">    <span class="comment">//向RpcEnv注册DriverEndpoint:用于提交task到Executor，接收Executor返回的计算结果</span></span><br><span class="line">    <span class="keyword">super</span>.start()</span><br><span class="line">    </span><br><span class="line">    <span class="comment">//忽略相关变量赋值</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">//生成APP的完整描述信息</span></span><br><span class="line">    <span class="keyword">val</span> appDesc = <span class="type">ApplicationDescription</span>(sc.appName, maxCores, sc.executorMemory, command,</span><br><span class="line">      webUrl, sc.eventLogDir, sc.eventLogCodec, coresPerExecutor, initialExecutorLimit)</span><br><span class="line">    <span class="comment">//用于和 Spark standalone cluster manager 建立连接</span></span><br><span class="line">    client = <span class="keyword">new</span> <span class="type">StandaloneAppClient</span>(sc.env.rpcEnv, masters, appDesc, <span class="keyword">this</span>, conf)</span><br><span class="line">    <span class="comment">//注册ClientEndpoint，ClientEndpoint的生命周期方法onStart中会和Master通信，注册APP</span></span><br><span class="line">    client.start()</span><br><span class="line">    launcherBackend.setState(<span class="type">SparkAppHandle</span>.<span class="type">State</span>.<span class="type">SUBMITTED</span>)</span><br><span class="line">    waitForRegistration()</span><br><span class="line">    launcherBackend.setState(<span class="type">SparkAppHandle</span>.<span class="type">State</span>.<span class="type">RUNNING</span>)</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>

<h2 id="AppClient的注册"><a href="#AppClient的注册" class="headerlink" title="AppClient的注册"></a>AppClient的注册</h2><p>本小节接着 如下代码讲解:</p>
<p>全路劲 org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">start</span></span>() &#123;</span><br><span class="line">  <span class="comment">// 忽略</span></span><br><span class="line">  <span class="comment">// ...</span></span><br><span class="line">  </span><br><span class="line">  client = <span class="keyword">new</span> <span class="type">StandaloneAppClient</span>(sc.env.rpcEnv, masters, appDesc, <span class="keyword">this</span>, conf)</span><br><span class="line">  <span class="comment">//注册ClientEndpoint，ClientEndpoint的生命周期方法onStart中会和Master通信，注册APP</span></span><br><span class="line">  client.start()</span><br><span class="line">  </span><br><span class="line">  <span class="comment">// 忽略</span></span><br><span class="line">  <span class="comment">// ...</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><strong>ClientEndpoint.onStart() 方法</strong></p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">onStart</span></span>(): <span class="type">Unit</span> = &#123;</span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">    registerWithMaster(<span class="number">1</span>)</span><br><span class="line">  &#125; <span class="keyword">catch</span> &#123;</span><br><span class="line">    <span class="keyword">case</span> e: <span class="type">Exception</span> =&gt;</span><br><span class="line">    logWarning(<span class="string">"Failed to connect to master"</span>, e)</span><br><span class="line">    markDisconnected()</span><br><span class="line">    stop()</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//向所有的master异步注册。在达到超时时间之前，他会以特定的时间间隔调用 registerWithMaster().</span></span><br><span class="line"><span class="comment">//一旦成功连上 其中一个master：</span></span><br><span class="line"><span class="comment">// 1. 会向 master 发送 RegisterApplication(appDescription, self) 消息</span></span><br><span class="line"><span class="comment">// 2. 所有的 scheduling work and Futures will be cancelled</span></span><br><span class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">registerWithMaster</span></span>(nthRetry: <span class="type">Int</span>) &#123;</span><br><span class="line">  registerMasterFutures.set(tryRegisterAllMasters())</span><br><span class="line">  registrationRetryTimer.set(registrationRetryThread.schedule(<span class="keyword">new</span> <span class="type">Runnable</span> &#123;</span><br><span class="line">    <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">run</span></span>(): <span class="type">Unit</span> = &#123;</span><br><span class="line">      <span class="keyword">if</span> (registered.get) &#123;</span><br><span class="line">        registerMasterFutures.get.foreach(_.cancel(<span class="literal">true</span>))</span><br><span class="line">        registerMasterThreadPool.shutdownNow()</span><br><span class="line">      &#125; <span class="keyword">else</span> <span class="keyword">if</span> (nthRetry &gt;= <span class="type">REGISTRATION_RETRIES</span>) &#123;</span><br><span class="line">        markDead(<span class="string">"All masters are unresponsive! Giving up."</span>)</span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        registerMasterFutures.get.foreach(_.cancel(<span class="literal">true</span>))</span><br><span class="line">        registerWithMaster(nthRetry + <span class="number">1</span>)</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;, <span class="type">REGISTRATION_TIMEOUT_SECONDS</span>, <span class="type">TimeUnit</span>.<span class="type">SECONDS</span>))</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//向所有的master异步注册</span></span><br><span class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">tryRegisterAllMasters</span></span>(): <span class="type">Array</span>[<span class="type">JFuture</span>[_]] = &#123;</span><br><span class="line">  <span class="keyword">for</span> (masterAddress &lt;- masterRpcAddresses) <span class="keyword">yield</span> &#123;</span><br><span class="line">    registerMasterThreadPool.submit(<span class="keyword">new</span> <span class="type">Runnable</span> &#123;</span><br><span class="line">      <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">run</span></span>(): <span class="type">Unit</span> = <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="keyword">if</span> (registered.get) &#123;</span><br><span class="line">          <span class="keyword">return</span></span><br><span class="line">        &#125;</span><br><span class="line">        logInfo(<span class="string">"Connecting to master "</span> + masterAddress.toSparkURL + <span class="string">"..."</span>)</span><br><span class="line">        <span class="keyword">val</span> masterRef = rpcEnv.setupEndpointRef(masterAddress, <span class="type">Master</span>.<span class="type">ENDPOINT_NAME</span>)</span><br><span class="line">        <span class="comment">//向 master 发送 RegisterApplication(appDescription, self) 消息</span></span><br><span class="line">        masterRef.send(<span class="type">RegisterApplication</span>(appDescription, self))</span><br><span class="line">      &#125; <span class="keyword">catch</span> &#123;</span><br><span class="line">        <span class="keyword">case</span> ie: <span class="type">InterruptedException</span> =&gt; <span class="comment">// Cancelled</span></span><br><span class="line">        <span class="keyword">case</span> <span class="type">NonFatal</span>(e) =&gt; logWarning(<span class="string">s"Failed to connect to master <span class="subst">$masterAddress</span>"</span>, e)</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><strong>Master 接收消息:</strong></p>
<p>全路径 org.apache.spark.deploy.master.Master</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">receive</span></span>: <span class="type">PartialFunction</span>[<span class="type">Any</span>, <span class="type">Unit</span>] = &#123;</span><br><span class="line">  <span class="comment">//其他case忽略</span></span><br><span class="line"></span><br><span class="line">  <span class="keyword">case</span> <span class="type">RegisterApplication</span>(description, driver) =&gt;</span><br><span class="line">  <span class="comment">// TODO Prevent repeated registrations from some driver</span></span><br><span class="line">  <span class="keyword">if</span> (state == <span class="type">RecoveryState</span>.<span class="type">STANDBY</span>) &#123;</span><br><span class="line">    <span class="comment">// ignore, don't send response</span></span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    logInfo(<span class="string">"Registering app "</span> + description.name)</span><br><span class="line">    <span class="comment">// 创建 ApplicationInfo 实例</span></span><br><span class="line">    <span class="keyword">val</span> app = createApplication(description, driver)</span><br><span class="line">    <span class="comment">// 注册 app</span></span><br><span class="line">    registerApplication(app)</span><br><span class="line">    </span><br><span class="line">    logInfo(<span class="string">"Registered app "</span> + description.name + <span class="string">" with ID "</span> + app.id)</span><br><span class="line">    <span class="comment">//PersistenceEngine作用</span></span><br><span class="line">    <span class="comment">// - 当Master发生故障时，来读取持久化的Application，Worker，Driver的详细信息。</span></span><br><span class="line">    <span class="comment">// - 负责写入持久化Application，Worker，Driver的详细信息。</span></span><br><span class="line">    persistenceEngine.addApplication(app)</span><br><span class="line">    <span class="comment">//向StandaloneAppClient发送消息RegisteredApplication，表示已注册Application</span></span><br><span class="line">    driver.send(<span class="type">RegisteredApplication</span>(app.id, self))</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">   * Schedule the currently available resources among waiting apps. This method will be called</span></span><br><span class="line"><span class="comment">   * every time a new app joins or resource availability changes.</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">    schedule()</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">registerApplication</span></span>(app: <span class="type">ApplicationInfo</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">  <span class="keyword">val</span> appAddress = app.driver.address</span><br><span class="line">  <span class="keyword">if</span> (addressToApp.contains(appAddress)) &#123;</span><br><span class="line">    logInfo(<span class="string">"Attempted to re-register application at same address: "</span> + appAddress)</span><br><span class="line">    <span class="keyword">return</span></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  applicationMetricsSystem.registerSource(app.appSource)</span><br><span class="line">  apps += app</span><br><span class="line">  idToApp(app.id) = app</span><br><span class="line">  endpointToApp(app.driver) = app</span><br><span class="line">  addressToApp(appAddress) = app</span><br><span class="line">  waitingApps += app</span><br><span class="line">  <span class="keyword">if</span> (reverseProxy) &#123;</span><br><span class="line">    webUi.addProxyTargets(app.id, app.desc.appUiUrl)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>最后，完整流程如下 。</p>
<p><strong>注</strong>：图中的 SparkDeploySchedulerBackend 应该为 StandaloneSchedulerBackend。</p>
<p><img src="/images/3_%E5%90%AF%E5%8A%A8%E7%94%A8%E6%88%B7%E7%BC%96%E5%86%99%E7%9A%84App/spark%E6%B3%A8%E5%86%8CApp.png" alt="img"></p>
<p>注释：</p>
<p>①，Driver端注册<strong>DriverEndpoint</strong>到RpcEnv的流程，之后DriverEndpoint用于和Executor通信，包括send task和接收返回的计算结果。</p>
<p>②，Driver向Master注册APP的流程。</p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="http://www.louisvv.com/archives/1191.html" target="_blank" rel="noopener">参考一</a></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

  </div>

  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/24/"><i class="fa fa-angle-left" aria-label="上一页"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/24/">24</a><span class="page-number current">25</span><a class="page-number" href="/page/26/">26</a><span class="space">&hellip;</span><a class="page-number" href="/page/36/">36</a><a class="extend next" rel="next" href="/page/26/"><i class="fa fa-angle-right" aria-label="下一页"></i></a>
  </nav>



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let activeClass = CONFIG.comments.activeClass;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">zhoul</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">351</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">92</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">190</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/longzl2015" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;longzl2015" rel="noopener" target="_blank"><i class="fa fa-fw fa-github"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:289570126@qq.com" title="E-Mail → mailto:289570126@qq.com" rel="noopener" target="_blank"><i class="fa fa-fw fa-envelope"></i>E-Mail</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://stackoverflow.com/users/5276366/egg" title="StackOverflow → https:&#x2F;&#x2F;stackoverflow.com&#x2F;users&#x2F;5276366&#x2F;egg" rel="noopener" target="_blank"><i class="fa fa-fw fa-stack-overflow"></i>StackOverflow</a>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">zhoul</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> 强力驱动 v4.2.0
  </div>
  <span class="post-meta-divider">|</span>
  <div class="theme-info">主题 – <a href="https://theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a> v7.7.0
  </div>

        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>













  

  

<script>
  function loadCount() {
    var d = document, s = d.createElement('script');
    s.src = 'https://long12356-gitee-io.disqus.com/count.js';
    s.id = 'dsq-count-scr';
    (d.head || d.body).appendChild(s);
  }
  // defer loading until the whole page loading is completed
  window.addEventListener('load', loadCount, false);
</script>

</body>
</html>
