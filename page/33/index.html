<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 4.2.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css">


<script id="hexo-configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    hostname: new URL('https://longzl2015.github.io').hostname,
    root: '/',
    scheme: 'Gemini',
    version: '7.7.0',
    exturl: false,
    sidebar: {"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},
    copycode: {"enable":false,"show_result":false,"style":null},
    back2top: {"enable":true,"sidebar":false,"scrollpercent":false},
    bookmark: {"enable":false,"color":"#222","save":"auto"},
    fancybox: false,
    mediumzoom: false,
    lazyload: false,
    pangu: false,
    comments: {"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},
    algolia: {
      appID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"我们没有找到任何搜索结果: ${query}","hits_stats":"找到约${hits}条结果（用时${time}ms）"}
    },
    localsearch: {"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":true},
    path: 'search.xml',
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}
  };
</script>

  <meta property="og:type" content="website">
<meta property="og:title" content="Hexo">
<meta property="og:url" content="https://longzl2015.github.io/page/33/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="zhoul">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="https://longzl2015.github.io/page/33/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome: true,
    isPost: false
  };
</script>

  <title>Hexo</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-meta">

    <div>
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Hexo</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
  </div>

  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>
</div>


<nav class="site-nav">
  
  <ul id="menu" class="menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-fw fa-home"></i>首页</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-fw fa-tags"></i>标签<span class="badge">190</span></a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-fw fa-th"></i>分类<span class="badge">92</span></a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-fw fa-archive"></i>归档<span class="badge">351</span></a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>

</nav>
  <div class="site-search">
    <div class="popup search-popup">
    <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocorrect="off" autocapitalize="none"
           placeholder="搜索..." spellcheck="false"
           type="text" id="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result"></div>

</div>
<div class="search-pop-overlay"></div>

  </div>
</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content">
            

  <div class="posts-expand">
        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://longzl2015.github.io/2016/04/02/hadoop%E7%94%9F%E6%80%81/parquet/parquet%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="zhoul">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2016/04/02/hadoop%E7%94%9F%E6%80%81/parquet/parquet%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB/" class="post-title-link" itemprop="url">parquet文件结构相关类</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2016-04-02 22:46:48" itemprop="dateCreated datePublished" datetime="2016-04-02T22:46:48+08:00">2016-04-02</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-02-27 17:16:07" itemprop="dateModified" datetime="2020-02-27T17:16:07+08:00">2020-02-27</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/hadoop%E7%94%9F%E6%80%81/" itemprop="url" rel="index">
                    <span itemprop="name">hadoop生态</span>
                  </a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/hadoop%E7%94%9F%E6%80%81/parquet/" itemprop="url" rel="index">
                    <span itemprop="name">parquet</span>
                  </a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="fa fa-comment-o"></i>
      </span>
      <span class="post-meta-item-text">Disqus：</span>
    
    <a title="disqus" href="/2016/04/02/hadoop%E7%94%9F%E6%80%81/parquet/parquet%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB/#comments" itemprop="discussionUrl">
      <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2016/04/02/hadoop生态/parquet/parquet源码阅读/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p><img src="/images/parquet%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB/parquet_classes.png" alt="parquet_classes"></p>
<h2 id="1、parquet文件结构相关类"><a href="#1、parquet文件结构相关类" class="headerlink" title="1、parquet文件结构相关类"></a>1、parquet文件结构相关类</h2><h3 id="ParquetMetadata"><a href="#ParquetMetadata" class="headerlink" title="ParquetMetadata"></a>ParquetMetadata</h3><p>ParquetMetaData类封装了Parquet文件的元数据信息，其包含一个FileMetaData类和一个BlockMetaData List，并且提供静态方法，采用org.codehaus.jackson包将ParquetMetaData变成json格式，当然也提供函数将json格式的元数据转换成一个ParquetMetaData对象。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ParquetMetadata</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> ObjectMapper objectMapper = <span class="keyword">new</span> ObjectMapper();</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> ObjectMapper prettyObjectMapper = <span class="keyword">new</span> ObjectMapper();</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> FileMetaData fileMetaData;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> List&lt;BlockMetaData&gt; blocks;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="FileMetaData"><a href="#FileMetaData" class="headerlink" title="FileMetaData"></a>FileMetaData</h3><p>FileMetaData类包含文件的元数据，包含数据描述信息schema、String键值对<code>Map&lt;String,String&gt;</code>、以及文件创建版本信息。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">final</span> <span class="class"><span class="keyword">class</span> <span class="title">FileMetaData</span> <span class="keyword">implements</span> <span class="title">Serializable</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">long</span> serialVersionUID = <span class="number">1L</span>;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> MessageType schema;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> Map&lt;String, String&gt; keyValueMetaData;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> String createdBy;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>keyValueMetaData中一般会存储parquet的补充信息，不同软件生成的信息不同：</p>
<ul>
<li>sparksql生成的信息如下：</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">org.apache.spark.sql.parquet.row.metadata&#x3D;&#123;</span><br><span class="line">  &quot;type&quot;:&quot;struct&quot;,</span><br><span class="line">  &quot;fields&quot;:[</span><br><span class="line">    &#123;&quot;name&quot;:&quot;apply_cnt&quot;,&quot;type&quot;:&quot;string&quot;,&quot;nullable&quot;:true,&quot;metadata&quot;:&#123;&#125;&#125;,</span><br><span class="line">    &#123;&quot;name&quot;:&quot;bbr_addressno&quot;,&quot;type&quot;:&quot;string&quot;,&quot;nullable&quot;:true,&quot;metadata&quot;:&#123;&#125;&#125;,</span><br><span class="line">    &#123;&quot;name&quot;:&quot;bbr_age&quot;,&quot;type&quot;:&quot;string&quot;,&quot;nullable&quot;:true,&quot;metadata&quot;:&#123;&#125;&#125;,</span><br><span class="line">    &#123;&quot;name&quot;:&quot;bbr_is_has_medica&quot;,&quot;type&quot;:&quot;string&quot;,&quot;nullable&quot;:true,&quot;metadata&quot;:&#123;&#125;&#125;,</span><br><span class="line">    &#123;&quot;name&quot;:&quot;bbr_marriage&quot;,&quot;type&quot;:&quot;string&quot;,&quot;nullable&quot;:true,&quot;metadata&quot;:&#123;&#125;&#125;,</span><br><span class="line">    &#123;&quot;name&quot;:&quot;bbr_sex&quot;,&quot;type&quot;:&quot;string&quot;,&quot;nullable&quot;:true,&quot;metadata&quot;:&#123;&#125;&#125;,</span><br><span class="line">    &#123;&quot;name&quot;:&quot;bd_amnt_sum&quot;,&quot;type&quot;:&quot;string&quot;,&quot;nullable&quot;:true,&quot;metadata&quot;:&#123;&#125;&#125;,</span><br><span class="line">    &#123;&quot;name&quot;:&quot;bd_lccont_year&quot;,&quot;type&quot;:&quot;string&quot;,&quot;nullable&quot;:true,&quot;metadata&quot;:&#123;&#125;&#125;,</span><br><span class="line">    &#123;&quot;name&quot;:&quot;dir_work_time&quot;,&quot;type&quot;:&quot;string&quot;,&quot;nullable&quot;:true,&quot;metadata&quot;:&#123;&#125;&#125;,</span><br><span class="line">    &#123;&quot;name&quot;:&quot;dlr_bd_chuxian&quot;,&quot;type&quot;:&quot;string&quot;,&quot;nullable&quot;:true,&quot;metadata&quot;:&#123;&#125;&#125;,</span><br><span class="line">    &#123;&quot;name&quot;:&quot;dlr_if_have_backgroud&quot;,&quot;type&quot;:&quot;string&quot;,&quot;nullable&quot;:true,&quot;metadata&quot;:&#123;&#125;&#125;,</span><br><span class="line">    &#123;&quot;name&quot;:&quot;dlr_kind_accresult2&quot;,&quot;type&quot;:&quot;string&quot;,&quot;nullable&quot;:true,&quot;metadata&quot;:&#123;&#125;&#125;,</span><br><span class="line">    &#123;&quot;name&quot;:&quot;grtno&quot;,&quot;type&quot;:&quot;string&quot;,&quot;nullable&quot;:true,&quot;metadata&quot;:&#123;&#125;&#125;,</span><br><span class="line">    &#123;&quot;name&quot;:&quot;label&quot;,&quot;type&quot;:&quot;string&quot;,&quot;nullable&quot;:true,&quot;metadata&quot;:&#123;&#125;&#125;,</span><br><span class="line">    &#123;&quot;name&quot;:&quot;last_declinepay_amt&quot;,&quot;type&quot;:&quot;double&quot;,&quot;nullable&quot;:true,&quot;metadata&quot;:&#123;&#125;&#125;,</span><br><span class="line">    &#123;&quot;name&quot;:&quot;last_declinepay_cnt&quot;,&quot;type&quot;:&quot;double&quot;,&quot;nullable&quot;:true,&quot;metadata&quot;:&#123;&#125;&#125;,</span><br><span class="line">    &#123;&quot;name&quot;:&quot;last_realpay_amt&quot;,&quot;type&quot;:&quot;double&quot;,&quot;nullable&quot;:true,&quot;metadata&quot;:&#123;&#125;&#125;,</span><br><span class="line">    &#123;&quot;name&quot;:&quot;last_realpay_cnt&quot;,&quot;type&quot;:&quot;double&quot;,&quot;nullable&quot;:true,&quot;metadata&quot;:&#123;&#125;&#125;,</span><br><span class="line">    &#123;&quot;name&quot;:&quot;pol_num&quot;,&quot;type&quot;:&quot;double&quot;,&quot;nullable&quot;:true,&quot;metadata&quot;:&#123;&#125;&#125;,</span><br><span class="line">    &#123;&quot;name&quot;:&quot;prem_sum&quot;,&quot;type&quot;:&quot;double&quot;,&quot;nullable&quot;:true,&quot;metadata&quot;:&#123;&#125;&#125;,</span><br><span class="line">    &#123;&quot;name&quot;:&quot;prt_accidentdate_del&quot;,&quot;type&quot;:&quot;double&quot;,&quot;nullable&quot;:true,&quot;metadata&quot;:&#123;&#125;&#125;,</span><br><span class="line">    &#123;&quot;name&quot;:&quot;self_pol&quot;,&quot;type&quot;:&quot;double&quot;,&quot;nullable&quot;:true,&quot;metadata&quot;:&#123;&#125;&#125;,</span><br><span class="line">    &#123;&quot;name&quot;:&quot;tabfeemoney&quot;,&quot;type&quot;:&quot;double&quot;,&quot;nullable&quot;:false,&quot;metadata&quot;:&#123;&#125;&#125;,</span><br><span class="line">    &#123;&quot;name&quot;:&quot;tbr_accilccont_cnt&quot;,&quot;type&quot;:&quot;double&quot;,&quot;nullable&quot;:false,&quot;metadata&quot;:&#123;&#125;&#125;,</span><br><span class="line">    &#123;&quot;name&quot;:&quot;tbr_age&quot;,&quot;type&quot;:&quot;double&quot;,&quot;nullable&quot;:false,&quot;metadata&quot;:&#123;&#125;&#125;,</span><br><span class="line">    &#123;&quot;name&quot;:&quot;tbr_appntsex&quot;,&quot;type&quot;:&quot;double&quot;,&quot;nullable&quot;:false,&quot;metadata&quot;:&#123;&#125;&#125;,</span><br><span class="line">    &#123;&quot;name&quot;:&quot;tbr_lccont_cnt&quot;,&quot;type&quot;:&quot;double&quot;,&quot;nullable&quot;:false,&quot;metadata&quot;:&#123;&#125;&#125;,</span><br><span class="line">    &#123;&quot;name&quot;:&quot;tbr_marriage&quot;,&quot;type&quot;:&quot;double&quot;,&quot;nullable&quot;:false,&quot;metadata&quot;:&#123;&#125;&#125;,</span><br><span class="line">    &#123;&quot;name&quot;:&quot;tbr_year_prem&quot;,&quot;type&quot;:&quot;double&quot;,&quot;nullable&quot;:false,&quot;metadata&quot;:&#123;&#125;&#125;,</span><br><span class="line">    &#123;&quot;name&quot;:&quot;bit_result&quot;,&quot;type&quot;:&quot;string&quot;,&quot;nullable&quot;:true,&quot;metadata&quot;:&#123;&#125;&#125;</span><br><span class="line">    ]</span><br><span class="line">  &#125;&#125;</span><br></pre></td></tr></table></figure>

<ul>
<li>sqoop生成的如下:</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">avro.schema&#x3D;&#123;</span><br><span class="line">  &quot;type&quot;:&quot;record&quot;,</span><br><span class="line">  &quot;name&quot;:&quot;dw_data_table&quot;,</span><br><span class="line">  &quot;doc&quot;:&quot;Sqoop import of dw_data_table&quot;,</span><br><span class="line">  &quot;fields&quot;:[</span><br><span class="line">    &#123;&quot;name&quot;:&quot;TABLE_ID&quot;,&quot;type&quot;:[&quot;null&quot;,&quot;long&quot;],&quot;default&quot;:null,&quot;columnName&quot;:&quot;TABLE_ID&quot;,&quot;sqlType&quot;:&quot;-5&quot;&#125;,</span><br><span class="line">    &#123;&quot;name&quot;:&quot;TABLE_NAME&quot;,&quot;type&quot;:[&quot;null&quot;,&quot;string&quot;],&quot;default&quot;:null,&quot;columnName&quot;:&quot;TABLE_NAME&quot;,&quot;sqlType&quot;:&quot;12&quot;&#125;,</span><br><span class="line">    &#123;&quot;name&quot;:&quot;TABLE_TYPE&quot;,&quot;type&quot;:[&quot;null&quot;,&quot;int&quot;],&quot;default&quot;:null,&quot;columnName&quot;:&quot;TABLE_TYPE&quot;,&quot;sqlType&quot;:&quot;4&quot;&#125;,</span><br><span class="line">    &#123;&quot;name&quot;:&quot;DW_ID&quot;,&quot;type&quot;:[&quot;null&quot;,&quot;long&quot;],&quot;default&quot;:null,&quot;columnName&quot;:&quot;DW_ID&quot;,&quot;sqlType&quot;:&quot;-5&quot;&#125;,</span><br><span class="line">    &#123;&quot;name&quot;:&quot;NODE_INSTANCE_ID&quot;,&quot;type&quot;:[&quot;null&quot;,&quot;long&quot;],&quot;default&quot;:null,&quot;columnName&quot;:&quot;NODE_INSTANCE_ID&quot;,&quot;sqlType&quot;:&quot;-5&quot;&#125;,</span><br><span class="line">    &#123;&quot;name&quot;:&quot;COLUMNS&quot;,&quot;type&quot;:[&quot;null&quot;,&quot;long&quot;],&quot;default&quot;:null,&quot;columnName&quot;:&quot;COLUMNS&quot;,&quot;sqlType&quot;:&quot;-5&quot;&#125;,</span><br><span class="line">    &#123;&quot;name&quot;:&quot;TABLE_ROWS&quot;,&quot;type&quot;:[&quot;null&quot;,&quot;long&quot;],&quot;default&quot;:null,&quot;columnName&quot;:&quot;TABLE_ROWS&quot;,&quot;sqlType&quot;:&quot;-5&quot;&#125;,</span><br><span class="line">    &#123;&quot;name&quot;:&quot;FILE_SIZE&quot;,&quot;type&quot;:[&quot;null&quot;,&quot;long&quot;],&quot;default&quot;:null,&quot;columnName&quot;:&quot;FILE_SIZE&quot;,&quot;sqlType&quot;:&quot;-5&quot;&#125;,</span><br><span class="line">    &#123;&quot;name&quot;:&quot;FILE_PATH&quot;,&quot;type&quot;:[&quot;null&quot;,&quot;string&quot;],&quot;default&quot;:null,&quot;columnName&quot;:&quot;FILE_PATH&quot;,&quot;sqlType&quot;:&quot;12&quot;&#125;,</span><br><span class="line">    &#123;&quot;name&quot;:&quot;MODIFY_TIME&quot;,&quot;type&quot;:[&quot;null&quot;,&quot;long&quot;],&quot;default&quot;:null,&quot;columnName&quot;:&quot;MODIFY_TIME&quot;,&quot;sqlType&quot;:&quot;93&quot;&#125;,</span><br><span class="line">    &#123;&quot;name&quot;:&quot;STORAGE_TYPE&quot;,&quot;type&quot;:[&quot;null&quot;,&quot;int&quot;],&quot;default&quot;:null,&quot;columnName&quot;:&quot;STORAGE_TYPE&quot;,&quot;sqlType&quot;:&quot;4&quot;&#125;,</span><br><span class="line">    &#123;&quot;name&quot;:&quot;TABLE_DESC&quot;,&quot;type&quot;:[&quot;null&quot;,&quot;string&quot;],&quot;default&quot;:null,&quot;columnName&quot;:&quot;TABLE_DESC&quot;,&quot;sqlType&quot;:&quot;12&quot;&#125;,</span><br><span class="line">    &#123;&quot;name&quot;:&quot;STATUS&quot;,&quot;type&quot;:[&quot;null&quot;,&quot;int&quot;],&quot;default&quot;:null,&quot;columnName&quot;:&quot;STATUS&quot;,&quot;sqlType&quot;:&quot;4&quot;&#125;,</span><br><span class="line">    &#123;&quot;name&quot;:&quot;LAST_UPDATE_TIME&quot;,&quot;type&quot;:[&quot;null&quot;,&quot;long&quot;],&quot;default&quot;:null,&quot;columnName&quot;:&quot;LAST_UPDATE_TIME&quot;,&quot;sqlType&quot;:&quot;93&quot;&#125;,</span><br><span class="line">    &#123;&quot;name&quot;:&quot;LAST_UPDATE_OPER&quot;,&quot;type&quot;:[&quot;null&quot;,&quot;string&quot;],&quot;default&quot;:null,&quot;columnName&quot;:&quot;LAST_UPDATE_OPER&quot;,&quot;sqlType&quot;:&quot;12&quot;&#125;,</span><br><span class="line">    &#123;&quot;name&quot;:&quot;CREATE_TIME&quot;,&quot;type&quot;:[&quot;null&quot;,&quot;long&quot;],&quot;default&quot;:null,&quot;columnName&quot;:&quot;CREATE_TIME&quot;,&quot;sqlType&quot;:&quot;93&quot;&#125;,</span><br><span class="line">    &#123;&quot;name&quot;:&quot;CREATE_OPER&quot;,&quot;type&quot;:[&quot;null&quot;,&quot;string&quot;],&quot;default&quot;:null,&quot;columnName&quot;:&quot;CREATE_OPER&quot;,&quot;sqlType&quot;:&quot;12&quot;&#125;,</span><br><span class="line">    &#123;&quot;name&quot;:&quot;TABLE_SCHEMA&quot;,&quot;type&quot;:[&quot;null&quot;,&quot;bytes&quot;],&quot;default&quot;:null,&quot;columnName&quot;:&quot;TABLE_SCHEMA&quot;,&quot;sqlType&quot;:&quot;-4&quot;&#125;</span><br><span class="line">    ],</span><br><span class="line">  &quot;tableName&quot;:&quot;dw_data_table&quot;&#125;&#125;</span><br></pre></td></tr></table></figure>




<h3 id="BlockMetaData"><a href="#BlockMetaData" class="headerlink" title="BlockMetaData"></a>BlockMetaData</h3><p>row group元数据</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">BlockMetaData</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> List&lt;ColumnChunkMetaData&gt; columns = <span class="keyword">new</span> ArrayList();</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">long</span> rowCount;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">long</span> totalByteSize;</span><br><span class="line">    <span class="keyword">private</span> String path;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="MessageType"><a href="#MessageType" class="headerlink" title="MessageType"></a>MessageType</h3><p>MessageType 是 GroupType 的子类，代表Parquet描述数据字段的schema的根节点</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">final</span> <span class="class"><span class="keyword">class</span> <span class="title">MessageType</span> <span class="keyword">extends</span> <span class="title">GroupType</span> </span>&#123;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h2 id="2、数据类型相关类"><a href="#2、数据类型相关类" class="headerlink" title="2、数据类型相关类"></a>2、数据类型相关类</h2><h3 id="Type"><a href="#Type" class="headerlink" title="Type"></a>Type</h3><p>抽象类Type封装了当前字段的名称、重复类型（Repetition）、以及逻辑类型（OriginalType）。</p>
<p>其中OriginalType中对应关系：</p>
<table>
<thead>
<tr>
<th>MAP</th>
<th>LIST</th>
<th>UTF8</th>
<th>MAP_KEY_VALUE</th>
<th>ENUM</th>
<th>DECIMAL</th>
</tr>
</thead>
<tbody><tr>
<td>哈希映射表Map</td>
<td>线性表List</td>
<td>UTF8编码的字符串</td>
<td>包含键值对的Map</td>
<td>枚举类型</td>
<td>十进制数</td>
</tr>
</tbody></table>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="class"><span class="keyword">class</span> <span class="title">Type</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> String name;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> Type.Repetition repetition;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> OriginalType originalType;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> Type.ID id;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><strong>Type 有两个子类PrimitiveType和GroupType</strong>，分别代表Parquet支持的原始数据类型和Group多个字段的组合类型。</p>
<h3 id="GroupType"><a href="#GroupType" class="headerlink" title="GroupType"></a>GroupType</h3><p>多个字段的组合类型</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">GroupType</span> <span class="keyword">extends</span> <span class="title">Type</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> List&lt;Type&gt; fields;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> Map&lt;String, Integer&gt; indexByName;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="PrimitiveType"><a href="#PrimitiveType" class="headerlink" title="PrimitiveType"></a>PrimitiveType</h3><p>Parquet支持的原始数据类型</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">final</span> <span class="class"><span class="keyword">class</span> <span class="title">PrimitiveType</span> <span class="keyword">extends</span> <span class="title">Type</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> PrimitiveType.PrimitiveTypeName primitive;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">int</span> length;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> DecimalMetadata decimalMeta;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="3、Group相关"><a href="#3、Group相关" class="headerlink" title="3、Group相关"></a>3、Group相关</h2><h3 id="Group"><a href="#Group" class="headerlink" title="Group"></a>Group</h3><p>抽象类Group表示包含一组字段的Parquet schema节点类型，封装了各种类型的 add方法和get方法</p>
<h3 id="SimpleGroup"><a href="#SimpleGroup" class="headerlink" title="SimpleGroup"></a>SimpleGroup</h3><p>SimpleGroup是Group的一个子类，一个最简单形式的Group：包含一个GroupType 和字段数据。</p>
<p>GroupType表示Group类型。</p>
<p><code>List&lt;Object&gt;[] data</code>保存该Group中的字段数据，各字段在List数组中的顺序和GroupType中定义的一致。List列表中既可以保存Primitive类型的原始数据类型，也可以保存一个Group。也就是说一个SimpleGroup类型可以表示由schema表示的一行记录。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">public class SimpleGroup extends Group &#123;</span><br><span class="line">  private final GroupType schema;</span><br><span class="line">  private final List&lt;Object&gt;[] data;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://my.oschina.net/jhone/blog/517918" target="_blank" rel="noopener">列式存储 Parquet</a></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://longzl2015.github.io/2016/04/02/hadoop%E7%94%9F%E6%80%81/sqoop/sqoop%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="zhoul">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2016/04/02/hadoop%E7%94%9F%E6%80%81/sqoop/sqoop%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/" class="post-title-link" itemprop="url">sqoop 常用操作</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2016-04-02 22:46:48" itemprop="dateCreated datePublished" datetime="2016-04-02T22:46:48+08:00">2016-04-02</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-02-27 17:16:07" itemprop="dateModified" datetime="2020-02-27T17:16:07+08:00">2020-02-27</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/hadoop%E7%94%9F%E6%80%81/" itemprop="url" rel="index">
                    <span itemprop="name">hadoop生态</span>
                  </a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/hadoop%E7%94%9F%E6%80%81/sqoop/" itemprop="url" rel="index">
                    <span itemprop="name">sqoop</span>
                  </a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="fa fa-comment-o"></i>
      </span>
      <span class="post-meta-item-text">Disqus：</span>
    
    <a title="disqus" href="/2016/04/02/hadoop%E7%94%9F%E6%80%81/sqoop/sqoop%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/#comments" itemprop="discussionUrl">
      <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2016/04/02/hadoop生态/sqoop/sqoop常用命令/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="sqoop导入到hdfs命令"><a href="#sqoop导入到hdfs命令" class="headerlink" title="sqoop导入到hdfs命令"></a>sqoop导入到hdfs命令</h2><h3 id="指定parquet类型"><a href="#指定parquet类型" class="headerlink" title="指定parquet类型"></a>指定parquet类型</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sqoop import --connect jdbc:mysql:&#x2F;&#x2F;10.100.1.30:3306&#x2F;zy-ds --username root --password root --table users --delete-target-dir --target-dir &#x2F;user&#x2F;mls&#x2F;dw_data&#x2F;2&#x2F; --as-parquetfile;</span><br></pre></td></tr></table></figure>


<h2 id="sqoop导入hive命令"><a href="#sqoop导入hive命令" class="headerlink" title="sqoop导入hive命令"></a>sqoop导入hive命令</h2><h3 id="增量导入"><a href="#增量导入" class="headerlink" title="增量导入"></a>增量导入</h3><ol>
<li>简单的增量导入,需自行确定时间分片</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sqoop import --connect jdbc:mysql:&#x2F;&#x2F;10.100.1.30:3306&#x2F;zy-ds2 --username root --password root --table calls --delete-target-dir --hive-import --hive-database zyds --hive-table calls -m 1 --where &quot;split_date&#x3D;&#39;20170101&#39;&quot;;</span><br></pre></td></tr></table></figure>

<ol start="2">
<li>使用 <code>--incremental</code><br>incremental 有两种模式：append 和 lastmodified。目前 hive import 暂不支持 append 模式。<br>incremental 需要跟随两个参数（以下只针对 lastmodified 说明）：</li>
</ol>
<ul>
<li>check-column 必须是 <code>timestamp</code> 和 <code>date</code> 类型。（对于 db2 ：check-column的列名必须<code>大写</code>）</li>
<li>last-value 需要大于之前的最大值，一般取 <code>字段最大值 +1</code></li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sqoop import --connect jdbc:mysql:&#x2F;&#x2F;10.100.1.30:3306&#x2F;zy-ds2 --username root --password root --table calls --delete-target-dir --hive-import --hive-database zyds --hive-table calls -m 1 --incremental lastmodified --check-column crt_date --last-value &quot;2015-11-25 12:41:40&quot;</span><br></pre></td></tr></table></figure>

<h3 id="全量导入"><a href="#全量导入" class="headerlink" title="全量导入"></a>全量导入</h3><p>其实就是将原有覆盖写入</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sqoop import --connect jdbc:mysql:&#x2F;&#x2F;10.100.1.30:3306&#x2F;zy-ds2 --username root --password root --table calls --delete-target-dir --hive-import --hive-database zyds --hive-table calls -m 1 --hive-overwrite;</span><br></pre></td></tr></table></figure>

<h2 id="取消SSL警告"><a href="#取消SSL警告" class="headerlink" title="取消SSL警告"></a>取消SSL警告</h2><h3 id="警告如下："><a href="#警告如下：" class="headerlink" title="警告如下："></a>警告如下：</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Tue Aug 09 10:29:43 CST 2016 WARN: Establishing SSL connection without server&#39;s identity verification is not recommended. According to MySQL 5.5.45+, 5.6.26+ and 5.7.6+ requirements SSL connection must be established by default if explicit option isn&#39;t set. For compliance with existing applications not using SSL the verifyServerCertificate property is set to &#39;false&#39;. You need either to explicitly disable SSL by setting useSSL&#x3D;false, or set useSSL&#x3D;true and provide truststore for server certificate verification.</span><br></pre></td></tr></table></figure>
<h3 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h3><p> 产生报警的原因是因为，我搭建的Hive使用MySql作为metadata的存储，而MySql为5.7.12版本，需要在连接串中指定是否采用SSL连接。</p>
<p>所以我们只需修改Hive的 hive-site.xml，在连接串中加入指定SSL为false即可：</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionURL<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>jdbc:mysql://ut07:3306/hive?createDatabaseIfNotExist=true<span class="symbol">&amp;amp;</span>useUnicode=true<span class="symbol">&amp;amp;</span>characterEncoding=UTF-8<span class="symbol">&amp;amp;</span>useSSL=false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>

<h2 id="实践中遇到的问题"><a href="#实践中遇到的问题" class="headerlink" title="实践中遇到的问题"></a>实践中遇到的问题</h2><h3 id="1-Mysql-导到-hive-命令（单表导入命令）："><a href="#1-Mysql-导到-hive-命令（单表导入命令）：" class="headerlink" title="1. Mysql 导到 hive 命令（单表导入命令）："></a>1. Mysql 导到 hive 命令（单表导入命令）：</h3><p>进入/sqoop/bin目录下，执行如下语句:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">.&#x2F;sqoop import --connect jdbc:mysql:&#x2F;&#x2F;10.100.1.30:3306&#x2F;zy-ds2 --username root --password root --table calls --hive-import --hive-database zyds --hive-table calls -m 1;</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">--connect         jdbc:mysql:&#x2F;&#x2F;10.100.1.30:3306&#x2F;zy-ds2为数据库url</span><br><span class="line">--username root --password root 为数据库用户名密码</span><br><span class="line">--table calls         导入表</span><br><span class="line">--hive-database  zyds 导入至hive内的数据库名</span><br><span class="line">--hive-table calls    导入至hive内的表名</span><br><span class="line">-m 1                  表示启动几个map任务来读取数据（如果数据库中的表没有主键这个参数是必须设置的而且只能设定为1 ）</span><br></pre></td></tr></table></figure>
<h3 id="db2-导入到-hive"><a href="#db2-导入到-hive" class="headerlink" title="db2 导入到 hive"></a>db2 导入到 hive</h3><p>若要使用DB2可将 db2jcc.jar 和 db2jcc_license_cu.jar加入sqoop的lib目录</p>
<h4 id="1-1-FileAlreadyExistsException"><a href="#1-1-FileAlreadyExistsException" class="headerlink" title="1.1 FileAlreadyExistsException"></a>1.1 FileAlreadyExistsException</h4><pre><code>17/02/17 12:27:02 ERROR tool.ImportTool: Encountered IOException running import job: org.apache.hadoop.mapred.FileAlreadyExistsException: Output directory hdfs://master:9000/user/hadoop/calls already exists</code></pre><p>解决方法: </p>
<blockquote>
<p>hadoop dfs -rm -r 相应目录。</p>
</blockquote>
<p>或者<br>运行 sqoop 时添加 <code>--delete-target-dir</code> 参数 （放在hive-import 之前）</p>
<h4 id="1-2-已经存在相应的表"><a href="#1-2-已经存在相应的表" class="headerlink" title="1.2 已经存在相应的表"></a>1.2 已经存在相应的表</h4><p>如果hive数据库已经存在相应的表，可以通过添加参数  <code>--hive-overwrite</code>（放在hive-import 之后）</p>
<h3 id="2-Mysql-gt-hive-命令（多表导入命令）："><a href="#2-Mysql-gt-hive-命令（多表导入命令）：" class="headerlink" title="2. Mysql =&gt; hive 命令（多表导入命令）："></a>2. Mysql =&gt; hive 命令（多表导入命令）：</h3><p>使用<code>sqoop-import-all-tables</code>命令实现多表导入。</p>
<p>在使用多表导入之前，以下三个条件必须同时满足：<br>           1、每个表必须都只有一个列作为主键；<br>           2、必须将每个表中所有的数据导入，而不是部分；<br>           3、你必须使用默认分隔列，且WHERE子句无任何强加的条件</p>
<h4 id="2-1-例子"><a href="#2-1-例子" class="headerlink" title="2.1 例子"></a>2.1 例子</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sqoop import-all-tables --connect jdbc:mysql:&#x2F;&#x2F;10.100.1.30:3306&#x2F;zy-ds2 --username root --password root --hive-import --hive-database zyds -m 2</span><br></pre></td></tr></table></figure>

<p>如需指定 hdfs 目录 可加参数 <code>--warehouse-dir=&#39;/user/zl/&#39;</code></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://longzl2015.github.io/2016/04/02/hadoop%E7%94%9F%E6%80%81/yarn%E6%A1%86%E6%9E%B6/NodeManager/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="zhoul">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2016/04/02/hadoop%E7%94%9F%E6%80%81/yarn%E6%A1%86%E6%9E%B6/NodeManager/" class="post-title-link" itemprop="url">NodeManager介绍</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2016-04-02 22:46:48" itemprop="dateCreated datePublished" datetime="2016-04-02T22:46:48+08:00">2016-04-02</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-02-27 17:16:07" itemprop="dateModified" datetime="2020-02-27T17:16:07+08:00">2020-02-27</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/hadoop%E7%94%9F%E6%80%81/" itemprop="url" rel="index">
                    <span itemprop="name">hadoop生态</span>
                  </a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/hadoop%E7%94%9F%E6%80%81/yarn/" itemprop="url" rel="index">
                    <span itemprop="name">yarn</span>
                  </a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="fa fa-comment-o"></i>
      </span>
      <span class="post-meta-item-text">Disqus：</span>
    
    <a title="disqus" href="/2016/04/02/hadoop%E7%94%9F%E6%80%81/yarn%E6%A1%86%E6%9E%B6/NodeManager/#comments" itemprop="discussionUrl">
      <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2016/04/02/hadoop生态/yarn框架/NodeManager/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>NodeManager（NM）是YARN中每个节点上的代理，它管理Hadoop集群中单个计算节点，包括与ResourceManger保持通信，监督Container的生命周期管理，监控每个Container的资源使用（内存、CPU等）情况，追踪节点健康状况，管理日志和不同应用程序用到的附属服务（auxiliary service）。</p>
<p><img src="/images/NodeManager/yarn-state-machine.task-attempt.png" alt="NodeManager"></p>
<h2 id="1-NodeManager内各组件功能"><a href="#1-NodeManager内各组件功能" class="headerlink" title="1 NodeManager内各组件功能"></a>1 NodeManager内各组件功能</h2><h3 id="1-1-NodeStatusUpdater"><a href="#1-1-NodeStatusUpdater" class="headerlink" title="1.1 NodeStatusUpdater"></a>1.1 NodeStatusUpdater</h3><p>当NM启动时，该组件向RM注册，并发送节点上可用资源。接下来，NM与RM通信，汇报各个Container的状态更新，包括节点上正运行的Container、已完成的Contaner等。<br>此外，RM可能向NodeStatusUpdater发信号，杀死处于运行中的Container。</p>
<p>注：NodeStatusUpdater是NM与RM通信的唯一通道，它实际上是RPC协议ResourceTracker的client，它周期性地调用RPC函数nodeHeartbeat()向RM汇报本节点上各种信息，包括资源使用情况，各个Container运行情况等。</p>
<h3 id="1-2-ContainerManager"><a href="#1-2-ContainerManager" class="headerlink" title="1.2 ContainerManager"></a>1.2 ContainerManager</h3><p>它是NodeManager中核心组件，它由以下几个子组件构成，每个子组件负责一部分功能，以管理运行在该节点上的所有Container。（注意，ContainerManager实际上是个接口，真正的实现是ContainerManagerImpl类）</p>
<h4 id="1-2-1-RPC-Server"><a href="#1-2-1-RPC-Server" class="headerlink" title="1.2.1 RPC Server"></a>1.2.1 RPC Server</h4><p>ContainerManager从各个Application Master上接收RPC请求以启动Container或者停止正在运行的Container。它与ContainerTokenSecretManager（下面将介绍）合作，以对所有请求进行合法性验证。所有作用在正运行Container的操作均会被写入audit-log，以便让安全工具进行后续处理。<br>注：这里的“RPC Server”实际上是RPC协议ContainerManager的server，AM可通过该协议通知某个节点启动或者释放container，ContainerManager定义了三个接口供AM使用：</p>
<blockquote>
<p>StartContainerResponse startContainer(StartContainerRequest request); //启动container<br>StopContainerResponse stopContainer(StopContainerRequest request); //释放container<br>GetContainerStatusResponse getContainerStatus(GetContainerStatusRequest request);//获取container列表。</p>
</blockquote>
<h4 id="1-2-2-ResourceLocalizationService"><a href="#1-2-2-ResourceLocalizationService" class="headerlink" title="1.2.2 ResourceLocalizationService"></a>1.2.2 ResourceLocalizationService</h4><p>负责（从HDFS上）安全地下载和组织Container需要的各种文件资源。它尽量将文件分摊到各个磁盘上。它会为下载的文件添加访问控制限制，并为之施加合适的（磁盘空间）使用上限。</p>
<p>注：该服务会采用多线程方式同时从HDFS上下载文件，并按照文件类型（public或者private文件）存放到不同目录下，并为目录设置严格的访问权限，同时，每个用户可使用的磁盘空间大小也可以设置。</p>
<h4 id="1-2-3-ContainersLauncher"><a href="#1-2-3-ContainersLauncher" class="headerlink" title="1.2.3 ContainersLauncher"></a>1.2.3 ContainersLauncher</h4><p>维护了一个线程池，随时准备并在必要时尽快启动Container，同时，当收到来自RM或者 ApplicationMaster的清理Container请求时，会清理对应的Container进程。</p>
<h4 id="1-2-4-AuxServices"><a href="#1-2-4-AuxServices" class="headerlink" title="1.2.4 AuxServices"></a>1.2.4 AuxServices</h4><p>NM提供了一个框架以通过配置附属服务扩展自己的功能，这允许每个节点定制一些特定框架可能需要的服务，当然，这些服务是与NM其他服务隔离开的（有自己的安全验证机制）。附属服务需要在NM启动之前配置好，且由对应应用程序的运行在本节点上的第一container触发启动。</p>
<h4 id="1-2-5-ContainersMonitor"><a href="#1-2-5-ContainersMonitor" class="headerlink" title="1.2.5 ContainersMonitor"></a>1.2.5 ContainersMonitor</h4><p>当一个Container启动之后，该组件便开始观察它在运行过程中的资源利用率。为了实现资源隔离和公平共享，RM为每个Container分配了一定量的资源。ContainersMonitor持续监控每个Container的利用率，一旦一个Container超出了它的允许使用份额，它将向Container发送信号将其杀掉，这可以避免失控的Container影响了同节点上其他正在运行的Container。（注意，ContainersMonitor实际上是个接口，真正的实现是ContainersMonitorImpl类）。</p>
<p>注：NM启动一个container后，ContainersMonitor会将该container进程对一个的pid添加到监控列表中，以监控以pid为根的整棵进程树的资源使用情况，它周期性地从/etc/proc中获取进程树使用的总资源，一旦发现超过了预期值，则会将其杀死。在最新版YARN中，已采用了Linux container对资源进行隔离。</p>
<h4 id="1-2-6-LogHandler"><a href="#1-2-6-LogHandler" class="headerlink" title="1.2.6 LogHandler"></a>1.2.6 LogHandler</h4><p>一个可插拔组件，用户通过它可选择将Container日志写到本地磁盘上还是将其打包后上传到一个文件系统中。</p>
<h3 id="1-3-ContainerExecutor"><a href="#1-3-ContainerExecutor" class="headerlink" title="1.3 ContainerExecutor"></a>1.3 ContainerExecutor</h3><p>与底层操作系统交互，安全存放Container需要的文件和目录，进而以一种安全的方式启动和清除Container对应的进程。<br>注：在最新版YARN中，已采用了Linux container对资源进行隔离</p>
<h3 id="1-4-NodeHealthCheckerService"><a href="#1-4-NodeHealthCheckerService" class="headerlink" title="1.4 NodeHealthCheckerService"></a>1.4 NodeHealthCheckerService</h3><p>提供以下功能：通过周期性地运行一个配置好的脚本检查节点的健康状况，它也会通过周期性地在磁盘上创建临时文件以监控磁盘健康状况。任何系统健康方面的改变均会通知NodeStatusUpdater（前面已经介绍过），它会进一步将信息传递给RM。</p>
<h3 id="1-5-Security"><a href="#1-5-Security" class="headerlink" title="1.5 Security"></a>1.5 Security</h3><p>（1） ApplicationACLsManager NM需要为所有面向用户的API提供安全检查，如在Web-UI上只能将container日志显示给授权用户。该组件为每个应用程序维护了一个ACL列表，一旦收到类似请求后会利用该列表对其进行验证。<br>（2） ContainerTokenSecretManager 检查收到的各种访问请求的合法性，确保这些请求操作已被RM授权。</p>
<h3 id="1-6-WebServer"><a href="#1-6-WebServer" class="headerlink" title="1.6 WebServer"></a>1.6 WebServer</h3><p>在给定时间点，展示该节点上所有应用程序和container列表，节点健康相关的信息和container产生的日志。</p>
<h2 id="2-主要功能亮点"><a href="#2-主要功能亮点" class="headerlink" title="2 主要功能亮点"></a>2 主要功能亮点</h2><h3 id="2-1-启动Container"><a href="#2-1-启动Container" class="headerlink" title="2.1 启动Container"></a>2.1 启动Container</h3><p>为了能够启动Container，NM期望收到的Container定义了关于它运行时所需的详细信息，包括运行container的命令、环境变量、所需的资源列表和安全令牌等。<br>一旦收到container启动请求，如果YARN启用了安全机制，则NM首先验证请求合法性以对用户和正确的资源分配进行授权。之后，NM将按照以下步骤启动一个container：</p>
<ol>
<li>在本地拷贝一份运行Container所需的所有资源（通过Distributed Cache实现）。</li>
<li>为container创建经隔离的工作目录，并在这些目录中准备好所有（文件）资源。</li>
<li>运行命令启动container</li>
</ol>
<h3 id="2-2-日志聚集"><a href="#2-2-日志聚集" class="headerlink" title="2.2 日志聚集"></a>2.2 日志聚集</h3><p>处理用户日志是过去令人头痛的事情之一。与MRv1不同，NM不再截取日志并将日志留单个节点（TaskTracker）上，而是将日志上传到一个文件系统中，比如HDFS，以此来解决日志管理问题。<br>在某个NM上，所有属于同一个应用程序的container日志经聚集后被写到（可能经过压缩处理）一个FS上的日志文件中，用户可通过YARN命令行工具，WEB-UI或者直接通过FS访问这些日志。</p>
<h3 id="2-3-MapReduce-shuffle如何利用NM的附属服务"><a href="#2-3-MapReduce-shuffle如何利用NM的附属服务" class="headerlink" title="2.3 MapReduce shuffle如何利用NM的附属服务"></a>2.3 MapReduce shuffle如何利用NM的附属服务</h3><p>运行MapReduce程序所需的shuffle功能是通过附属服务实现的，该服务会启动一个Netty Server，它知道如何处理来自Reduce Task的MR相关的shuffle请求。MR（MapReduce） AM（ApplicationMaster）为shuffle服务定义了服务ID，和可能需要的安全令牌，而NM向AM提供shuffle服务的运行端口号，并由AM传递给各个Reduce Task。</p>
<h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><p>在YARN中，NodeManager主要用于管理抽象的container，它只处理container相关的事情，而不必关心每个应用程序（如MapReduce Task）自身的状态管理，它也不再有类似于map slot和reduce slot的slot概念，正是由于上述各个模块间清晰的责任分离，NM可以很容易的扩展，且它的代码也更容易维护。</p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://hortonworks.com/blog/apache-hadoop-yarn-nodemanager/" target="_blank" rel="noopener">介绍NodeManager</a></p>
<p><a href="http://dongxicheng.org/mapreduce-nextgen/nodemanager-architecture/" target="_blank" rel="noopener">董的博客</a></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://longzl2015.github.io/2016/04/02/hadoop%E7%94%9F%E6%80%81/yarn%E6%A1%86%E6%9E%B6/ResourceManager/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="zhoul">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2016/04/02/hadoop%E7%94%9F%E6%80%81/yarn%E6%A1%86%E6%9E%B6/ResourceManager/" class="post-title-link" itemprop="url">ResourceManager</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2016-04-02 22:46:48" itemprop="dateCreated datePublished" datetime="2016-04-02T22:46:48+08:00">2016-04-02</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-02-27 17:16:07" itemprop="dateModified" datetime="2020-02-27T17:16:07+08:00">2020-02-27</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/hadoop%E7%94%9F%E6%80%81/" itemprop="url" rel="index">
                    <span itemprop="name">hadoop生态</span>
                  </a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/hadoop%E7%94%9F%E6%80%81/yarn/" itemprop="url" rel="index">
                    <span itemprop="name">yarn</span>
                  </a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="fa fa-comment-o"></i>
      </span>
      <span class="post-meta-item-text">Disqus：</span>
    
    <a title="disqus" href="/2016/04/02/hadoop%E7%94%9F%E6%80%81/yarn%E6%A1%86%E6%9E%B6/ResourceManager/#comments" itemprop="discussionUrl">
      <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2016/04/02/hadoop生态/yarn框架/ResourceManager/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>##简介 </p>
<p>在YARN中，ResourceManager负责集群中所有资源的统一管理和分配，它接收来自各个节点（NodeManager）的资源汇报信息，并把这些信息按照一定的策略分配给各个应用程序（ApplicationMasters）。</p>
<ol>
<li>NodeManager:  接收来自ResourceManager的信息，并管理单个节点上的可用资源</li>
<li>ApplicationMasters: 负责向ResourceManager申请相关资源，并与NodeManagers一起处理containers的启动</li>
</ol>
<p><img src="/images/ResourceManager/resource_manager.gif" alt="resource_manager"></p>
<h2 id="1-客户端和RM的接口组件"><a href="#1-客户端和RM的接口组件" class="headerlink" title="1 客户端和RM的接口组件"></a>1 客户端和RM的接口组件</h2><ul>
<li><strong>ClientService</strong>: 客户端和Resource Manager的接口。这个组件控制所有从客户端到RM的RPC接口，包括application提交，中断，获取查询信息，集群统计等。</li>
<li><strong>AdminService</strong>: 为了确保管理请求不受普通用户的请求影响，给操作者的命令更高的优先权，所有的管理操作，比如刷新节点列表，队列配置等，都通过这个独立的接口提供服务。</li>
</ul>
<h2 id="2-RM连接节点的组件"><a href="#2-RM连接节点的组件" class="headerlink" title="2 RM连接节点的组件"></a>2 RM连接节点的组件</h2><ul>
<li><strong>ResourceTrackerService</strong>: 这是响应所有节点RPC请求的组件。他负责注册新节点，拒绝任何无效/退役的节点请求，收集节点心跳并发送给YarnScheduler。他和下面说的NMLivelinessMonitor和NodesListManager结合紧密。</li>
<li><strong>NMLivelinessMonitor</strong>: 跟踪活跃的节点，特别关注关闭和死掉得节点，这个组件保持跟踪每个节点的最新心跳时间。任何在设定间隔时间内没有新掉的节点被认为是死掉了，默认是10分钟，被RM认为是失效。所有当时运行在失效节点上的container被标记为死亡，不会有新的container被安排在这个节点。</li>
<li><strong>NodesListManager</strong>: 收集有效和失效节点。通过读取配置文件<code>yarn.resourcemanager.nodes.include-path</code> 和 <code>yarn.resourcemanager.nodes.exclude-path，来初始化节点列表。同时持续跟踪节点失效情况。</code></li>
</ul>
<h2 id="3-和每个AMs交互的组件"><a href="#3-和每个AMs交互的组件" class="headerlink" title="3 和每个AMs交互的组件"></a>3 和每个AMs交互的组件</h2><ul>
<li><strong>ApplicationMasterService</strong>: 这个组件响应所有AMs的RPCs请求。他负责处理注册新的AMs，中断/注销任何完成的AMs，从所有正在运行的AMs获取container分配和处理请求，并发送到YarnScheduler。他和下面说的AMLivelinessMonitor紧密结合。</li>
<li><strong>AMLivelinessMonitor</strong>: 帮助管理活跃AMs和死亡/无响应AMs列表，这个组件持续跟踪每个AM和他的最新心跳时间。任何在配置的间隔时间内无心跳的AM被认为死亡，并从RM里失效，默认是10分钟。所有失效AM的containers也会被标记死亡。RM会安排同一个AM在一个新的container上，最大重试次数是默认是4。</li>
</ul>
<h2 id="4-ResourceManager的核心-–-调度器相关组件"><a href="#4-ResourceManager的核心-–-调度器相关组件" class="headerlink" title="4 ResourceManager的核心 – 调度器相关组件"></a>4 ResourceManager的核心 – 调度器相关组件</h2><ul>
<li><strong>ApplicationsManager</strong>: 负责维护一个已提交applications的集合。保存完成applications缓存，用来给用户的web UI或者命令行请求提供完成applications的信息。</li>
<li><strong>ApplicationACLsManager</strong>: RM需要面对用户通过客户端或者管理者的API请求，并只允许授权的用户。这个组件维护着每个application的ACLs列表，强制接收杀应用和查看应用状态的请求。</li>
<li><strong>ApplicationMasterLauncher</strong>: 维护一个线程池去启动最新提交applications的AMs，以及那些之前由于原因需要退出的applications的AMs。也负责当一个application正常完成或者强制中断后清理AM。</li>
<li><strong>YarnScheduler</strong>: 这个调度者负责根据性能，队列等因素分配资源给各种运行的applications。他基于applications资源请求来执行调度，比如内存，CPU，磁盘，网络等。当前只支持内存，CPU支持很快会完成。</li>
<li><strong>ContainerAllocationExpirer</strong>: 这个组件确保所有已经分配的containers正在被AMs使用，和之后要被启动的container对应的NMs。AMs上运行的是不被信赖的用户代码，分配的资源有可能不被使用，就造成了集群利用率的降低。为了解决这个问题，ContainerAllocationExpirer维护着一个已分配但是没有在相应NM上使用的containers列表。对于任意container，如果对应的NM在配置的时间间隔(默认10分钟)内没有报告给RM这个container已经启动，这个container就被RM认为是死亡了或者失效了。</li>
</ul>
<h2 id="5-TokenSecretManagers-for-security"><a href="#5-TokenSecretManagers-for-security" class="headerlink" title="5 TokenSecretManagers (for security)"></a>5 TokenSecretManagers (for security)</h2><p>   ResourceManager 有几个 SecretManagers负责管理 tokens, secret-keys，用于认证/授权各种RPC接口的请求。一些YARN上的覆盖tokens，secret-keys和secret-managers的细节概要如下：</p>
<ul>
<li><strong>ApplicationTokenSecretManager</strong>: 为了避免从RM发送过来的任意进程的请求，RM使用每个应用的tokens，ApplicationTokens。这个组件保存token在本地内存里直到applications完成，使用他去认证从一个有效AM进程来的任何请求。</li>
<li><strong>ContainerTokenSecretManager</strong>: ContainerTokens的SecretManager是被RM标记的特殊tokens用于给AM一个在指定节点上的container。ContainerTokens被AMs用于创建一个和相应的分配container的NM的连接。这个组件是RM特定的，跟踪相关的主机和secret-keys，并定时更新keys。</li>
<li><strong>RMDelegationTokenSecretManager</strong>: 一个ResourceManager有一个特定的 delegation-token secret-manager. 他负责生成委托token给客户端，客户端可以传给未认证的希望和RM交互的进程。</li>
</ul>
<h2 id="6-DelegationTokenRenewer"><a href="#6-DelegationTokenRenewer" class="headerlink" title="6 DelegationTokenRenewer"></a>6 DelegationTokenRenewer</h2><p>在安全模式，RM是Kerberos认证的，提供更新文件系统的tokens服务给applications代表。这个组件更新已经提交的applications的tokens，只要这个applications在运行中，直到这个tokens不再被更新。</p>
<h2 id="结束"><a href="#结束" class="headerlink" title="结束"></a>结束</h2><p>在YARN里, ResourceManage主要被限制于调度用途，即只可以做系统中可用资源的竞争applications间的仲裁，并不关心每个application的状态管理。由于这种如之前所说的模块化的清晰的责任划分，使用前面说的强大的调度器API，RM能够满足最重要的设计要求 – 可扩展性，支持多种编程模型。</p>
<p>要允许不同的策略实现，RM的调度器是可插拔的，允许不同的策略算法。在未来很长时间，我们会深入挖掘各种特性的性能调度器，确保基于性能保证和队列安排containers。</p>
<h2 id="参考网址"><a href="#参考网址" class="headerlink" title="参考网址"></a>参考网址</h2><p><a href="https://hortonworks.com/blog/apache-hadoop-yarn-resourcemanager/" target="_blank" rel="noopener">介绍resourcemanager</a></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://longzl2015.github.io/2016/04/02/hadoop%E7%94%9F%E6%80%81/yarn%E6%A1%86%E6%9E%B6/Yarn%E6%A6%82%E5%BF%B5%E4%B8%8E%E5%BA%94%E7%94%A8/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="zhoul">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2016/04/02/hadoop%E7%94%9F%E6%80%81/yarn%E6%A1%86%E6%9E%B6/Yarn%E6%A6%82%E5%BF%B5%E4%B8%8E%E5%BA%94%E7%94%A8/" class="post-title-link" itemprop="url">yarn概念与应用</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2016-04-02 22:46:48" itemprop="dateCreated datePublished" datetime="2016-04-02T22:46:48+08:00">2016-04-02</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-02-27 17:16:07" itemprop="dateModified" datetime="2020-02-27T17:16:07+08:00">2020-02-27</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/hadoop%E7%94%9F%E6%80%81/" itemprop="url" rel="index">
                    <span itemprop="name">hadoop生态</span>
                  </a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/hadoop%E7%94%9F%E6%80%81/yarn/" itemprop="url" rel="index">
                    <span itemprop="name">yarn</span>
                  </a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="fa fa-comment-o"></i>
      </span>
      <span class="post-meta-item-text">Disqus：</span>
    
    <a title="disqus" href="/2016/04/02/hadoop%E7%94%9F%E6%80%81/yarn%E6%A1%86%E6%9E%B6/Yarn%E6%A6%82%E5%BF%B5%E4%B8%8E%E5%BA%94%E7%94%A8/#comments" itemprop="discussionUrl">
      <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2016/04/02/hadoop生态/yarn框架/Yarn概念与应用/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>如前面所描述的, YARN 实质上是管理分布式app的系统。他由一个全局的<strong>ResourceManager</strong>和 每一个节点上的<strong>NodeManager</strong>组成。<strong>ResourceManager</strong>用于管理集群所有的可用资源，而每一个节点上的 <strong>NodeManager</strong>用于与ResourceManager沟通并负责管理单节点的可用资源。</p>
<p><img src="/images/Yarn%E6%A6%82%E5%BF%B5%E4%B8%8E%E5%BA%94%E7%94%A8/yarnflow1.png" alt="yarnflow1"></p>
<h2 id="1、Resource-Manager"><a href="#1、Resource-Manager" class="headerlink" title="1、Resource Manager"></a>1、Resource Manager</h2><p>在YARN里, ResourceManager 是一个主要的纯粹的scheduler。从本质上讲，它严格限制系统中可用资源的竞争。它优化了集群利用率（保持所有资源始终处于可用状态），以抵御各种限制，如容量保证，公平性和slas。为了允许不同的策略约束，资源管理器具有可插入的调度器，允许根据需要使用不同的算法，例如容量和公平调度。</p>
<h2 id="2、ApplicationMaster"><a href="#2、ApplicationMaster" class="headerlink" title="2、ApplicationMaster"></a>2、ApplicationMaster</h2><p>许多人会将yarn与现有的hadoop mapreduce系统（apache hadoop 1.x中的MR1）相提并论。然而，他们之间关键的区别：ApplicationMaster概念的加入。</p>
<p>ApplicationMaster 实际上是一个特定框架库的一个实例，负责与ResourceManager协商资源，并与NodeManager（s）一起执行和监视这些容器及其资源消耗。AM的功能就是向ResourceManager申请适当的资源容器，跟踪他们的状态和监测进度。</p>
<p>ApplicationMaster 使 YARN 具有以下几个特性：</p>
<ul>
<li>可扩展：ApplicationMaster提供给传统的ResourceManager很多功能，使整个系统拥有了更好的可扩展性。在测试中，我们已经成功模拟了10000个由现代硬件组成的节点集群，没有出现重大问题。这是我们选择将ResourceManager设计成纯调度器的关键原因之一，它并不试图为资源提供容错。我们将其转移到了ApplicationMaster实例的主要职责上。此外，由于每个应用程序都有一个ApplicationMaster的实例，所以ApplicationMaster本身并不是集群中常见的瓶颈。</li>
<li>开放：将所有应用程序框架特定的代码移动到ApplicationMaster中，以使我们现在可以支持多种框架，比如MapReduce、mpi和图形处理。</li>
</ul>
<p>下面有一些YARN设计的关键点：</p>
<ul>
<li>把所有的复杂性（尽可能的）交给ApplicationMaster，同时提供足够的功能以允许applicaiton-framework的开发者有足够的灵活性和权利。</li>
<li>既然他实际上是用户端代码，所以不必信任ApplicationMasters，即任何ApplicationMaster都不是一个特权服务。</li>
<li>YARN 系统 (ResourceManager 和 NodeManager) 能够保护他们自己免受错误的或者恶意的ApplicationMasters的影响。</li>
</ul>
<p>记住这点是重要的，每个application有它自己的ApplicationMaster实例。然而，ApplicationMaster管理一组applications也是完全可行的（比如Pig或者Hive的ApplicationMaster就管理一系列的MapReduce作业）。此外，这个概念已经被延伸到管理长期运行的服务，这些长期运行的服务管理着他们自己的应用（比如通过一个虚拟的HBaseAppMaster启动HBase）。</p>
<h2 id="3、Resource-Model"><a href="#3、Resource-Model" class="headerlink" title="3、Resource Model"></a>3、Resource Model</h2><p>YARN 给applications提供了一个非常通用的Resource Model。一个application（通过ApplicationMaster）可以请求的资源包括如下：</p>
<ul>
<li>Resource-name (hostname, rackname – 我们正在进一步将其用于支持更复杂的网络拓扑结构).</li>
<li>Memory (in MB)</li>
<li>CPU (cores, for now)</li>
<li>将来, 我们会添加更多的资源类型比如磁盘/网络I/O，GPU等。</li>
</ul>
<h2 id="4、ResourceRequest-and-Container"><a href="#4、ResourceRequest-and-Container" class="headerlink" title="4、ResourceRequest and Container"></a>4、ResourceRequest and Container</h2><p>YARN的设计允许个别应用程序（通过应用程序管理器）以共享，安全和多租户的方式利用集群资源。此外，为了有效地调度和优化数据访问，它使用集群拓扑结构以尽可能减少应用程序的数据移动。</p>
<p>为了实现这些目标，ResourceManager的Scheduler获取了广泛的application的资源需求信息，这样使他能够给集群里所有的applications做出更好的调度决定。这就带给我们了 <strong>ResourceRequest</strong> 和 <strong>Container</strong>.</p>
<h3 id="4-1-ResourceRequest"><a href="#4-1-ResourceRequest" class="headerlink" title="4.1 ResourceRequest"></a>4.1 ResourceRequest</h3><p>一个application可以通过ApplicationMaster请求到足够的资源来满足application的资源需求。调度程序通过授予容器来响应资源请求，该容器满足初始资源请求中由应用程序管理器规定的要求。</p>
<p>看一下 ResourceRequest – 有如下形式：</p>
<blockquote>
<p>&lt;resource-name, priority, resource-requirement, number-of-containers&gt;</p>
</blockquote>
<p>####4.1.1 ResourceRequest的每个组件</p>
<ul>
<li>resource-name:  hostname, rackname 或者 * 表示没有特别要求。在未来，我们希望能够支持更复杂的虚拟机拓扑结构，更复杂的网络等等。</li>
<li>priority: 这个请求的优先级是应用内优先级（强调，这不是跨多个应用程序）。</li>
<li>resource-requirement: 如内存，CPU等（编写时只支持内存和CPU）。。</li>
<li>number-of-containers: 容器个数</li>
</ul>
<h3 id="4-2-Container"><a href="#4-2-Container" class="headerlink" title="4.2 Container"></a>4.2 Container</h3><p>本质上，Container 是资源分配，这是ResourceManager 授予特定ResourceRequest的成功结果。Container为application授予在特定主机上使用特定数量的资源（内存，CPU等）的权限。</p>
<p>ApplicationMaster必须将Container提交给对应的NodeManager，以便使用资源启动其任务。当然，在安全模式下验证容器分配是为了确保 ApplicationMaster(s) 不能在集群中伪造分配。</p>
<h3 id="4-2-1-容器运行期间的容器规格"><a href="#4-2-1-容器运行期间的容器规格" class="headerlink" title="4.2.1 容器运行期间的容器规格"></a>4.2.1 容器运行期间的容器规格</h3><p>如上所述，容器仅仅拥有在集群中的特定计算机上使用指定数量资源的权利，ApplicationMaster必须向NodeManager提供相当多的信息才能真正启动容器。</p>
<p>yarn允许应用程序启动任何进程，而不像hadoop-1.x（aka MR1）中现有的hadoop mapreduce，它不仅仅局限于java应用程序。</p>
<p>yarn容器的启动规范API是平台不可知的，包含：</p>
<ul>
<li>命令行来启动容器内的进程。</li>
<li>环境变量。</li>
<li>机器启动前必需的本地资源，如罐子，共享对象，辅助数据文件等</li>
<li>与安全有关的令牌。</li>
</ul>
<p>这允许ApplicationMaster使用NodeManager来启动容器，从unix / windows上的简单shell脚本到c / java / python进程到完整的虚拟机（例如kvms）。</p>
<h2 id="5、YARN-应用"><a href="#5、YARN-应用" class="headerlink" title="5、YARN - 应用"></a>5、YARN - 应用</h2><p>掌握了上述概念的知识后，概略地说明applications在YARN上的工作原理是有用的。</p>
<p>applications执行包括以下步骤：</p>
<ul>
<li>申请提交。</li>
<li>引导applications的ApplicationMaster实例。</li>
<li>applications执行由ApplicationMaster实例管理。</li>
</ul>
<p>让我们来看一下应用程序的执行顺序（步骤如图所示）：</p>
<ol>
<li>客户端程序提交applications，包括启动特定于applications的ApplicationMaster本身的必要规范。</li>
<li>Resource Manager承担协商指定容器的责任，在该容器中启动ApplicationMaster，然后启动ApplicationMaster。</li>
<li>在启动时，ApplicationMaster向ResourceManager注册 - 注册允许客户端程序查询资源管理器的细节，这使得它可以直接与自己的ApplicationMaster进行通信。</li>
<li>在正常操作期间，ApplicationMaster通过资源请求协议来协商合适的资源容器。</li>
<li>在成功分配容器时，ApplicationMaster通过向NodeManager提供容器启动规范来启动容器。启动规范通常包含允许容器与应用程序管理器本身通信的必要信息。</li>
<li>在容器内执行的应用程序代码然后通过应用程序特定的协议向其应用程序主管提供必要的信息（进度，状态等）。</li>
<li>在应用程序执行期间，提交程序的客户端通过应用程序特定的协议直接与应用程序管理器通信以获取状态，进度更新等。</li>
<li>一旦申请完成，并且所有必要的工作已经完成，申请管理员就会注销资源管理器并关闭，从而允许自己的容器被重新利用。</li>
</ol>
<p><img src="/images/Yarn%E6%A6%82%E5%BF%B5%E4%B8%8E%E5%BA%94%E7%94%A8/yarnflow.png" alt="img"></p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://hortonworks.com/blog/apache-hadoop-yarn-concepts-and-applications/" target="_blank" rel="noopener">APACHE HADOOP YARN – CONCEPTS AND APPLICATIONS</a></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://longzl2015.github.io/2016/04/02/hadoop%E7%94%9F%E6%80%81/yarn%E6%A1%86%E6%9E%B6/hadoop_yarn%E6%A1%86%E6%9E%B6/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="zhoul">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2016/04/02/hadoop%E7%94%9F%E6%80%81/yarn%E6%A1%86%E6%9E%B6/hadoop_yarn%E6%A1%86%E6%9E%B6/" class="post-title-link" itemprop="url">yarn 框架</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2016-04-02 22:46:48" itemprop="dateCreated datePublished" datetime="2016-04-02T22:46:48+08:00">2016-04-02</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-02-27 17:16:07" itemprop="dateModified" datetime="2020-02-27T17:16:07+08:00">2020-02-27</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/hadoop%E7%94%9F%E6%80%81/" itemprop="url" rel="index">
                    <span itemprop="name">hadoop生态</span>
                  </a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/hadoop%E7%94%9F%E6%80%81/yarn/" itemprop="url" rel="index">
                    <span itemprop="name">yarn</span>
                  </a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="fa fa-comment-o"></i>
      </span>
      <span class="post-meta-item-text">Disqus：</span>
    
    <a title="disqus" href="/2016/04/02/hadoop%E7%94%9F%E6%80%81/yarn%E6%A1%86%E6%9E%B6/hadoop_yarn%E6%A1%86%E6%9E%B6/#comments" itemprop="discussionUrl">
      <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2016/04/02/hadoop生态/yarn框架/hadoop_yarn框架/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="一、Apache-Hadoop-MapReduce"><a href="#一、Apache-Hadoop-MapReduce" class="headerlink" title="一、Apache Hadoop MapReduce"></a>一、Apache Hadoop MapReduce</h2><p>Apache Hadoop MapReduce是一个Google MapReduce编程模型的开源版本，由Apache基金会维护。现在，已经有人花了超过6年的时间在Hadoop上。但是，基本上MapReduce基本上可以分为三个主要部分：</p>
<ul>
<li>MapReduce API：提供给终端用户（程序猿）开发MR程序的接口；</li>
<li>MapReduce 框架：MR各个过程（phrase）的实现，如：map phrase、reduce phrase、sort/shuffle/merge phrase等；</li>
<li>MapReduce 系统：运行用户MR程序的后端基础设施，用以管理资源、调度任务等。</li>
</ul>
<p>将MR分成以上三个概念非常的重要，特别是对终端用户，他们可以完全专注于MR逻辑代码的编写，只需要通过API既可，由MR系统来解决资源管理、容错、调度的问题，而不需要用户考虑后端框架和系统的细节。</p>
<p>现在工业界大部分还是用的0.23之前的版本（至少我待的公司还是0.20.2），老版本的MapReduce系统是简易的Master-Slaves结构，具体名字叫JobTracker-TaskTracker。</p>
<p>JobTracker负责资源的管理（结点资源、计算资源等）以及任务生命周期管理（任务调度、进度查看、容错等）。而TaskTracker职责非常简单，开启/销毁任务，向JobTracker汇报任务状态。</p>
<p>旧版的架构其实挺清晰的，不过也有很多不足的地方，业界一直嚷着要给MR一次大整修（Overhaul），JobTracker的可靠性是一直被诟病的一点（虽然我没见它挂过，但是风险一直存在着），但是除了JobTracker的单点问题，其它的问题也需要一一列出来。</p>
<h3 id="1-1-不支持其它编程模型"><a href="#1-1-不支持其它编程模型" class="headerlink" title="1.1 不支持其它编程模型"></a>1.1 不支持其它编程模型</h3><p>MapReduce对大多数应用（尤其是大数据统计分析）来说，都非常合适。但是有的时候，可能现实生活也有其它的编程模型，如图算法(<a href="http://www.csdn.net/article/2012-08-20/2808870" target="_blank" rel="noopener">Google Pregel</a>/<a href="http://giraph.apache.org/" target="_blank" rel="noopener">Apache Giapah</a>)或者是迭代式模型(<a href="http://en.wikipedia.org/wiki/Message_Passing_Interface" target="_blank" rel="noopener">MPI</a>)。当企业的所有数据在放在了HDFS上，有多种处理数据的方式就很重要了。</p>
<p>而且，MR本质上是面向批处理的，并不支持实时或接近实时的处理请求，但是业界也希望Hadoop能支持实时计算。（我也一直希望可以支持实时计算，但是有时候觉得有点贪心，专注做一项不就好了么？但是好像人的贪欲是无穷的）</p>
<p>有了以上的需求，为了降低了管理者使用成本，减少数据在HDFS和其它存储设备的迁移，Hadoop开发组织重新投入了Hadoop设计。</p>
<h3 id="1-2-低可扩展性"><a href="#1-2-低可扩展性" class="headerlink" title="1.2 低可扩展性"></a>1.2 低可扩展性</h3><p>摩尔定律一直在生效，也让商用服务器的性能一直提高，以下就是一台商用服务器在不同时间的配置：</p>
<ul>
<li>2009 - 8 cores, 16GB of RAM, 4*1TB disk</li>
<li>2012 - 16+ cores, 48-96GB of RAM, 12<em>2TB or 12</em>3TB of disk</li>
</ul>
<p>按照上面的配置，大约2-3年，服务器的配置就可以翻翻。而现在的Hadoop集群就只能支持10,000个节点和200,000个核。Hadoop软件需要赶上硬件的速度是非常重要的。顺带说句，我们公司的计算型服务器就是16cores 64GB of RAM。</p>
<h3 id="1-3-服务器的低利用率"><a href="#1-3-服务器的低利用率" class="headerlink" title="1.3 服务器的低利用率"></a>1.3 服务器的低利用率</h3><p>在现在的系统中，JobTracker将管理集群视为很多的Map/Reduce槽（slot），然而在MR用运行的时候，大多数时候都是reduce槽在等待map槽完成（map 100% reduce 0%）。如果能优化这个的话，服务器就可以得到最大的利用。</p>
<h3 id="1-4-使用的灵活性"><a href="#1-4-使用的灵活性" class="headerlink" title="1.4 使用的灵活性"></a>1.4 使用的灵活性</h3><p>在现实生产环境中，Hadoop常常被部署成一个共享的、多用户的系统。这样就会导致一种情况，完全Hadoop软件可能会影响到整个部门。用户希望能够控制hadoop软件栈升级，因此，允许多版本的MapReduce框架并存对Hadoop来说就是很重要的了。</p>
<h2 id="二、Apache-Hadoop-YARN"><a href="#二、Apache-Hadoop-YARN" class="headerlink" title="二、Apache Hadoop YARN"></a>二、Apache Hadoop YARN</h2><p>YARN的基本思想是将JobTracker的两个主要职责给解耦：资源管理和任务管理（监控/调度），YARN将其分成了两个部分：全局的<code>ResourceManager(RM)</code>和给每个应用分配的<code>ApplicationMaster(AM)</code>。</p>
<h3 id="2-1-ResourceManager"><a href="#2-1-ResourceManager" class="headerlink" title="2.1 ResourceManager"></a>2.1 ResourceManager</h3><p>ResourceManager和它每个节点的slave——NodeManager(NM)，形成了一个全新的、用以管理应用的分布式系统。</p>
<p>RM是系统资源的终极管理者，而AM则是一个特定应用框架的实体（每次提交任务的时候，需要编写相应的应用框架，现在只支持MapReduce），需要与RM索要应用资源，和NM一起执行和监控任务。</p>
<p>RM中有调度器，而调度器内嵌有策略可插拔的插件，主要负责将集群中得资源分配给多个队列和应用。当前MapReduce的调度器，如Capacity Scheduler和Fair Scheduler，均可作为该插件。但是调度器的职责仅限于调度任务，并不保证任务的容错性。</p>
<h3 id="2-2-NodeManager"><a href="#2-2-NodeManager" class="headerlink" title="2.2 NodeManager"></a>2.2 NodeManager</h3><p>NodeManager有点类似于TaskTracker，它负责启动应用程序Container（类似于JVM），并监控container的资源（CPU、内存、磁盘、网络等），并将信息上报给ResouceManager。</p>
<p>ApplicationMaster负责向调度器请求合适的container，并监控container的状态以及任务进程。从系统的角度来看，ApplicationMaster本身也是一个普通的container。</p>
<h3 id="2-3-YARN的架构图："><a href="#2-3-YARN的架构图：" class="headerlink" title="2.3 YARN的架构图："></a>2.3 YARN的架构图：</h3><p><img src="/images/hadoop_yarn%E6%A1%86%E6%9E%B6/image002.jpg" alt="image002"></p>
<p>新YARN系统比较重要的一条就是复用了原有的MapReduce框架，而并不需要大的改动，这对现有的MR应用以及用户来说，是非常重要的，具体是怎么复用的，以后再细说。</p>
<p>接下来，Hadoop开发者会深入架构细节，继续提高系统的可扩展性，并让其支持更多的数据处理框架（graph, MPI）并提高集群可用性。</p>
<p>以Hortonworks’ Arun Murthy（YARN开发者）的一段话做结尾吧：</p>
<blockquote>
<p>“People are not going to be comfortable buying a $5 million Hadoop cluster just to do MapReduce and a $2 million cluster to do something else. If you can allow them to run both apps in the same cluster, its not only easier for you in terms of a CapEx perspective … it’s also easier from an operational perspective because you don’t have to have two separate sets of people managing your clusters or two sets of tools for managing your clusters.”</p>
</blockquote>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://longzl2015.github.io/2016/04/02/hadoop%E7%94%9F%E6%80%81/hadoop/%E6%BA%90%E7%A0%81/hadoop_getmerge%E6%BA%90%E7%A0%81/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="zhoul">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2016/04/02/hadoop%E7%94%9F%E6%80%81/hadoop/%E6%BA%90%E7%A0%81/hadoop_getmerge%E6%BA%90%E7%A0%81/" class="post-title-link" itemprop="url">hadoop 源码 - 命令getMerge</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2016-04-02 22:46:48" itemprop="dateCreated datePublished" datetime="2016-04-02T22:46:48+08:00">2016-04-02</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-02-27 17:16:07" itemprop="dateModified" datetime="2020-02-27T17:16:07+08:00">2020-02-27</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/hadoop%E7%94%9F%E6%80%81/" itemprop="url" rel="index">
                    <span itemprop="name">hadoop生态</span>
                  </a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/hadoop%E7%94%9F%E6%80%81/hadoop/" itemprop="url" rel="index">
                    <span itemprop="name">hadoop</span>
                  </a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="fa fa-comment-o"></i>
      </span>
      <span class="post-meta-item-text">Disqus：</span>
    
    <a title="disqus" href="/2016/04/02/hadoop%E7%94%9F%E6%80%81/hadoop/%E6%BA%90%E7%A0%81/hadoop_getmerge%E6%BA%90%E7%A0%81/#comments" itemprop="discussionUrl">
      <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2016/04/02/hadoop生态/hadoop/源码/hadoop_getmerge源码/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p><code>hadoop fs -getMerge</code> 源码位于 <code>hadoop-common</code> 包的 <code>org.apache.hadoop.fs.shell.CopyCommands</code>类中，以下文章以2.7.3版本为例。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CopyCommands</span> </span>&#123;  </span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">registerCommands</span><span class="params">(CommandFactory factory)</span> </span>&#123;</span><br><span class="line">    factory.addClass(Merge.class, "-getmerge");</span><br><span class="line">    factory.addClass(Cp.class, "-cp");</span><br><span class="line">    factory.addClass(CopyFromLocal.class, "-copyFromLocal");</span><br><span class="line">    factory.addClass(CopyToLocal.class, "-copyToLocal");</span><br><span class="line">    factory.addClass(Get.class, "-get");</span><br><span class="line">    factory.addClass(Put.class, "-put");</span><br><span class="line">    factory.addClass(AppendToFile.class, "-appendToFile");</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">/** merge multiple files together */</span></span><br><span class="line">  <span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">Merge</span> <span class="keyword">extends</span> <span class="title">FsCommand</span> </span>&#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> String NAME = <span class="string">"getmerge"</span>;    </span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> String USAGE = <span class="string">"[-nl] &lt;src&gt; &lt;localdst&gt;"</span>;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> String DESCRIPTION =</span><br><span class="line">      <span class="string">"Get all the files in the directories that "</span> +</span><br><span class="line">      <span class="string">"match the source file pattern and merge and sort them to only "</span> +</span><br><span class="line">      <span class="string">"one file on local fs. &lt;src&gt; is kept.\n"</span> +</span><br><span class="line">      <span class="string">"-nl: Add a newline character at the end of each file."</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">protected</span> PathData dst = <span class="keyword">null</span>;</span><br><span class="line">    <span class="keyword">protected</span> String delimiter = <span class="keyword">null</span>;</span><br><span class="line">    <span class="keyword">protected</span> List&lt;PathData&gt; srcs = <span class="keyword">null</span>;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="comment">/** 准备输入输出变量 */</span></span><br><span class="line">    <span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">processOptions</span><span class="params">(LinkedList&lt;String&gt; args)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">      <span class="keyword">try</span> &#123;</span><br><span class="line">        CommandFormat cf = <span class="keyword">new</span> CommandFormat(<span class="number">2</span>, Integer.MAX_VALUE, <span class="string">"nl"</span>);</span><br><span class="line">        cf.parse(args);</span><br><span class="line"></span><br><span class="line">        delimiter = cf.getOpt(<span class="string">"nl"</span>) ? <span class="string">"\n"</span> : <span class="keyword">null</span>;</span><br><span class="line"></span><br><span class="line">        dst = <span class="keyword">new</span> PathData(<span class="keyword">new</span> URI(args.removeLast()), getConf());</span><br><span class="line">        <span class="keyword">if</span> (dst.exists &amp;&amp; dst.stat.isDirectory()) &#123;</span><br><span class="line">          <span class="keyword">throw</span> <span class="keyword">new</span> PathIsDirectoryException(dst.toString());</span><br><span class="line">        &#125;</span><br><span class="line">        srcs = <span class="keyword">new</span> LinkedList&lt;PathData&gt;();</span><br><span class="line">      &#125; <span class="keyword">catch</span> (URISyntaxException e) &#123;</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> IOException(<span class="string">"unexpected URISyntaxException"</span>, e);</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="comment">/** 依次将Input文件流写入outPut文件流*/</span></span><br><span class="line">    <span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">processArguments</span><span class="params">(LinkedList&lt;PathData&gt; items)</span></span></span><br><span class="line"><span class="function">    <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">      <span class="keyword">super</span>.processArguments(items);</span><br><span class="line">      <span class="keyword">if</span> (exitCode != <span class="number">0</span>) &#123; <span class="comment">// check for error collecting paths</span></span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">      &#125;</span><br><span class="line">      FSDataOutputStream out = dst.fs.create(dst.path);</span><br><span class="line">      <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="keyword">for</span> (PathData src : srcs) &#123;</span><br><span class="line">          FSDataInputStream in = src.fs.open(src.path);</span><br><span class="line">          <span class="keyword">try</span> &#123;</span><br><span class="line">            IOUtils.copyBytes(in, out, getConf(), <span class="keyword">false</span>);</span><br><span class="line">            <span class="keyword">if</span> (delimiter != <span class="keyword">null</span>) &#123;</span><br><span class="line">              out.write(delimiter.getBytes(<span class="string">"UTF-8"</span>));</span><br><span class="line">            &#125;</span><br><span class="line">          &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">            in.close();</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">        out.close();</span><br><span class="line">      &#125;      </span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">processNonexistentPath</span><span class="params">(PathData item)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">      exitCode = <span class="number">1</span>; <span class="comment">// flag that a path is bad</span></span><br><span class="line">      <span class="keyword">super</span>.processNonexistentPath(item);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// this command is handled a bit differently than others.  the paths</span></span><br><span class="line">    <span class="comment">// are batched up instead of actually being processed.  this avoids</span></span><br><span class="line">    <span class="comment">// unnecessarily streaming into the merge file and then encountering</span></span><br><span class="line">    <span class="comment">// a path error that should abort the merge</span></span><br><span class="line">    </span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">processPath</span><span class="params">(PathData src)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">      <span class="comment">// for directories, recurse one level to get its files, else skip it</span></span><br><span class="line">      <span class="keyword">if</span> (src.stat.isDirectory()) &#123;</span><br><span class="line">        <span class="keyword">if</span> (getDepth() == <span class="number">0</span>) &#123;</span><br><span class="line">          recursePath(src);</span><br><span class="line">        &#125; <span class="comment">// skip subdirs</span></span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        srcs.add(src);</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>


      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://longzl2015.github.io/2016/04/02/hadoop%E7%94%9F%E6%80%81/yarn%E6%A1%86%E6%9E%B6/%E6%97%A5%E5%BF%97/%E6%97%A5%E5%BF%97%E8%8E%B7%E5%8F%96api/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="zhoul">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2016/04/02/hadoop%E7%94%9F%E6%80%81/yarn%E6%A1%86%E6%9E%B6/%E6%97%A5%E5%BF%97/%E6%97%A5%E5%BF%97%E8%8E%B7%E5%8F%96api/" class="post-title-link" itemprop="url">日志获取API</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2016-04-02 22:46:48" itemprop="dateCreated datePublished" datetime="2016-04-02T22:46:48+08:00">2016-04-02</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-02-27 17:16:07" itemprop="dateModified" datetime="2020-02-27T17:16:07+08:00">2020-02-27</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/hadoop%E7%94%9F%E6%80%81/" itemprop="url" rel="index">
                    <span itemprop="name">hadoop生态</span>
                  </a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/hadoop%E7%94%9F%E6%80%81/yarn/" itemprop="url" rel="index">
                    <span itemprop="name">yarn</span>
                  </a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="fa fa-comment-o"></i>
      </span>
      <span class="post-meta-item-text">Disqus：</span>
    
    <a title="disqus" href="/2016/04/02/hadoop%E7%94%9F%E6%80%81/yarn%E6%A1%86%E6%9E%B6/%E6%97%A5%E5%BF%97/%E6%97%A5%E5%BF%97%E8%8E%B7%E5%8F%96api/#comments" itemprop="discussionUrl">
      <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2016/04/02/hadoop生态/yarn框架/日志/日志获取api/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> test;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.commons.lang.StringUtils;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.FileContext;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.FileStatus;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.Path;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.RemoteIterator;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.security.UserGroupInformation;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.yarn.api.records.ApplicationId;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.yarn.api.records.ApplicationReport;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.yarn.client.api.YarnClient;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.yarn.conf.YarnConfiguration;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.yarn.exceptions.YarnException;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.yarn.logaggregation.AggregatedLogFormat;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.yarn.logaggregation.LogAggregationUtils;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.yarn.util.Times;</span><br><span class="line"><span class="keyword">import</span> org.slf4j.Logger;</span><br><span class="line"><span class="keyword">import</span> org.slf4j.LoggerFactory;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.DataInputStream;</span><br><span class="line"><span class="keyword">import</span> java.io.EOFException;</span><br><span class="line"><span class="keyword">import</span> java.io.FileNotFoundException;</span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">GetLogTask</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> Logger logger = LoggerFactory.getLogger(GetLogTask<span class="class">.<span class="keyword">class</span>)</span>;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">getLog</span><span class="params">(ApplicationId appId, String appOwner, Configuration conf)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        checkLogAggregationEnable(conf);</span><br><span class="line">        <span class="keyword">int</span> resultCode = verifyApplicationState(appId, conf);</span><br><span class="line">        <span class="keyword">if</span> (resultCode != <span class="number">0</span>) &#123;</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> Exception(<span class="string">"Application has not completed."</span> +</span><br><span class="line">                    <span class="string">" Logs are only available after an application completes"</span>);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (appOwner == <span class="keyword">null</span> || appOwner.isEmpty()) &#123;</span><br><span class="line">            appOwner = UserGroupInformation.getCurrentUser().getShortUserName();</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> dumpAllContainersLogs(appId, appOwner, conf);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">private</span> String <span class="title">dumpAllContainersLogs</span><span class="params">(ApplicationId appId, String appOwner, Configuration conf)</span> <span class="keyword">throws</span></span></span><br><span class="line"><span class="function">            Exception </span>&#123;</span><br><span class="line"></span><br><span class="line">        StringBuilder output = <span class="keyword">new</span> StringBuilder();</span><br><span class="line">        Path remoteRootLogDir = <span class="keyword">new</span> Path(conf.get(</span><br><span class="line">                YarnConfiguration.NM_REMOTE_APP_LOG_DIR,</span><br><span class="line">                YarnConfiguration.DEFAULT_NM_REMOTE_APP_LOG_DIR));</span><br><span class="line">        String logDirSuffix = LogAggregationUtils.getRemoteNodeLogDirSuffix(conf);</span><br><span class="line"></span><br><span class="line">        Path remoteAppLogDir = LogAggregationUtils.getRemoteAppLogDir(</span><br><span class="line">                remoteRootLogDir, appId, appOwner, logDirSuffix);</span><br><span class="line">        RemoteIterator&lt;FileStatus&gt; nodeFiles = <span class="keyword">null</span>;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            Path qualifiedLogDir = FileContext.getFileContext(conf).makeQualified(remoteAppLogDir);</span><br><span class="line">            nodeFiles = FileContext.getFileContext(qualifiedLogDir.toUri(), conf).listStatus(remoteAppLogDir);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (FileNotFoundException fnf) &#123;</span><br><span class="line">            logDirNotExist(remoteAppLogDir.toString());</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">boolean</span> foundAnyLogs = <span class="keyword">false</span>;</span><br><span class="line">        <span class="keyword">assert</span> nodeFiles != <span class="keyword">null</span>;</span><br><span class="line"></span><br><span class="line">        <span class="comment">//遍历 所有节点</span></span><br><span class="line">        <span class="keyword">while</span> (nodeFiles.hasNext()) &#123;</span><br><span class="line">            FileStatus thisNodeFile = nodeFiles.next();</span><br><span class="line">            <span class="keyword">if</span> (!thisNodeFile.getPath().getName().endsWith(LogAggregationUtils.TMP_FILE_SUFFIX)) &#123;</span><br><span class="line">                AggregatedLogFormat.LogReader reader = <span class="keyword">new</span> AggregatedLogFormat.LogReader(conf, thisNodeFile.getPath());</span><br><span class="line">                <span class="keyword">try</span> &#123;</span><br><span class="line">                    DataInputStream valueStream;</span><br><span class="line">                    AggregatedLogFormat.LogKey key = <span class="keyword">new</span> AggregatedLogFormat.LogKey();</span><br><span class="line">                    valueStream = reader.next(key);</span><br><span class="line"></span><br><span class="line">                    <span class="keyword">while</span> (valueStream != <span class="keyword">null</span>) &#123;</span><br><span class="line"></span><br><span class="line">                        String containerString = <span class="string">"\n\nContainer: "</span> + key + <span class="string">" on "</span> + thisNodeFile.getPath().getName();</span><br><span class="line">                        output.append(containerString).append(<span class="string">"\n"</span>);</span><br><span class="line">                        output.append(StringUtils.repeat(<span class="string">"="</span>, containerString.length())).append(<span class="string">"\n"</span>);</span><br><span class="line">                        <span class="keyword">while</span> (<span class="keyword">true</span>) &#123;</span><br><span class="line">                            <span class="keyword">try</span> &#123;</span><br><span class="line">                                readContainerLogs(valueStream, output, thisNodeFile.getModificationTime());</span><br><span class="line">                                foundAnyLogs = <span class="keyword">true</span>;</span><br><span class="line">                            &#125; <span class="keyword">catch</span> (EOFException eof) &#123;</span><br><span class="line">                                <span class="keyword">break</span>;</span><br><span class="line">                            &#125;</span><br><span class="line">                        &#125;</span><br><span class="line"></span><br><span class="line">                        <span class="comment">// Next container</span></span><br><span class="line">                        key = <span class="keyword">new</span> AggregatedLogFormat.LogKey();</span><br><span class="line">                        valueStream = reader.next(key);</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">                    reader.close();</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span> (!foundAnyLogs) &#123;</span><br><span class="line">            emptyLogDir(remoteAppLogDir.toString());</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> output.toString();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">int</span> <span class="title">verifyApplicationState</span><span class="params">(ApplicationId appId, Configuration conf)</span> <span class="keyword">throws</span> IOException,</span></span><br><span class="line"><span class="function">            YarnException </span>&#123;</span><br><span class="line">        YarnClient yarnClient = <span class="keyword">null</span>;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            yarnClient = YarnClient.createYarnClient();</span><br><span class="line">            yarnClient.init(conf);</span><br><span class="line">            yarnClient.start();</span><br><span class="line">            ApplicationReport appReport = yarnClient.getApplicationReport(appId);</span><br><span class="line">            <span class="keyword">switch</span> (appReport.getYarnApplicationState()) &#123;</span><br><span class="line">                <span class="keyword">case</span> NEW:</span><br><span class="line">                <span class="keyword">case</span> NEW_SAVING:</span><br><span class="line">                <span class="keyword">case</span> ACCEPTED:</span><br><span class="line">                <span class="keyword">case</span> SUBMITTED:</span><br><span class="line">                <span class="keyword">case</span> RUNNING:</span><br><span class="line">                    <span class="keyword">return</span> -<span class="number">1</span>;</span><br><span class="line">                <span class="keyword">case</span> FAILED:</span><br><span class="line">                <span class="keyword">case</span> FINISHED:</span><br><span class="line">                <span class="keyword">case</span> KILLED:</span><br><span class="line">                <span class="keyword">default</span>:</span><br><span class="line">                    <span class="keyword">break</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">            <span class="keyword">if</span> (yarnClient != <span class="keyword">null</span>) &#123;</span><br><span class="line">                yarnClient.close();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">logDirNotExist</span><span class="params">(String remoteAppLogDir)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> FileNotFoundException(remoteAppLogDir + <span class="string">" does not exist.\n"</span> + <span class="string">"Log aggregation has not completed "</span> +</span><br><span class="line">                <span class="string">"or is not "</span> + <span class="string">"enabled."</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">emptyLogDir</span><span class="params">(String remoteAppLogDir)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        logger.warn(remoteAppLogDir + <span class="string">" does not have any log files."</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">readContainerLogs</span><span class="params">(DataInputStream valueStream,</span></span></span><br><span class="line"><span class="function"><span class="params">                                   StringBuilder out, <span class="keyword">long</span> logUploadedTime)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        <span class="keyword">byte</span>[] buf = <span class="keyword">new</span> <span class="keyword">byte</span>[<span class="number">65535</span>];</span><br><span class="line"></span><br><span class="line">        String fileType = valueStream.readUTF();</span><br><span class="line">        String fileLengthStr = valueStream.readUTF();</span><br><span class="line">        <span class="keyword">long</span> fileLength = Long.parseLong(fileLengthStr);</span><br><span class="line"></span><br><span class="line">        out.append(<span class="string">"ContainerLog-start "</span>).append(StringUtils.repeat(<span class="string">"-"</span>, <span class="number">80</span>)).append(<span class="string">"\n"</span>);</span><br><span class="line"></span><br><span class="line">        out.append(<span class="string">"LogType:"</span>).append(fileType).append(<span class="string">"\n"</span>);</span><br><span class="line">        <span class="keyword">if</span> (logUploadedTime != -<span class="number">1</span>) &#123;</span><br><span class="line">            out.append(<span class="string">"Log Upload Time:"</span>).append(Times.format(logUploadedTime)).append(<span class="string">"\n"</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        out.append(<span class="string">"LogLength:"</span>);</span><br><span class="line">        out.append(fileLengthStr).append(<span class="string">"\n\n"</span>);</span><br><span class="line">        out.append(<span class="string">"Log Contents:"</span>).append(<span class="string">"\n"</span>);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">long</span> curRead = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">long</span> pendingRead = fileLength - curRead;</span><br><span class="line">        <span class="keyword">int</span> toRead = pendingRead &gt; buf.length ? buf.length : (<span class="keyword">int</span>) pendingRead;</span><br><span class="line">        <span class="keyword">int</span> len = valueStream.read(buf, <span class="number">0</span>, toRead);</span><br><span class="line">        <span class="keyword">while</span> (len != -<span class="number">1</span> &amp;&amp; curRead &lt; fileLength) &#123;</span><br><span class="line">            out.append(<span class="keyword">new</span> String(buf, <span class="number">0</span>, len));</span><br><span class="line">            curRead += len;</span><br><span class="line"></span><br><span class="line">            pendingRead = fileLength - curRead;</span><br><span class="line">            toRead =</span><br><span class="line">                    pendingRead &gt; buf.length ? buf.length : (<span class="keyword">int</span>) pendingRead;</span><br><span class="line">            len = valueStream.read(buf, <span class="number">0</span>, toRead);</span><br><span class="line">        &#125;</span><br><span class="line">        out.append(<span class="string">"End of LogType:"</span>).append(fileType).append(<span class="string">"\n"</span>);</span><br><span class="line">        out.append(<span class="string">""</span>).append(<span class="string">"\n"</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">checkLogAggregationEnable</span><span class="params">(Configuration conf)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        String isEnable = conf.get(YarnConfiguration.LOG_AGGREGATION_ENABLED);</span><br><span class="line">        <span class="keyword">if</span> (!<span class="string">"true"</span>.equalsIgnoreCase(isEnable)) &#123;</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> Exception(<span class="string">"LOG_AGGREGATION_ENABLED must be ENABLED"</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>


      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://longzl2015.github.io/2016/04/02/hadoop%E7%94%9F%E6%80%81/yarn%E6%A1%86%E6%9E%B6/%E6%97%A5%E5%BF%97/%E6%97%A5%E5%BF%97%E8%AF%A6%E8%A7%A3/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="zhoul">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2016/04/02/hadoop%E7%94%9F%E6%80%81/yarn%E6%A1%86%E6%9E%B6/%E6%97%A5%E5%BF%97/%E6%97%A5%E5%BF%97%E8%AF%A6%E8%A7%A3/" class="post-title-link" itemprop="url">日志详解</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2016-04-02 22:46:48" itemprop="dateCreated datePublished" datetime="2016-04-02T22:46:48+08:00">2016-04-02</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-02-27 17:16:07" itemprop="dateModified" datetime="2020-02-27T17:16:07+08:00">2020-02-27</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/hadoop%E7%94%9F%E6%80%81/" itemprop="url" rel="index">
                    <span itemprop="name">hadoop生态</span>
                  </a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/hadoop%E7%94%9F%E6%80%81/yarn/" itemprop="url" rel="index">
                    <span itemprop="name">yarn</span>
                  </a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="fa fa-comment-o"></i>
      </span>
      <span class="post-meta-item-text">Disqus：</span>
    
    <a title="disqus" href="/2016/04/02/hadoop%E7%94%9F%E6%80%81/yarn%E6%A1%86%E6%9E%B6/%E6%97%A5%E5%BF%97/%E6%97%A5%E5%BF%97%E8%AF%A6%E8%A7%A3/#comments" itemprop="discussionUrl">
      <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2016/04/02/hadoop生态/yarn框架/日志/日志详解/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="一-Hadoop-日志存放路径详解"><a href="#一-Hadoop-日志存放路径详解" class="headerlink" title="一. Hadoop 日志存放路径详解"></a>一. Hadoop 日志存放路径详解</h2><p>Hadoop的日志大致可以分为两大类，且这两类的日志存放的路径是不一样的。本文基于Hadoop 2.x 版本进行说明的。</p>
<ol>
<li>Hadoop 系统服务输出的日志</li>
<li>Mapreduce 程序输出来的日志 ( 作业运行日志 、任务运行日志 (Container 日志))</li>
</ol>
<p>在 Hadoop 2.0 中，Mapreduce 程序的日志包含两部分，<strong>作业运行日志</strong> 和 <strong>任务运行日志(Container 日志)</strong></p>
<h3 id="1-1-Hadoop系统服务输出的日志"><a href="#1-1-Hadoop系统服务输出的日志" class="headerlink" title="1.1 Hadoop系统服务输出的日志"></a>1.1 Hadoop系统服务输出的日志</h3><p>诸如 NameNode、DataNode、ResourceManage 等系统自带的服务输出来的日志默认是存放在 <code>${HADOOP_HOME}/logs</code>目录下。比如 resourcemanager 的输出日志为 <code>yarn-${USER}-resourcemanager-${hostname}.log</code></p>
<ul>
<li>yarn 指的就是该日志的属性即为 YARN，其他类似的有 mapred、hadoop 等</li>
<li><code>${USER}s</code> 是指启动 resourcemanager 进程的用户</li>
<li>resourcemanager 就是指明 resourcemanager 进程，其他类似的有 namenode、zkfc、historyserver 等</li>
<li><code>${hostname}</code> 是 resourcemanager 进程所在机器的 hostname</li>
</ul>
<p>当日志到达一定的大小（可以在 <code>${HADOOP_HOME}/etc/hadoop/log4j.properties</code> 文件中配置）将会被切割出一个新的文件，切割出来的日志文件名类似 <code>yarn-${USER}-resourcemanager-${hostname}.log.数字</code> 的形式，后面的数字越大，代表日志越旧。在默认情况下，只保存前 20 个日志文件，比如下面：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@master logs]$ ll</span><br><span class="line">总用量 7360356</span><br><span class="line">-rw-rw-r--. 1 hadoop hadoop   6251772 10月 16 13:59 hadoop-hadoop-datanode-devhost21.log</span><br><span class="line">-rw-rw-r--. 1 hadoop hadoop       722 10月 16 10:52 hadoop-hadoop-datanode-devhost21.out</span><br><span class="line">-rw-rw-r--. 1 hadoop hadoop       722 9月  17 15:09 hadoop-hadoop-datanode-devhost21.out.1</span><br><span class="line">-rw-rw-r--. 1 hadoop hadoop       722 9月  15 23:10 hadoop-hadoop-datanode-devhost21.out.2</span><br><span class="line">-rw-rw-r--. 1 hadoop hadoop       722 8月  17 20:34 hadoop-hadoop-datanode-devhost21.out.3</span><br><span class="line">-rw-rw-r--. 1 hadoop hadoop 151078937 2月   8 19:16 hadoop-hadoop-datanode-master.log</span><br><span class="line">-rw-rw-r--. 1 hadoop hadoop 268479664 12月  8 10:00 hadoop-hadoop-datanode-master.log.1</span><br><span class="line">-rw-rw-r--. 1 hadoop hadoop 268471403 11月 14 11:34 hadoop-hadoop-datanode-master.log.2</span><br><span class="line">-rw-rw-r--. 1 hadoop hadoop 268439864 11月  8 08:30 hadoop-hadoop-datanode-master.log.3</span><br><span class="line">-rw-rw-r--. 1 hadoop hadoop 268435710 8月  17 19:00 hadoop-hadoop-datanode-master.log.4</span><br><span class="line">-rw-rw-r--. 1 hadoop hadoop 268445084 8月  16 21:33 hadoop-hadoop-datanode-master.log.5</span><br><span class="line">-rw-rw-r--. 1 hadoop hadoop       722 1月   4 14:09 hadoop-hadoop-datanode-master.out</span><br><span class="line">-rw-rw-r--. 1 hadoop hadoop       722 12月 20 10:49 hadoop-hadoop-datanode-master.out.1</span><br><span class="line">-rw-rw-r--. 1 hadoop hadoop       722 12月 18 16:13 hadoop-hadoop-datanode-master.out.2</span><br><span class="line">-rw-rw-r--. 1 hadoop hadoop       722 10月 30 15:20 hadoop-hadoop-datanode-master.out.3</span><br><span class="line">-rw-rw-r--. 1 hadoop hadoop       722 10月 30 15:17 hadoop-hadoop-datanode-master.out.4</span><br><span class="line">-rw-rw-r--. 1 hadoop hadoop       722 10月 30 13:14 hadoop-hadoop-datanode-master.out.5</span><br></pre></td></tr></table></figure>




<h3 id="1-2-配置-Hadoop-系统服务日志"><a href="#1-2-配置-Hadoop-系统服务日志" class="headerlink" title="1.2 配置 Hadoop 系统服务日志"></a>1.2 配置 Hadoop 系统服务日志</h3><p><strong>1. 配置 log4j 日志的属性参数</strong></p>
<p>比如 resourcemanager（在 <code>${HADOOP_HOME}/etc/hadoop/log4j.properties</code>）：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">log4j.logger.org.apache.hadoop.yarn.server.resourcemanager.RMAppManager</span><br><span class="line">          $ApplicationSummary&#x3D;$&#123;yarn.server.resourcemanager.appsummary.logger&#125;</span><br><span class="line">log4j.additivity.org.apache.hadoop.yarn.server.resourcemanager</span><br><span class="line">                                    .RMAppManager$ApplicationSummary&#x3D;false</span><br><span class="line">log4j.appender.RMSUMMARY&#x3D;org.apache.log4j.RollingFileAppender</span><br><span class="line">log4j.appender.RMSUMMARY.File&#x3D;$&#123;hadoop.log.dir&#125;&#x2F;</span><br><span class="line">                        $&#123;yarn.server.resourcemanager.appsummary.log.file&#125;</span><br><span class="line">log4j.appender.RMSUMMARY.MaxFileSize&#x3D;256MB（多大切割日志）</span><br><span class="line">log4j.appender.RMSUMMARY.MaxBackupIndex&#x3D;20（说明保存最近20个日志文件）</span><br><span class="line">log4j.appender.RMSUMMARY.layout&#x3D;org.apache.log4j.PatternLayout</span><br><span class="line">log4j.appender.RMSUMMARY.layout.ConversionPattern&#x3D;%d&#123;ISO8601&#125; %p %c&#123;2&#125;: %m%n</span><br></pre></td></tr></table></figure>

<p><strong>2. 配置 resourcemanager 日志存放路径</strong></p>
<p>在 <code>${HADOOP_HOME}/etc/hadoop/yarn-env.sh</code> 文件中</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># default log directory &amp; file</span></span><br><span class="line"><span class="keyword">if</span> [ <span class="string">"<span class="variable">$YARN_LOG_DIR</span>"</span> = <span class="string">""</span> ]; <span class="keyword">then</span></span><br><span class="line">  YARN_LOG_DIR=<span class="string">"<span class="variable">$HADOOP_YARN_HOME</span>/logs"</span></span><br><span class="line"><span class="keyword">fi</span></span><br></pre></td></tr></table></figure>

<p>只需要修改 <code>YARN_LOG_DIR</code> 的值，这时候，yarn 相关的日志记录都将存放在你配置的目录下。</p>
<h2 id="二-历史服务器-JobHistory-Server"><a href="#二-历史服务器-JobHistory-Server" class="headerlink" title="二. 历史服务器 (JobHistory Server)"></a>二. 历史服务器 (JobHistory Server)</h2><p>MapReduce 的 JobHistory Server，这是一个独立的服务，可通过 web UI 展示历史作业日志，之所以将其独立出来，是为了减轻 ResourceManager 负担。JobHistory Server 将会分析作业运行日志，并展示作业的启动时间、结束时间、各个任务的运行时间，各种Counter数据等，并产生一个指向作业和任务日志的链接，其默认端口号为 19888。<strong>通常可以启动在一台独立的机器上</strong>。</p>
<h3 id="2-1-历史服务器配置"><a href="#2-1-历史服务器配置" class="headerlink" title="2.1 历史服务器配置"></a>2.1 历史服务器配置</h3><p>你需在 <strong>mapred-site.xml</strong> 中对其进行配置</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.jobhistory.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>0.0.0.0:10020<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.jobhistory.webapp.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>0.0.0.0:19888<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>上面的参数是在 mapred-site.xml 文件中进行配置，mapreduce.jobhistory.address 和 mapreduce.jobhistory.webapp.address 默认的值分别是 0.0.0.0:10020 和 0.0.0.0:19888，大家可以一定要根据自己的情况进行相应的配置，<strong>最好别用默认的 0.0.0.0</strong> ，参数的格式是 host:port。</p>
<p>在 Hadoop 历史服务器的 WEB UI 上最多显示 20000 个历史的作业记录信息；其实我们可以在 mapred-site.xml 文件中通过下面的参数进行配置，然后重启一下 Hadoop jobhistory 即可。</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.jobhistory.joblist.cache.size<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>20000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>


<h3 id="2-2-关于-HA-模式下的历史服务器配置的结论"><a href="#2-2-关于-HA-模式下的历史服务器配置的结论" class="headerlink" title="2.2 关于 HA 模式下的历史服务器配置的结论"></a>2.2 关于 HA 模式下的历史服务器配置的结论</h3><p>笔者的集群是 HA 模式的( HDFS 和 ResourceManager HA)。在 <a href="http://blog.csdn.net/u011414200/article/details/50283401" target="_blank" rel="noopener">” Hadoop-2.5.0-cdh5.3.2 HA 安装＂</a> 中详细讲解了关于 HA 模式的搭建，这里就不再赘述。但网上直接将关于 HA 模式下的历史服务器的配置资料却很少。</p>
<p>笔者在思考，如果配置在 mapred-site.xml 中就设置一台历史服务器，那么当这台机器挂了，那么能不能有另一台机器来承担历史服务器的责任，也就是笔者理想当然的 jobhistory server HA 模式。后面经过各自尝试，得出来的结论是笔者我太年轻了，概念没有搞懂，先总结如下:</p>
<ul>
<li>历史服务器是个独立的服务，其不会受到 namenode 和 resourcemanager 的 active/standby 切换所带来的影响</li>
<li>当历史服务器突然失效了，那些日志文件依旧存在 HDFS 上。当历史服务器又恢复正常，还是能看到在历史服务器失效期间的运行日志</li>
<li>可以很简单地把历史服务器当成是存在 HDFS 上日志文件的 Web 浏览器。当且仅当历史服务器启动后，才可以通过 Web 查看，比如 <code>http://10.6.3.43:19888/jobhistory</code></li>
<li>实际上，每台机器的 MapReduce 历史服务器的配置可以不同，当在哪台机器上执行程序时，那么所指向的历史服务器地址其实就是 mapred-site.xml 文件中 mapreduce.jobhistory.webapp.address 配置参数所指定的那台机器</li>
</ul>
<p><strong>所以 Hadoop HA 模式下的历史服务器配置和非 HA 模式是一样样的</strong>，如果你自作聪明（比如笔者），在 mapred-site.xml 文件中，添加了两个运行 namenode(resourcemanager) 进程的主备节点的主机名（或IP地址）。</p>
<p>但是真正在两台主机上同时启动历史服务器进程时，会报如下的类似错误：</p>
<blockquote>
<p>INFO org.apache.hadoop.http.HttpServer2: HttpServer.start() threw a non Bind IOException<br>77504 java.net.BindException: Port in use: master52:19888<br>Caused by: java.net.BindException: Cannot assign requested address<br>INFO org.apache.hadoop.service.AbstractService: Service HistoryClientService failed in state STARTED; cause: org.apache.hadoop.yarn.webapp.WebAppException: Error starting http server<br>INFO org.apache.hadoop.util.ExitUtil: Exiting with status -1</p>
</blockquote>
<p>原因就是端口被占用了，很明显如果不改变端口，有且仅有一个 历史服务器成功启动，且启动的那个服务器是在 mapred-site.xml 文件中设置位置最下面的那个，及后面的配置参数将覆盖前一个配置参数。就算改变端口也没卵用…</p>
<p>Note：以上这些是笔者一边操作，一边对比总结，有些结论未必是正确的，还请各位指正…</p>
<h3 id="2-3-启动历史服务器"><a href="#2-3-启动历史服务器" class="headerlink" title="2.3 启动历史服务器"></a>2.3 启动历史服务器</h3><p>配置完上述的参数之后，重新启动 Hadoop jobhistory，这样我们就可以在 mapreduce.jobhistory.webapp.address 参数配置的主机上对 Hadoop 历史作业情况经行查看。</p>
<p><strong>只能在 mapred-site.xml 文件中 mapreduce.jobhistory.webapp.address 配置参数所指定的那台机器上执行：</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sbin&#x2F;mr-jobhistory-daemon.sh start jobhistoryserver</span><br></pre></td></tr></table></figure>

<p>这样我们就可以在相应机器的 19888 端口上打开历史服务器的 WEB UI 界面。可以查看已经运行完的作业情况。且在 HDFS 上可以看到如下目录：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;tmp</span><br><span class="line">&#x2F;tmp&#x2F;hadoop-yarn</span><br><span class="line">&#x2F;tmp&#x2F;hadoop-yarn&#x2F;staging</span><br><span class="line">&#x2F;tmp&#x2F;hadoop-yarn&#x2F;staging&#x2F;history</span><br><span class="line">&#x2F;tmp&#x2F;hadoop-yarn&#x2F;staging&#x2F;history&#x2F;done</span><br><span class="line">&#x2F;tmp&#x2F;hadoop-yarn&#x2F;staging&#x2F;history&#x2F;done_intermediate</span><br></pre></td></tr></table></figure>



<h2 id="三-作业运行日志"><a href="#三-作业运行日志" class="headerlink" title="三. 作业运行日志"></a>三. 作业运行日志</h2><h3 id="3-1-作业运行日志概念"><a href="#3-1-作业运行日志概念" class="headerlink" title="3.1 作业运行日志概念"></a>3.1 作业运行日志概念</h3><p>作业运行由 MRAppMaster（MapReduce 作业的 ApplicationMaster）产生，详细记录了作业启动时间、运行时间，每个任务启动时间、运行时间、Counter 值等信息，与 Hadoop 1.0 中的 JobHistory 日志是基本一致。MapReduce 作业的 ApplicationMaster 也运行在 Container 中，且是编号为 000001 的 Container，比如 <code>container_1385051297072_0001_01_000001</code>，它自身可认为是一个特殊的 task，因此，也有自己的运行日志，该日志与 Map Task 和 Reduce Task 类似，但并不是前面介绍的”作业运行日志”。</p>
<p>ApplicationMaster 产生的作业运行日志举例如下，日志采用 apache avro（作为日志存储格式是 Hadoop 2.0 唯一使用到 Avro 的地方）工具，以 json 的格式保存：</p>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line"><span class="attr">"type"</span>:<span class="string">"JOB_SUBMITTED"</span>,</span><br><span class="line"><span class="attr">"event"</span>:</span><br><span class="line">    &#123;<span class="attr">"org.apache.hadoop.mapreduce.jobhistory.JobSubmitted"</span>:</span><br><span class="line">    	&#123;<span class="attr">"jobid"</span>:<span class="string">"job_1385051297072_0002″,</span></span><br><span class="line"><span class="string">         "</span>jobName<span class="string">":"</span>QuasiMonteCarlo<span class="string">",</span></span><br><span class="line"><span class="string">         "</span>userName<span class="string">":"</span>yarn<span class="string">", </span></span><br><span class="line"><span class="string">         "</span>submitTime<span class="string">":1385393834983,</span></span><br><span class="line"><span class="string">         "</span>jobConfPath<span class="string">":"</span>hdfs:<span class="comment">//hadoop-test/tmp/hadoop-yarn/staging/yarn/.staging/job_1385051297072_0002/job.xml",</span></span><br><span class="line">         <span class="string">"acls"</span>:&#123;&#125;,</span><br><span class="line">         <span class="attr">"jobQueueName"</span>:<span class="string">"default"</span>,</span><br><span class="line">         <span class="attr">"workflowId"</span>:<span class="string">""</span>,</span><br><span class="line">         <span class="attr">"workflowName"</span>:<span class="string">""</span>,</span><br><span class="line">         <span class="attr">"workflowNodeName"</span>:<span class="string">""</span>,</span><br><span class="line">         <span class="attr">"workflowAdjacencies"</span>:<span class="string">""</span>,</span><br><span class="line">         <span class="attr">"workflowTags"</span>:<span class="string">""</span></span><br><span class="line">         &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">&#123;</span><br><span class="line"><span class="attr">"type"</span>:<span class="string">"JOB_INITED"</span>,</span><br><span class="line"><span class="attr">"event"</span>:</span><br><span class="line">   &#123;<span class="attr">"org.apache.hadoop.mapreduce.jobhistory.JobInited"</span>:</span><br><span class="line">        &#123;<span class="attr">"jobid"</span>:<span class="string">"job_1385051297072_0002″,</span></span><br><span class="line"><span class="string">         "</span>launchTime<span class="string">":1385393974505,</span></span><br><span class="line"><span class="string">         "</span>totalMaps<span class="string">":8,</span></span><br><span class="line"><span class="string">    	 "</span>totalReduces<span class="string">":1,</span></span><br><span class="line"><span class="string">         "</span>jobStatus<span class="string">":"</span>INITED<span class="string">",</span></span><br><span class="line"><span class="string">         "</span>uberized<span class="string">":false&#125;</span></span><br><span class="line"><span class="string">   &#125;</span></span><br><span class="line"><span class="string">&#125;</span></span><br><span class="line"><span class="string">&#123;</span></span><br><span class="line"><span class="string"> "</span>type<span class="string">":"</span>JOB_INFO_CHANGED<span class="string">",</span></span><br><span class="line"><span class="string"> "</span>event<span class="string">":</span></span><br><span class="line"><span class="string">    &#123;"</span>org.apache.hadoop.mapreduce.jobhistory.JobInfoChange<span class="string">":</span></span><br><span class="line"><span class="string">		&#123;"</span>jobid<span class="string">":"</span>job_1385051297072_0002″,</span><br><span class="line"> 		 <span class="attr">"submitTime"</span>:<span class="number">1385393834983</span>,</span><br><span class="line"> 		 <span class="attr">"launchTime"</span>:<span class="number">1385393974505</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h3 id="3-2-作业运行日志配置"><a href="#3-2-作业运行日志配置" class="headerlink" title="3.2 作业运行日志配置"></a>3.2 作业运行日志配置</h3><p>历史作业的记录里面包含了一个作业用了多少个 Map、用了多少个 Reduce、作业提交时间、作业启动时间、作业完成时间等信息；这些信息对分析作业是很有帮助的，我们可以通过这些历史作业记录得到每天有多少个作业运行成功、有多少个作业运行失败、每个队列作业运行了多少个作业等很有用的信息。这些历史作业的信息是通过下面的信息配置的：</p>
<p>在 mapred-site.xml 文件中进行配置：</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.jobhistory.done-dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>$&#123;yarn.app.mapreduce.am.staging-dir&#125;/history/done<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.jobhistory.intermediate-done-dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>$&#123;yarn.app.mapreduce.am.staging-dir&#125;/history/done_intermediate<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.app.mapreduce.am.staging-dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>/tmp/hadoop-yarn/staging<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>



<h3 id="3-3-作业运行日志产生过程"><a href="#3-3-作业运行日志产生过程" class="headerlink" title="3.3 作业运行日志产生过程"></a>3.3 作业运行日志产生过程</h3><p><strong>1. 启动作业的 ApplicationMaster 并写日志至 HDFS</strong></p>
<ul>
<li>ResourceManager 启动作业的 ApplicationMaster</li>
<li>ApplicationMaster 运行过程中，将日志写到 <code>${yarn.app.mapreduce.am.staging-dir}/yarn/.staging/job_XXXXX_XXX/</code> 下</li>
<li>参数 <code>yarn.app.mapreduce.am.staging-dir</code> 的默认值是 <code>/tmp/hadoop-yarn/staging</code></li>
<li>该目录下将存在3个文件，分别是以 “<strong>.jhist</strong>“、”<strong>.summary</strong>” 和 “<strong>.xml</strong>” 结尾的文件，分别表示作业运行日志、作业概要信息和作业配置属性，其中，作业概要信息只有一句话，举例如下：</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">jobId&#x3D;job_1385051297072_0002,submitTime&#x3D;1385393834983,launchTime&#x3D;1385393974505,</span><br><span class="line">firstMapTaskLaunchTime&#x3D;1385393976706,firstReduceTaskLaunchTime&#x3D;1385393982581,</span><br><span class="line">finishTime&#x3D;1385393985417,resourcesPerMap&#x3D;1024,resourcesPerReduce&#x3D;1024,</span><br><span class="line">numMaps&#x3D;8,numReduces&#x3D;1,user&#x3D;yarn,queue&#x3D;default,status&#x3D;SUCCEEDED,</span><br><span class="line">mapSlotSeconds&#x3D;47,reduceSlotSeconds&#x3D;5,jobName&#x3D;QuasiMonteCarlo</span><br></pre></td></tr></table></figure>

<p><strong>2. HDFS 内转移历史运行日志</strong></p>
<ul>
<li>所有任务运行完成后，意味着，该作业运行完成</li>
<li>此时 ApplicationMaster 将三个文件拷贝到 <code>${ mapreduce.jobhistory.intermediate-done-dir}/${username}</code> 目录下，拷贝后的文件名后面添加 <code>&quot;_tmp&quot;</code></li>
<li>其中 mapreduce.jobhistory.intermediate-done-dir 默认值是 <code>${yarn.app.mapreduce.am.staging-dir}/history/done_intermediate</code></li>
<li>ApplicationMaster 将拷贝完成的三个文件重新命名成 “.jhist”、”.summary” 和 “.xml” 结尾的文件（去掉 <code>&quot;_tmp&quot;</code>）</li>
</ul>
<p><strong>3. 周期转移 done_intermediate 中的日志文件到 done 目录</strong></p>
<ul>
<li>周期性扫描线程定期将 done_intermediate 的日志文件转移到 done 目录</li>
<li>通过参数 mapreduce.jobhistory.done-dir 配置，默认值为 <code>${yarn.app.mapreduce.am.staging-dir}/history/done）</code>下</li>
<li>同时删除 “.summary” 文件（该文件中的信息，.jhist 文件中都有）</li>
<li>ApplicationMaster 移除 <code>${yarn.app.mapreduce.am.staging-dir}/yarn/.staging/job_XXXXX_XXX/</code> 目录</li>
</ul>
<h2 id="四-任务运行日志-Container-日志"><a href="#四-任务运行日志-Container-日志" class="headerlink" title="四. 任务运行日志 (Container 日志)"></a>四. 任务运行日志 (Container 日志)</h2><h3 id="4-1-Container-日志基本概念"><a href="#4-1-Container-日志基本概念" class="headerlink" title="4.1 Container 日志基本概念"></a>4.1 Container 日志基本概念</h3><p>默认情况下，任务运行日志 (Container 日志) 产只会存放在各 NodeManager 的本地磁盘上，且 NodeManager 将日志保存到 yarn.nodemanager.log-dirs 下 ，该属性缺省值为 <code>${yarn.log.dir}/userlogs</code>，也就是 Hadoop 安装目录下的 logs/userlogs 目录中，通常为了分摊磁盘负载，我们会为该参数设置多个路径。</p>
<p>需要注意的是，ApplicationMaster 的自身的日志也存放在该路目下，因为它也运行在 Container 之中，是一个特殊的 task。举例如下，其中，第一个是某个作业的 ApplicationMaster 日志（编号是000001）。且里面包含 stderr 、stdout 、 syslog 三个文件。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">container_1449861199315_0036_01_000001</span><br><span class="line">container_1449861199315_0036_01_000023</span><br><span class="line">container_1449861199315_0036_01_000061</span><br><span class="line">container_1449861199315_0036_01_000099</span><br><span class="line">container_1449861199315_0036_01_000137</span><br></pre></td></tr></table></figure>

<p>因为默认情况下，任务运行日志产只会存放在各 NodeManager 的本地磁盘上，而一个集群又有多个 NodeManager，将作业和任务日志存放在各个节点上肯定不便于统一管理和分析，为此，我们可以启用<strong>日志聚集</strong>功能。打开该功能后，各个任务运行完成后，会将生成的日志推送到 HDFS 的一个目录下，以便集中管理和分析（<strong>之前的并不会立即删除，在 HDFS 上，每个任务产生的三个文件，即 syslog、stderr 和 stdout 将合并一个文件，并通过索引记录各自位置</strong>）。</p>
<h3 id="4-2-不开启日志聚合时的日志配置"><a href="#4-2-不开启日志聚合时的日志配置" class="headerlink" title="4.2 不开启日志聚合时的日志配置"></a>4.2 不开启日志聚合时的日志配置</h3><p>Container 日志包含 ApplicationMaster 日志和普通 Task 日志等信息。默认情况下，这些日志信息是存放在 <code>${HADOOP_HOME}/logs/userlogs</code> 目录下（在那些 NodeManager 的机子上），我们可以通过下面的配置进行修改：</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">description</span>&gt;</span></span><br><span class="line">      Where to store container logs. An application's localized log directory </span><br><span class="line">      will be found in $&#123;yarn.nodemanager.log-dirs&#125;/application_$&#123;appid&#125;.</span><br><span class="line">      Individual containers' log directories will be below this, in </span><br><span class="line">      directories  named container_&#123;$contid&#125;. Each container directory will </span><br><span class="line">      contain the files stderr, stdin, and syslog generated by that container.</span><br><span class="line">    <span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.log-dirs<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>$&#123;yarn.log.dir&#125;/userlogs<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>


<h3 id="4-3-开启日志聚合时的配置参数"><a href="#4-3-开启日志聚合时的配置参数" class="headerlink" title="4.3 开启日志聚合时的配置参数"></a>4.3 开启日志聚合时的配置参数</h3><p><strong>日志聚集是 YARN 提供的日志中央化管理功能</strong>，它能将运行完成的 Container/ 任务日志上传到 HDFS 上，从而减轻 NodeManager 负载，且提供一个中央化存储和分析机制。默认情况下，Container/ 任务日志存在在各个 NodeManager 上，如果启用日志聚集功能需要额外的配置。</p>
<p>在 <strong>yarn-site.xml</strong> 中设置</p>
<p><strong>1. yarn.log-aggregation-enable</strong></p>
<ul>
<li>参数解释：是否启用日志聚集功能。</li>
<li>默认值：false</li>
</ul>
<p><strong>2. yarn.log-aggregation.retain-seconds</strong></p>
<ul>
<li>参数解释：在 HDFS 上聚集的日志最多保存多长时间。</li>
<li>默认值：-1</li>
</ul>
<p><strong>3. yarn.log-aggregation.retain-check-interval-seconds</strong></p>
<ul>
<li>参数解释：多长时间检查一次日志，并将满足条件的删除，如果是 0 或者负数，则为上一个值的 1/10。</li>
<li>默认值：-1</li>
</ul>
<p><strong>4. yarn.nodemanager.remote-app-log-dir</strong></p>
<ul>
<li>参数解释：当应用程序运行结束后，日志被转移到的HDFS目录（启用日志聚集功能时有效）</li>
<li>默认值：/tmp/logs</li>
</ul>
<p><strong>5. yarn.nodemanager.remote-app-log-dir-suffix</strong></p>
<ul>
<li>参数解释：远程日志目录子目录名称（启用日志聚集功能时有效）</li>
<li>默认值：日志将被转移到目录 <code>${yarn.nodemanager.remote-app-log-dir}/${user}/${thisParam}</code> 下</li>
</ul>
<h3 id="4-4-其他配置指导"><a href="#4-4-其他配置指导" class="headerlink" title="4.4 其他配置指导"></a>4.4 其他配置指导</h3><ul>
<li>远端的聚合日志的地址的文件夹权限应该是 1777, <code>${NMUser}</code>和 <code>${NMGroup}</code> 是所有者和所有组.</li>
<li>每个应用层次的日志的权限是 770, 但是文件夹所有人是应用的提交者, 文件夹的所有群组是 <code>${NMGroup}</code>, 这样安排可以让应用的提交者能访问到聚合后的日志, 并且<code>${NMGroup}</code>可以访问和修改日志.</li>
<li><code>${NMGroup}</code> 应该是一个有限访问的群组, 这样才不会造成访问泄露.</li>
</ul>
<h2 id="五-扩展知识"><a href="#五-扩展知识" class="headerlink" title="五. 扩展知识"></a>五. 扩展知识</h2><h3 id="5-1-mapred-site-xml-和-yarn-site-xml-的作用"><a href="#5-1-mapred-site-xml-和-yarn-site-xml-的作用" class="headerlink" title="5.1 mapred-site.xml 和 yarn-site.xml 的作用"></a>5.1 mapred-site.xml 和 yarn-site.xml 的作用</h3><p><strong>1. yarn-site.xml</strong><br>yarn-site.xml 是 YARN 相关的配置文件，客户端、ResourceManager 和 NodeManager 需要改配置文件，为了简单，可让这三类节点上的该文件是一致的。</p>
<p><strong>2. Mapred-site.xml</strong><br>Mapred-site.xml 是 MapReduce 特有的配置文件，在 YARN 中，mapreduce 已经变成了一个客户端编程库，因此只有客户端和 jobhistory server 需要该配置文件，其他节点，比如 resourceManager 和 NodeManager 不需要，除非你们也把这些节点作为客户端提供给用户使用，另外，一定要让客户端和 jobhistory server 上的 mapres-site.xml 一致。</p>
<h3 id="5-2-权限相关配置参数"><a href="#5-2-权限相关配置参数" class="headerlink" title="5.2 权限相关配置参数"></a>5.2 权限相关配置参数</h3><p>注意，配置这些参数前，应充分理解这几个参数的含义，以防止误配给集群带来的隐患。另外，这些参数均需要在 <code>yarn-site.xml</code> 中配置。</p>
<p>这里的权限由三部分组成，分别是：</p>
<p><strong>1. 管理员和普通用户如何区分</strong><br>管理员列表由参数 yarn.admin.acl 指定。</p>
<p><strong>2. 服务级别的权限</strong><br>比如哪些用户可以向集群提交 ResourceManager 提交应用程序，服务级别的权限是通过配置 hadoop-policy.xml 实现的，这个与 Hadoop 1.0 类似。</p>
<p><strong>3. 队列级别的权限</strong><br>比如哪些用户可以向队列A提交作业等。队列级别的权限是由对应的资源调度器内部配置的，比如 Fair Scheduler 或者 Capacity Scheduler 等。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://longzl2015.github.io/2016/04/02/7%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/pmml/PMML%E6%96%87%E4%BB%B6%E6%A0%BC%E5%BC%8F/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="zhoul">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2016/04/02/7%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/pmml/PMML%E6%96%87%E4%BB%B6%E6%A0%BC%E5%BC%8F/" class="post-title-link" itemprop="url">PMML 标准化(转)</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2016-04-02 16:03:07" itemprop="dateCreated datePublished" datetime="2016-04-02T16:03:07+08:00">2016-04-02</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-02-27 17:16:07" itemprop="dateModified" datetime="2020-02-27T17:16:07+08:00">2020-02-27</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index">
                    <span itemprop="name">机器学习</span>
                  </a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/pmml/" itemprop="url" rel="index">
                    <span itemprop="name">pmml</span>
                  </a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="fa fa-comment-o"></i>
      </span>
      <span class="post-meta-item-text">Disqus：</span>
    
    <a title="disqus" href="/2016/04/02/7%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/pmml/PMML%E6%96%87%E4%BB%B6%E6%A0%BC%E5%BC%8F/#comments" itemprop="discussionUrl">
      <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2016/04/02/7机器学习/pmml/PMML文件格式/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="PMML简介"><a href="#PMML简介" class="headerlink" title="PMML简介"></a>PMML简介</h2><p>PMML全称预言模型标记模型（Predictive Model Markup Language），以XML 为载体呈现数据挖掘模型。<br>PMML 允许您在不同的应用程序之间轻松共享预测分析模型。<br>因此，您可以在一个系统中定型一个模型，在 PMML 中对其进行表达，然后将其移动到另一个系统中，而不需考虑分析和预测过程中的具体实现细节。<br>使得模型的部署摆脱了模型开发和产品整合的束缚。</p>
<h2 id="PMML标准"><a href="#PMML标准" class="headerlink" title="PMML标准"></a>PMML标准</h2><p>PMML 标准是数据挖掘过程的一个实例化标准，它按照数据挖掘任务执行过程，有序的定义了数据挖掘不同阶段的相关信息：<br><img src="https://www.ibm.com/developerworks/cn/opensource/ind-PMML1/image001.gif" alt="这里写图片描述"></p>
<ul>
<li>头信息  （Header）</li>
<li>数据字典（DataDictionary）</li>
<li>挖掘模式 (Mining Schema)</li>
<li>数据转换（Transformations）</li>
<li>模型定义 (Model Definition)</li>
<li>评分结果 (Score Result)</li>
</ul>
<h3 id="头信息（Header）"><a href="#头信息（Header）" class="headerlink" title="头信息（Header）"></a>头信息（Header）</h3><p>PMML文件使用头信息作为开始，它主要用于记录产品、版权、模型描述，建模时间等描述性信息。例如：</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">Header</span> <span class="attr">copyright</span>=<span class="string">"Copyright (c) 2017 liaotuo"</span> <span class="attr">description</span>=<span class="string">"Random Forest Tree Model"</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">Extension</span> <span class="attr">name</span>=<span class="string">"user"</span> <span class="attr">value</span>=<span class="string">"liaotuo"</span> <span class="attr">extender</span>=<span class="string">"Rattle/PMML"</span>/&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">Application</span> <span class="attr">name</span>=<span class="string">"Rattle/PMML"</span> <span class="attr">version</span>=<span class="string">"1.4"</span>/&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">Timestamp</span>&gt;</span>2017-07-04 16:33:42<span class="tag">&lt;/<span class="name">Timestamp</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">Header</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>其中：</p>
<ul>
<li>Header 是标识头信息部分的起始标记</li>
<li>copyright 包含了所记录模型的版权信息</li>
<li>description 包含可读的描述性信息</li>
<li>Application 描述了生成本文件所含模型的软件产品。</li>
<li>Timestamp 记录了模型创建的时间。</li>
</ul>
<h3 id="数据字典（DataDictionary）"><a href="#数据字典（DataDictionary）" class="headerlink" title="数据字典（DataDictionary）"></a>数据字典（DataDictionary）</h3><p>数据字典定义了所有变量的信息，包括<code>预测变量</code>和<code>目标变量</code>。这些信息包括变量名，量度和类型等。<br>对于分类变量，可能包含各种不同类型的分类值，包括有效值 (valid value)，遗漏值 (missing value) 和无效值 (invalid value)，<br>它们由 Value 的“property”属性决定；对于连续变量，可以指定一个或多个有效值范围 (Interval)。</p>
<p>对于字段 <code>Age</code>，范围从0到 120 的值是有效值，不在0-120范围值被定义为无效值。<br>尽管在此没有显示，您可以使用 PMML 元素 <code>MiningSchema</code> 为无效值和遗漏值定义合适的处理方法。）</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"> <span class="tag">&lt;<span class="name">DataDictionary</span> <span class="attr">numberOfFields</span>=<span class="string">"7"</span>&gt;</span> </span><br><span class="line">  <span class="tag">&lt;<span class="name">DataField</span> <span class="attr">dataType</span>=<span class="string">"double"</span> <span class="attr">displayName</span>=<span class="string">"Age"</span> <span class="attr">name</span>=<span class="string">"Age"</span> <span class="attr">optype</span>=<span class="string">"continuous"</span>/&gt;</span> </span><br><span class="line">  <span class="tag">&lt;<span class="name">Interval</span> <span class="attr">leftMargin</span>=<span class="string">"0"</span> <span class="attr">rightMargin</span>=<span class="string">"120"</span> <span class="attr">closure</span>=<span class="string">"closedClosed"</span> /&gt;</span> </span><br><span class="line">  <span class="tag">&lt;<span class="name">DataField</span> <span class="attr">dataType</span>=<span class="string">"string"</span> <span class="attr">displayName</span>=<span class="string">"Sex"</span> <span class="attr">name</span>=<span class="string">"Sex"</span> <span class="attr">optype</span>=<span class="string">"categorical"</span>&gt;</span> </span><br><span class="line">    <span class="tag">&lt;<span class="name">Value</span> <span class="attr">displayValue</span>=<span class="string">"F"</span> <span class="attr">property</span>=<span class="string">"valid"</span> <span class="attr">value</span>=<span class="string">"F"</span>/&gt;</span> </span><br><span class="line">    <span class="tag">&lt;<span class="name">Value</span> <span class="attr">displayValue</span>=<span class="string">"M"</span> <span class="attr">property</span>=<span class="string">"valid"</span> <span class="attr">value</span>=<span class="string">"M"</span>/&gt;</span> </span><br><span class="line">  <span class="tag">&lt;/<span class="name">DataField</span>&gt;</span> </span><br><span class="line">  <span class="tag">&lt;<span class="name">DataField</span> <span class="attr">dataType</span>=<span class="string">"string"</span> <span class="attr">displayName</span>=<span class="string">"BP"</span> <span class="attr">name</span>=<span class="string">"BP"</span> <span class="attr">optype</span>=<span class="string">"categorical"</span>&gt;</span> </span><br><span class="line">    <span class="tag">&lt;<span class="name">Value</span> <span class="attr">displayValue</span>=<span class="string">"HIGH"</span> <span class="attr">property</span>=<span class="string">"valid"</span> <span class="attr">value</span>=<span class="string">"HIGH"</span>/&gt;</span> </span><br><span class="line">    <span class="tag">&lt;<span class="name">Value</span> <span class="attr">displayValue</span>=<span class="string">"LOW"</span> <span class="attr">property</span>=<span class="string">"valid"</span> <span class="attr">value</span>=<span class="string">"LOW"</span>/&gt;</span> </span><br><span class="line">    <span class="tag">&lt;<span class="name">Value</span> <span class="attr">displayValue</span>=<span class="string">"NORMAL"</span> <span class="attr">property</span>=<span class="string">"valid"</span> <span class="attr">value</span>=<span class="string">"NORMAL"</span>/&gt;</span> </span><br><span class="line">    <span class="tag">&lt;<span class="name">Value</span> <span class="attr">displayValue</span>=<span class="string">"ABNORMAL"</span> <span class="attr">property</span>=<span class="string">"invalid"</span> <span class="attr">value</span>=<span class="string">"ABNORMAL"</span>/&gt;</span> </span><br><span class="line">    <span class="tag">&lt;<span class="name">Value</span> <span class="attr">displayValue</span>=<span class="string">"MISSING"</span> <span class="attr">property</span>=<span class="string">"missing"</span> <span class="attr">value</span>=<span class="string">"MISSING"</span>/&gt;</span> </span><br><span class="line">  <span class="tag">&lt;/<span class="name">DataField</span>&gt;</span> </span><br><span class="line">  <span class="tag">&lt;<span class="name">DataField</span> <span class="attr">dataType</span>=<span class="string">"string"</span> <span class="attr">displayName</span>=<span class="string">"Cholesterol"</span> <span class="attr">name</span>=<span class="string">"Cholesterol"</span> </span></span><br><span class="line"><span class="tag">    <span class="attr">optype</span>=<span class="string">"categorical"</span>&gt;</span> </span><br><span class="line">    <span class="tag">&lt;<span class="name">Value</span> <span class="attr">displayValue</span>=<span class="string">"HIGH"</span> <span class="attr">property</span>=<span class="string">"valid"</span> <span class="attr">value</span>=<span class="string">"HIGH"</span>/&gt;</span> </span><br><span class="line">    <span class="tag">&lt;<span class="name">Value</span> <span class="attr">displayValue</span>=<span class="string">"NORMAL"</span> <span class="attr">property</span>=<span class="string">"valid"</span> <span class="attr">value</span>=<span class="string">"NORMAL"</span>/&gt;</span> </span><br><span class="line">  <span class="tag">&lt;/<span class="name">DataField</span>&gt;</span> </span><br><span class="line">  <span class="tag">&lt;<span class="name">DataField</span> <span class="attr">dataType</span>=<span class="string">"double"</span> <span class="attr">displayName</span>=<span class="string">"Na"</span> <span class="attr">name</span>=<span class="string">"Na"</span> <span class="attr">optype</span>=<span class="string">"continuous"</span>/&gt;</span> </span><br><span class="line">  <span class="tag">&lt;<span class="name">DataField</span> <span class="attr">dataType</span>=<span class="string">"double"</span> <span class="attr">displayName</span>=<span class="string">"K"</span> <span class="attr">name</span>=<span class="string">"K"</span> <span class="attr">optype</span>=<span class="string">"continuous"</span>/&gt;</span> </span><br><span class="line">  <span class="tag">&lt;<span class="name">DataField</span> <span class="attr">dataType</span>=<span class="string">"string"</span> <span class="attr">displayName</span>=<span class="string">"Drug"</span> <span class="attr">name</span>=<span class="string">"Drug"</span> <span class="attr">optype</span>=<span class="string">"categorical"</span>&gt;</span> </span><br><span class="line">    <span class="tag">&lt;<span class="name">Value</span> <span class="attr">displayValue</span>=<span class="string">"drugA"</span> <span class="attr">property</span>=<span class="string">"valid"</span> <span class="attr">value</span>=<span class="string">"drugA"</span>/&gt;</span> </span><br><span class="line">    <span class="tag">&lt;<span class="name">Value</span> <span class="attr">displayValue</span>=<span class="string">"drugB"</span> <span class="attr">property</span>=<span class="string">"valid"</span> <span class="attr">value</span>=<span class="string">"drugB"</span>/&gt;</span> </span><br><span class="line">    <span class="tag">&lt;<span class="name">Value</span> <span class="attr">displayValue</span>=<span class="string">"drugC"</span> <span class="attr">property</span>=<span class="string">"valid"</span> <span class="attr">value</span>=<span class="string">"drugC"</span>/&gt;</span> </span><br><span class="line">    <span class="tag">&lt;<span class="name">Value</span> <span class="attr">displayValue</span>=<span class="string">"drugX"</span> <span class="attr">property</span>=<span class="string">"valid"</span> <span class="attr">value</span>=<span class="string">"drugX"</span>/&gt;</span> </span><br><span class="line">    <span class="tag">&lt;<span class="name">Value</span> <span class="attr">displayValue</span>=<span class="string">"drugY"</span> <span class="attr">property</span>=<span class="string">"valid"</span> <span class="attr">value</span>=<span class="string">"drugY"</span>/&gt;</span> </span><br><span class="line">  <span class="tag">&lt;/<span class="name">DataField</span>&gt;</span> </span><br><span class="line"><span class="tag">&lt;/<span class="name">DataDictionary</span>&gt;</span></span><br></pre></td></tr></table></figure>

<h3 id="挖掘模式-Mining-Schema"><a href="#挖掘模式-Mining-Schema" class="headerlink" title="挖掘模式(Mining Schema)"></a>挖掘模式(Mining Schema)</h3><p>定义预测变量和目标变量</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">MiningSchema</span>&gt;</span> </span><br><span class="line">  <span class="tag">&lt;<span class="name">MiningField</span> <span class="attr">importance</span>=<span class="string">"0.589759"</span> <span class="attr">name</span>=<span class="string">"K"</span> <span class="attr">usageType</span>=<span class="string">"active"</span>/&gt;</span> </span><br><span class="line">  <span class="tag">&lt;<span class="name">MiningField</span> <span class="attr">importance</span>=<span class="string">"0.0328595"</span> <span class="attr">name</span>=<span class="string">"Age"</span> <span class="attr">usageType</span>=<span class="string">"active"</span>/&gt;</span> </span><br><span class="line">  <span class="tag">&lt;<span class="name">MiningField</span> <span class="attr">importance</span>=<span class="string">"0.0249929"</span> <span class="attr">name</span>=<span class="string">"Na"</span> <span class="attr">usageType</span>=<span class="string">"active"</span> </span></span><br><span class="line"><span class="tag">    <span class="attr">outliers</span>=<span class="string">" asExtremeValues"</span> <span class="attr">lowValue</span>=<span class="string">"0.02"</span> <span class="attr">highValue</span>=<span class="string">"0.08"</span>/&gt;</span> </span><br><span class="line">  <span class="tag">&lt;<span class="name">MiningField</span> <span class="attr">importance</span>=<span class="string">"0.0333406"</span> <span class="attr">name</span>=<span class="string">"Cholesterol"</span> <span class="attr">usageType</span>=<span class="string">"active"</span>/&gt;</span> </span><br><span class="line">  <span class="tag">&lt;<span class="name">MiningField</span> <span class="attr">importance</span>=<span class="string">"0.307279"</span> <span class="attr">name</span>=<span class="string">"BP"</span> <span class="attr">usageType</span>=<span class="string">"active"</span> </span></span><br><span class="line"><span class="tag">    <span class="attr">missingValueReplacement</span>=<span class="string">"HIGH"</span>/&gt;</span> </span><br><span class="line">  <span class="tag">&lt;<span class="name">MiningField</span> <span class="attr">importance</span>=<span class="string">"0.0117684"</span> <span class="attr">name</span>=<span class="string">"Sex"</span> <span class="attr">usageType</span>=<span class="string">"active"</span>/&gt;</span> </span><br><span class="line">  <span class="tag">&lt;<span class="name">MiningField</span> <span class="attr">name</span>=<span class="string">"Drug"</span> <span class="attr">usageType</span>=<span class="string">"predicted"</span>/&gt;</span> </span><br><span class="line"><span class="tag">&lt;/<span class="name">MiningSchema</span>&gt;</span></span><br></pre></td></tr></table></figure>

<ul>
<li>变量的属性由 “usageType” 值决定，该属性未指定或者值为 “active” 代表预测变量， “predicted”代表目标变量。<br>一般来说，一个常见的模型有多个预测变量和一个目标变量， 但是也可以没有预测变量、多个目标变量或者根本没有目标变量。</li>
<li>所有在 Mining Schema 中被引用的变量一定会在数据字典中被定义， 但是不是所有出现在数据字典中的变量会在 Mining Schema 中被应用，<br>Mining Schema 定义了数据字典中的一个子集，这个子集才是对模型来说最重要的。</li>
</ul>
<h3 id="数据转换-Transformations"><a href="#数据转换-Transformations" class="headerlink" title="数据转换 (Transformations)"></a>数据转换 (Transformations)</h3><p>一旦数据字典对数据集做出了定义，那么就可以在其之上进行各种数据转换的预处理操作。这是由于有时用户所提供的数据并不能直接用于建模，<br>需要将原始的用户数据转换或映射成模型可以识别和使用的数据类型，这就需要使用数据转换来完成。<br>譬如，神经网络模型内部仅能处理数值型的数据，如果用户数据中含有离散型数据，如性别包含“男”、“女”二值，那在建模前就需要将性别变量映射成 0 和 1 来分别表示“男”和“女”。</p>
<p>PMML 标准支持一些常用的数据转换预处理操作，并在此基础上支持使用函数表达式的转换。以下所列的是标准所定义的一些简单的数据转换操作：</p>
<ul>
<li>正态化 (Normalization) - 把数据值转化为数值，同时适用于连续性变量和离散变量。</li>
<li>离散化 (Discretization) - 把连续性变量转化为离散变量。</li>
<li>数据映射 (Value mapping) - 把当前离散变量映射成另一种离散性变量。</li>
<li>函数 (Functions) - PMML 内建了大量的常用函数，用户也可以定义自己的函数。</li>
<li>聚合 (Aggregation) - 聚合操作，比如求平均值，最大值，最小值等。</li>
</ul>
<p>如下：给出了一个使用 Discretization 的示例。通过两个给定的区间将连续型变量“Profit”转换成仅含“negative”和“positive”二值的离散变量。</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">Discretize</span> <span class="attr">field</span>=<span class="string">"Profit"</span>&gt;</span> </span><br><span class="line">   <span class="tag">&lt;<span class="name">DiscretizeBin</span> <span class="attr">binValue</span>=<span class="string">"negative"</span>&gt;</span> </span><br><span class="line">       <span class="tag">&lt;<span class="name">Interval</span> <span class="attr">closure</span>=<span class="string">"openOpen"</span> <span class="attr">rightMargin</span>=<span class="string">"0"</span>/&gt;</span> </span><br><span class="line">       <span class="comment">&lt;!-- left margin is -infinity by default --&gt;</span> </span><br><span class="line">   <span class="tag">&lt;/<span class="name">DiscretizeBin</span>&gt;</span> </span><br><span class="line">   <span class="tag">&lt;<span class="name">DiscretizeBin</span> <span class="attr">binValue</span>=<span class="string">"positive"</span>&gt;</span> </span><br><span class="line">       <span class="tag">&lt;<span class="name">Interval</span> <span class="attr">closure</span>=<span class="string">"closedOpen"</span> <span class="attr">leftMargin</span>=<span class="string">"0"</span>/&gt;</span> </span><br><span class="line">       <span class="comment">&lt;!-- right margin is +infinity by default --&gt;</span> </span><br><span class="line">   <span class="tag">&lt;/<span class="name">DiscretizeBin</span>&gt;</span> </span><br><span class="line"><span class="tag">&lt;/<span class="name">Discretize</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>如下：给出了一个使用 Functions 的示例，通过使用内建函数 if 和 isMissing 将变量“PREVEXP”中的缺失值替换为指定的均值。<br>值得注意的是，替换了缺失值之后将产生一个新的变量“PREVEXP_without_missing”。</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">DerivedField</span> <span class="attr">dataType</span>=<span class="string">"double"</span> <span class="attr">name</span>=<span class="string">"PREVEXP_without_missing"</span> </span></span><br><span class="line"><span class="tag"><span class="attr">optype</span>=<span class="string">"continuous"</span>&gt;</span> </span><br><span class="line">   <span class="tag">&lt;<span class="name">Apply</span> <span class="attr">function</span>=<span class="string">"if"</span>&gt;</span> </span><br><span class="line">       <span class="tag">&lt;<span class="name">Apply</span> <span class="attr">function</span>=<span class="string">"isMissing"</span>&gt;</span> </span><br><span class="line">           <span class="tag">&lt;<span class="name">FieldRef</span> <span class="attr">field</span>=<span class="string">"PREVEXP"</span>/&gt;</span> </span><br><span class="line">       <span class="tag">&lt;/<span class="name">Apply</span>&gt;</span> </span><br><span class="line">       <span class="tag">&lt;<span class="name">Constant</span>&gt;</span>mean<span class="tag">&lt;/<span class="name">Constant</span>&gt;</span> </span><br><span class="line">       <span class="tag">&lt;<span class="name">FieldRef</span> <span class="attr">field</span>=<span class="string">"PREVEXP"</span>/&gt;</span> </span><br><span class="line">   <span class="tag">&lt;/<span class="name">Apply</span>&gt;</span> </span><br><span class="line"><span class="tag">&lt;/<span class="name">DerivedField</span>&gt;</span></span><br></pre></td></tr></table></figure>

<h3 id="模型定义-Model-Definition"><a href="#模型定义-Model-Definition" class="headerlink" title="模型定义 (Model Definition)"></a>模型定义 (Model Definition)</h3><p>具体的模型定义，最新的 PMML 4.0.1 定义了一下十三种模型：</p>
<ul>
<li>AssociationModel</li>
<li>ClusteringModel</li>
<li>GeneralRegressionModel</li>
<li>MiningModel</li>
<li>NaiveBayesModel</li>
<li>NeuralNetwork</li>
<li>RegressionModel</li>
<li>RuleSetModel</li>
<li>SequenceModel</li>
<li>SupportVectorMachineModel</li>
<li>TextModel</li>
<li>TimeSeriesModel</li>
<li>TreeModel</li>
</ul>
<p>这些模型都是帮助使用者从历史性的数据中提取出无法直观发现的，具有推广意义的数据模式。</p>
<ul>
<li>Association model，关联规则模型，常被用来发现大量交易数据中不同产品的购买关系和规则。使用其分析超市的销售单就可以发现，那些购买婴幼儿奶粉和护肤品的客户同时也会以较大的可能性去购买纸尿裤。这样有助于管理人员作出合理的商业决策，有导向的推动购物行为，比如将上述产品放在相邻的购物架上便于客户购买，从而产生更高的销售额。</li>
<li>Tree model，树模型，也是很常用的模型，她采用类似树分支的结构将数据逐层划分成节点，而每个叶子节点就表示一个特别的类别。树模型受到应用领域广泛的欢迎，还有一个重要的原因就是她所做出的预测决策易于解释，能够快速推广。为了支持这些模型，PMML 标准提供了大量的语法来有针对性的表示不同的模型。</li>
</ul>
<h3 id="评分结果-Score-Result"><a href="#评分结果-Score-Result" class="headerlink" title="评分结果(Score Result)"></a>评分结果(Score Result)</h3><p>评分结果集可以在输出元素 (Output) 中定义</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">Output</span>&gt;</span> </span><br><span class="line">  <span class="tag">&lt;<span class="name">OutputField</span> <span class="attr">name</span>=<span class="string">"$R-Drug"</span> <span class="attr">displayName</span>=<span class="string">"Predicted Value"</span> <span class="attr">optype</span>=<span class="string">"categorical"</span></span></span><br><span class="line"><span class="tag">    <span class="attr">dataType</span>=<span class="string">"string"</span> <span class="attr">targetField</span>=<span class="string">"Drug"</span> <span class="attr">feature</span>=<span class="string">"predictedValue"</span>/&gt;</span>    </span><br><span class="line">  <span class="tag">&lt;<span class="name">OutputField</span> <span class="attr">name</span>=<span class="string">"$RC-Drug"</span> <span class="attr">displayName</span>=<span class="string">"Confidence of Predicted Value"</span> </span></span><br><span class="line"><span class="tag">    <span class="attr">optype</span>=<span class="string">"continuous"</span> <span class="attr">dataType</span>=<span class="string">"double"</span> <span class="attr">targetField</span>=<span class="string">"Drug"</span> </span></span><br><span class="line"><span class="tag">    <span class="attr">feature</span>=<span class="string">"standardError"</span>/&gt;</span>        </span><br><span class="line">  <span class="tag">&lt;<span class="name">OutputField</span> <span class="attr">name</span>=<span class="string">"$RP-drugA"</span> <span class="attr">displayName</span>=<span class="string">"Probability of drugA"</span></span></span><br><span class="line"><span class="tag">    <span class="attr">optype</span>=<span class="string">"categorical"</span> <span class="attr">dataType</span>=<span class="string">"string"</span> <span class="attr">targetField</span>=<span class="string">"Drug"</span> </span></span><br><span class="line"><span class="tag">    <span class="attr">feature</span>=<span class="string">"probability"</span> <span class="attr">value</span>=<span class="string">"drugA"</span>/&gt;</span>        </span><br><span class="line">  <span class="tag">&lt;<span class="name">OutputField</span> <span class="attr">name</span>=<span class="string">"$RP-drugB"</span> <span class="attr">displayName</span>=<span class="string">"Probability of drugB"</span></span></span><br><span class="line"><span class="tag">    <span class="attr">optype</span>=<span class="string">"categorical"</span> <span class="attr">dataType</span>=<span class="string">"string"</span> <span class="attr">targetField</span>=<span class="string">"Drug"</span> </span></span><br><span class="line"><span class="tag">    <span class="attr">feature</span>=<span class="string">"probability"</span> <span class="attr">value</span>=<span class="string">"drugB"</span>/&gt;</span>       </span><br><span class="line">  <span class="tag">&lt;<span class="name">OutputField</span> <span class="attr">name</span>=<span class="string">"$RP-drugC"</span> <span class="attr">displayName</span>=<span class="string">"Probability of drugC"</span></span></span><br><span class="line"><span class="tag">    <span class="attr">optype</span>=<span class="string">"categorical"</span> <span class="attr">dataType</span>=<span class="string">"string"</span> <span class="attr">targetField</span>=<span class="string">"Drug"</span> </span></span><br><span class="line"><span class="tag">    <span class="attr">feature</span>=<span class="string">"probability"</span> <span class="attr">value</span>=<span class="string">"drugC"</span>/&gt;</span> </span><br><span class="line">  <span class="tag">&lt;<span class="name">OutputField</span> <span class="attr">name</span>=<span class="string">"$RP-drugX"</span> <span class="attr">displayName</span>=<span class="string">"Probability of drugX"</span></span></span><br><span class="line"><span class="tag">    <span class="attr">optype</span>=<span class="string">"categorical"</span> <span class="attr">dataType</span>=<span class="string">"string"</span> <span class="attr">targetField</span>=<span class="string">"Drug"</span> </span></span><br><span class="line"><span class="tag">    <span class="attr">feature</span>=<span class="string">"probability"</span> <span class="attr">value</span>=<span class="string">"drugX"</span>/&gt;</span> </span><br><span class="line">  <span class="tag">&lt;<span class="name">OutputField</span> <span class="attr">name</span>=<span class="string">"$RP-drugY"</span> <span class="attr">displayName</span>=<span class="string">"Probability of drugY"</span></span></span><br><span class="line"><span class="tag">    <span class="attr">optype</span>=<span class="string">"categorical"</span> <span class="attr">dataType</span>=<span class="string">"string"</span> <span class="attr">targetField</span>=<span class="string">"Drug"</span> </span></span><br><span class="line"><span class="tag">    <span class="attr">feature</span>=<span class="string">"probability"</span> <span class="attr">value</span>=<span class="string">"drugY"</span>/&gt;</span> </span><br><span class="line"><span class="tag">&lt;/<span class="name">Output</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>输出元素 : 描述了从模型中获取评分结果值的集合。每一个输出变量指定名称，类型，规则计算和结果特征。<br>结果特征 (feature): 它是一个结果的标识符 , 它有很多的分类表达，常见统计观念如下：</p>
<ul>
<li>预测价值（predictedValue）：它描述了预测统计的目标值。</li>
<li>概率（probability）：它描述预测统计的目标值的概率值。</li>
<li>标准误差（standardError）：它描述了标准误差的预测数值。</li>
</ul>
<p>其他类型参见 <a href="http://dmg.org/pmml/v4-3/Output.html" target="_blank" rel="noopener">http://dmg.org/pmml/v4-3/Output.html</a></p>
<h2 id="样例pmml"><a href="#样例pmml" class="headerlink" title="样例pmml"></a>样例pmml</h2><h3 id="LR-pmml"><a href="#LR-pmml" class="headerlink" title="LR.pmml"></a>LR.pmml</h3><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version="1.0"?&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">PMML</span> <span class="attr">version</span>=<span class="string">"4.3"</span> <span class="attr">xmlns</span>=<span class="string">"http://www.dmg.org/PMML-4_3"</span> <span class="attr">xmlns:xsi</span>=<span class="string">"http://www.w3.org/2001/XMLSchema-instance"</span> <span class="attr">xsi:schemaLocation</span>=<span class="string">"http://www.dmg.org/PMML-4_3 http://www.dmg.org/pmml/v4-3/pmml-4-3.xsd"</span>&gt;</span></span><br><span class="line"> <span class="tag">&lt;<span class="name">Header</span> <span class="attr">copyright</span>=<span class="string">"Copyright (c) 2017 liaotuo"</span> <span class="attr">description</span>=<span class="string">"Generalized Linear Regression Model"</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">Extension</span> <span class="attr">name</span>=<span class="string">"user"</span> <span class="attr">value</span>=<span class="string">"liaotuo"</span> <span class="attr">extender</span>=<span class="string">"Rattle/PMML"</span>/&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">Application</span> <span class="attr">name</span>=<span class="string">"Rattle/PMML"</span> <span class="attr">version</span>=<span class="string">"1.4"</span>/&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">Timestamp</span>&gt;</span>2017-07-11 13:18:36<span class="tag">&lt;/<span class="name">Timestamp</span>&gt;</span></span><br><span class="line"> <span class="tag">&lt;/<span class="name">Header</span>&gt;</span></span><br><span class="line"> <span class="tag">&lt;<span class="name">DataDictionary</span> <span class="attr">numberOfFields</span>=<span class="string">"4"</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">DataField</span> <span class="attr">name</span>=<span class="string">"am"</span> <span class="attr">optype</span>=<span class="string">"continuous"</span> <span class="attr">dataType</span>=<span class="string">"double"</span>/&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">DataField</span> <span class="attr">name</span>=<span class="string">"cyl"</span> <span class="attr">optype</span>=<span class="string">"continuous"</span> <span class="attr">dataType</span>=<span class="string">"double"</span>/&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">DataField</span> <span class="attr">name</span>=<span class="string">"hp"</span> <span class="attr">optype</span>=<span class="string">"continuous"</span> <span class="attr">dataType</span>=<span class="string">"double"</span>/&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">DataField</span> <span class="attr">name</span>=<span class="string">"wt"</span> <span class="attr">optype</span>=<span class="string">"continuous"</span> <span class="attr">dataType</span>=<span class="string">"double"</span>/&gt;</span></span><br><span class="line"> <span class="tag">&lt;/<span class="name">DataDictionary</span>&gt;</span></span><br><span class="line"> <span class="tag">&lt;<span class="name">GeneralRegressionModel</span> <span class="attr">modelName</span>=<span class="string">"General_Regression_Model"</span> <span class="attr">modelType</span>=<span class="string">"generalizedLinear"</span> <span class="attr">functionName</span>=<span class="string">"regression"</span> <span class="attr">algorithmName</span>=<span class="string">"glm"</span> <span class="attr">distribution</span>=<span class="string">"binomial"</span> <span class="attr">linkFunction</span>=<span class="string">"logit"</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">MiningSchema</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">MiningField</span> <span class="attr">name</span>=<span class="string">"am"</span> <span class="attr">usageType</span>=<span class="string">"predicted"</span>/&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">MiningField</span> <span class="attr">name</span>=<span class="string">"cyl"</span> <span class="attr">usageType</span>=<span class="string">"active"</span>/&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">MiningField</span> <span class="attr">name</span>=<span class="string">"hp"</span> <span class="attr">usageType</span>=<span class="string">"active"</span>/&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">MiningField</span> <span class="attr">name</span>=<span class="string">"wt"</span> <span class="attr">usageType</span>=<span class="string">"active"</span>/&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">MiningSchema</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">Output</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">OutputField</span> <span class="attr">name</span>=<span class="string">"Predicted_am"</span> <span class="attr">feature</span>=<span class="string">"predictedValue"</span>/&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">Output</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">ParameterList</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">Parameter</span> <span class="attr">name</span>=<span class="string">"p0"</span> <span class="attr">label</span>=<span class="string">"(Intercept)"</span>/&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">Parameter</span> <span class="attr">name</span>=<span class="string">"p1"</span> <span class="attr">label</span>=<span class="string">"cyl"</span>/&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">Parameter</span> <span class="attr">name</span>=<span class="string">"p2"</span> <span class="attr">label</span>=<span class="string">"hp"</span>/&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">Parameter</span> <span class="attr">name</span>=<span class="string">"p3"</span> <span class="attr">label</span>=<span class="string">"wt"</span>/&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">ParameterList</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">FactorList</span>/&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">CovariateList</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">Predictor</span> <span class="attr">name</span>=<span class="string">"cyl"</span>/&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">Predictor</span> <span class="attr">name</span>=<span class="string">"hp"</span>/&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">Predictor</span> <span class="attr">name</span>=<span class="string">"wt"</span>/&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">CovariateList</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">PPMatrix</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">PPCell</span> <span class="attr">value</span>=<span class="string">"1"</span> <span class="attr">predictorName</span>=<span class="string">"cyl"</span> <span class="attr">parameterName</span>=<span class="string">"p1"</span>/&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">PPCell</span> <span class="attr">value</span>=<span class="string">"1"</span> <span class="attr">predictorName</span>=<span class="string">"hp"</span> <span class="attr">parameterName</span>=<span class="string">"p2"</span>/&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">PPCell</span> <span class="attr">value</span>=<span class="string">"1"</span> <span class="attr">predictorName</span>=<span class="string">"wt"</span> <span class="attr">parameterName</span>=<span class="string">"p3"</span>/&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">PPMatrix</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">ParamMatrix</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">PCell</span> <span class="attr">parameterName</span>=<span class="string">"p0"</span> <span class="attr">df</span>=<span class="string">"1"</span> <span class="attr">beta</span>=<span class="string">"19.7028827927103"</span>/&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">PCell</span> <span class="attr">parameterName</span>=<span class="string">"p1"</span> <span class="attr">df</span>=<span class="string">"1"</span> <span class="attr">beta</span>=<span class="string">"0.487597975045672"</span>/&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">PCell</span> <span class="attr">parameterName</span>=<span class="string">"p2"</span> <span class="attr">df</span>=<span class="string">"1"</span> <span class="attr">beta</span>=<span class="string">"0.0325916758086386"</span>/&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">PCell</span> <span class="attr">parameterName</span>=<span class="string">"p3"</span> <span class="attr">df</span>=<span class="string">"1"</span> <span class="attr">beta</span>=<span class="string">"-9.14947126999654"</span>/&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">ParamMatrix</span>&gt;</span></span><br><span class="line"> <span class="tag">&lt;/<span class="name">GeneralRegressionModel</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">PMML</span>&gt;</span></span><br></pre></td></tr></table></figure>

<h3 id="rule-pmml"><a href="#rule-pmml" class="headerlink" title="rule.pmml"></a>rule.pmml</h3><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">RuleSetModel</span> <span class="attr">modelName</span>=<span class="string">"RiskEval"</span> <span class="attr">functionName</span>=<span class="string">"classification"</span> <span class="attr">algorithmName</span>=<span class="string">"RuleSet"</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">MiningSchema</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">MiningField</span> <span class="attr">name</span>=<span class="string">"var973"</span> <span class="attr">usageType</span>=<span class="string">"active"</span> <span class="attr">invalidValueTreatment</span>=<span class="string">"asMissing"</span> <span class="attr">missingValueReplacement</span>=<span class="string">"0"</span>/&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">MiningField</span> <span class="attr">name</span>=<span class="string">"var969"</span> <span class="attr">usageType</span>=<span class="string">"active"</span> <span class="attr">invalidValueTreatment</span>=<span class="string">"asMissing"</span> <span class="attr">missingValueReplacement</span>=<span class="string">"0"</span>/&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">MiningField</span> <span class="attr">name</span>=<span class="string">"var20"</span> <span class="attr">usageType</span>=<span class="string">"active"</span> <span class="attr">invalidValueTreatment</span>=<span class="string">"asMissing"</span> <span class="attr">missingValueReplacement</span>=<span class="string">"0"</span>/&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">MiningField</span> <span class="attr">name</span>=<span class="string">"var393"</span> <span class="attr">usageType</span>=<span class="string">"active"</span> <span class="attr">invalidValueTreatment</span>=<span class="string">"asMissing"</span> <span class="attr">missingValueReplacement</span>=<span class="string">"0"</span>/&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">MiningField</span> <span class="attr">name</span>=<span class="string">"var868"</span> <span class="attr">usageType</span>=<span class="string">"active"</span> <span class="attr">invalidValueTreatment</span>=<span class="string">"asMissing"</span> <span class="attr">missingValueReplacement</span>=<span class="string">"0"</span>/&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">MiningField</span> <span class="attr">name</span>=<span class="string">"var543"</span> <span class="attr">usageType</span>=<span class="string">"active"</span> <span class="attr">invalidValueTreatment</span>=<span class="string">"asMissing"</span> <span class="attr">missingValueReplacement</span>=<span class="string">"0"</span>/&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">MiningField</span> <span class="attr">name</span>=<span class="string">"var1213"</span> <span class="attr">usageType</span>=<span class="string">"active"</span> <span class="attr">invalidValueTreatment</span>=<span class="string">"asMissing"</span> <span class="attr">missingValueReplacement</span>=<span class="string">"0.0"</span>/&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">MiningField</span> <span class="attr">name</span>=<span class="string">"flg"</span> <span class="attr">usageType</span>=<span class="string">"target"</span>/&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">MiningSchema</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">RuleSet</span> <span class="attr">defaultScore</span>=<span class="string">"0"</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">RuleSelectionMethod</span> <span class="attr">criterion</span>=<span class="string">"firstHit"</span>/&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">SimpleRule</span> <span class="attr">id</span>=<span class="string">"RULE1"</span> <span class="attr">score</span>=<span class="string">"1"</span> <span class="attr">confidence</span>=<span class="string">"1"</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">CompoundPredicate</span> <span class="attr">booleanOperator</span>=<span class="string">"or"</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">SimplePredicate</span> <span class="attr">field</span>=<span class="string">"var973"</span> <span class="attr">operator</span>=<span class="string">"greaterOrEqual"</span> <span class="attr">value</span>=<span class="string">"1"</span>/&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">SimplePredicate</span> <span class="attr">field</span>=<span class="string">"var969"</span> <span class="attr">operator</span>=<span class="string">"greaterOrEqual"</span> <span class="attr">value</span>=<span class="string">"1"</span>/&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">SimplePredicate</span> <span class="attr">field</span>=<span class="string">"var20"</span> <span class="attr">operator</span>=<span class="string">"greaterOrEqual"</span> <span class="attr">value</span>=<span class="string">"7"</span>/&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">CompoundPredicate</span> <span class="attr">booleanOperator</span>=<span class="string">"and"</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="name">SimplePredicate</span> <span class="attr">field</span>=<span class="string">"var393"</span> <span class="attr">operator</span>=<span class="string">"greaterOrEqual"</span> <span class="attr">value</span>=<span class="string">"2"</span>/&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="name">SimplePredicate</span> <span class="attr">field</span>=<span class="string">"var543"</span> <span class="attr">operator</span>=<span class="string">"notEqual"</span> <span class="attr">value</span>=<span class="string">"1"</span>/&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">CompoundPredicate</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">CompoundPredicate</span> <span class="attr">booleanOperator</span>=<span class="string">"and"</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="name">SimplePredicate</span> <span class="attr">field</span>=<span class="string">"var868"</span> <span class="attr">operator</span>=<span class="string">"greaterOrEqual"</span> <span class="attr">value</span>=<span class="string">"1"</span>/&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="name">SimplePredicate</span> <span class="attr">field</span>=<span class="string">"var1213"</span> <span class="attr">operator</span>=<span class="string">"lessThan"</span> <span class="attr">value</span>=<span class="string">"0.8"</span>/&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">CompoundPredicate</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;/<span class="name">CompoundPredicate</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">SimpleRule</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">RuleSet</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">RuleSetModel</span>&gt;</span></span><br></pre></td></tr></table></figure>


<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p><a href="https://blog.csdn.net/c1481118216/article/details/78411200" target="_blank" rel="noopener">https://blog.csdn.net/c1481118216/article/details/78411200</a></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

  </div>

  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/32/"><i class="fa fa-angle-left" aria-label="上一页"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/32/">32</a><span class="page-number current">33</span><a class="page-number" href="/page/34/">34</a><span class="space">&hellip;</span><a class="page-number" href="/page/36/">36</a><a class="extend next" rel="next" href="/page/34/"><i class="fa fa-angle-right" aria-label="下一页"></i></a>
  </nav>



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let activeClass = CONFIG.comments.activeClass;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">zhoul</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">351</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">92</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">190</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/longzl2015" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;longzl2015" rel="noopener" target="_blank"><i class="fa fa-fw fa-github"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:289570126@qq.com" title="E-Mail → mailto:289570126@qq.com" rel="noopener" target="_blank"><i class="fa fa-fw fa-envelope"></i>E-Mail</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://stackoverflow.com/users/5276366/egg" title="StackOverflow → https:&#x2F;&#x2F;stackoverflow.com&#x2F;users&#x2F;5276366&#x2F;egg" rel="noopener" target="_blank"><i class="fa fa-fw fa-stack-overflow"></i>StackOverflow</a>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">zhoul</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> 强力驱动 v4.2.0
  </div>
  <span class="post-meta-divider">|</span>
  <div class="theme-info">主题 – <a href="https://theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a> v7.7.0
  </div>

        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>













  

  

<script>
  function loadCount() {
    var d = document, s = d.createElement('script');
    s.src = 'https://long12356-gitee-io.disqus.com/count.js';
    s.id = 'dsq-count-scr';
    (d.head || d.body).appendChild(s);
  }
  // defer loading until the whole page loading is completed
  window.addEventListener('load', loadCount, false);
</script>

</body>
</html>
