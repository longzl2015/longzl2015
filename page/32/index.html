<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 4.2.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css">


<script id="hexo-configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    hostname: new URL('https://longzl2015.github.io').hostname,
    root: '/',
    scheme: 'Gemini',
    version: '7.7.0',
    exturl: false,
    sidebar: {"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},
    copycode: {"enable":false,"show_result":false,"style":null},
    back2top: {"enable":true,"sidebar":false,"scrollpercent":false},
    bookmark: {"enable":false,"color":"#222","save":"auto"},
    fancybox: false,
    mediumzoom: false,
    lazyload: false,
    pangu: false,
    comments: {"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},
    algolia: {
      appID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"我们没有找到任何搜索结果: ${query}","hits_stats":"找到约${hits}条结果（用时${time}ms）"}
    },
    localsearch: {"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":true},
    path: 'search.xml',
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}
  };
</script>

  <meta property="og:type" content="website">
<meta property="og:title" content="Hexo">
<meta property="og:url" content="https://longzl2015.github.io/page/32/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="zhoul">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="https://longzl2015.github.io/page/32/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome: true,
    isPost: false
  };
</script>

  <title>Hexo</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-meta">

    <div>
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Hexo</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
  </div>

  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>
</div>


<nav class="site-nav">
  
  <ul id="menu" class="menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-fw fa-home"></i>首页</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-fw fa-tags"></i>标签<span class="badge">190</span></a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-fw fa-th"></i>分类<span class="badge">92</span></a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-fw fa-archive"></i>归档<span class="badge">351</span></a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>

</nav>
  <div class="site-search">
    <div class="popup search-popup">
    <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocorrect="off" autocapitalize="none"
           placeholder="搜索..." spellcheck="false"
           type="text" id="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result"></div>

</div>
<div class="search-pop-overlay"></div>

  </div>
</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content">
            

  <div class="posts-expand">
        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://longzl2015.github.io/2016/04/02/hadoop%E7%94%9F%E6%80%81/hadoop/hadoop%20balancer%20%E7%9A%84%E4%BD%BF%E7%94%A8%E7%BB%8F%E9%AA%8C/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="zhoul">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2016/04/02/hadoop%E7%94%9F%E6%80%81/hadoop/hadoop%20balancer%20%E7%9A%84%E4%BD%BF%E7%94%A8%E7%BB%8F%E9%AA%8C/" class="post-title-link" itemprop="url">hadoop balancer 的使用经验</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2016-04-02 22:46:48" itemprop="dateCreated datePublished" datetime="2016-04-02T22:46:48+08:00">2016-04-02</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-02-27 17:16:07" itemprop="dateModified" datetime="2020-02-27T17:16:07+08:00">2020-02-27</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/hadoop%E7%94%9F%E6%80%81/" itemprop="url" rel="index">
                    <span itemprop="name">hadoop生态</span>
                  </a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/hadoop%E7%94%9F%E6%80%81/hadoop/" itemprop="url" rel="index">
                    <span itemprop="name">hadoop</span>
                  </a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="fa fa-comment-o"></i>
      </span>
      <span class="post-meta-item-text">Disqus：</span>
    
    <a title="disqus" href="/2016/04/02/hadoop%E7%94%9F%E6%80%81/hadoop/hadoop%20balancer%20%E7%9A%84%E4%BD%BF%E7%94%A8%E7%BB%8F%E9%AA%8C/#comments" itemprop="discussionUrl">
      <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2016/04/02/hadoop生态/hadoop/hadoop balancer 的使用经验/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>由于历史原因，hadoop集群中的机器的磁盘空间的大小各不相同，而HDFS在进行写入操作时，并没有考虑到这种情况，所以随着数据量的逐渐增加，磁盘较小的datanode机器上的磁盘空间很快将被写满，从而触发了报警。<br>此时，不得不手工执行start-balancer.sh来进行balance操作，即使将dfs.balance.bandwidthPerSec  参数设置为10M/s，整个集群达到平衡也需要很长的时间，所以写了个<code>crontab</code>来每天凌晨来执行start-balancer.sh，由于此时集群不平衡的状态还没有那么严重，所以start-balancer.sh很快执行结束了。</p>
<h3 id="不要在namenode中执行banlance指令"><a href="#不要在namenode中执行banlance指令" class="headerlink" title="不要在namenode中执行banlance指令"></a>不要在namenode中执行banlance指令</h3><p>由于HDFS需要启动单独的Rebalance Server来执行Rebalance操作，所以尽量不要在NameNode上执行start-balancer.sh，而是找一台比较空闲的机器。</p>
<h3 id="hadoop-balance工具的用法："><a href="#hadoop-balance工具的用法：" class="headerlink" title="hadoop balance工具的用法："></a>hadoop balance工具的用法：</h3><p>开始：  <code>bin/start-balancer.sh [-threshold &lt;threshold&gt;]</code>  </p>
<p>停止：  <code>bin/stop-balancer.sh</code></p>
<h3 id="影响hadoop-balance工具的几个参数："><a href="#影响hadoop-balance工具的几个参数：" class="headerlink" title="影响hadoop balance工具的几个参数："></a>影响hadoop balance工具的几个参数：</h3><ul>
<li><p>threshold<br>默认设置：10，参数取值范围：0-100，参数含义：判断集群是否平衡的目标参数，每一个 datanode 存储使用率和集群总存储使用率的差值都应该小于这个阀值 ，理论上，该参数设置的越小，整个集群就越平衡，但是在线上环境中，hadoop集群在进行balance时，还在并发的进行数据的写入和删除，所以有可能无法到达设定的平衡参数值。</p>
</li>
<li><p>setBalancerBandwidth<br>可以使用如下命令修改 balancer宽带参数<br><code>hdfs dfsadmin -setBalancerBandwidth 67108864</code><br>默认设置：1048576（1 M/S），参数含义：设置balance工具在运行中所能占用的带宽，设置的过大可能会造成mapred运行缓慢</p>
</li>
</ul>
<h3 id="命令-未验证"><a href="#命令-未验证" class="headerlink" title="命令 (未验证)"></a>命令 (未验证)</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdfs balancer -Dfs.defaultFS&#x3D;hdfs:&#x2F;&#x2F;&lt;NN_HOSTNAME&gt;:8020 -Ddfs.balancer.movedWinWidth&#x3D;5400000 -Ddfs.balancer.moverThreads&#x3D;1000 -Ddfs.balancer.dispatcherThreads&#x3D;200 -Ddfs.datanode.balance.max.concurrent.moves&#x3D;5 -Ddfs.balance.bandwidthPerSec&#x3D;100000000 -Ddfs.balancer.max-size-to-move&#x3D;10737418240 -threshold 5</span><br></pre></td></tr></table></figure>

<h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><p><a href="https://hadoop.apache.org/docs/r2.7.3/hadoop-project-dist/hadoop-hdfs/HDFSCommands.html#balancer" target="_blank" rel="noopener">hadoop command guide</a><br><a href="http://forum.huawei.com/enterprise/thread-363899-1-1.html" target="_blank" rel="noopener">Hadoop集群datanode磁盘不均衡的解决方案</a></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://longzl2015.github.io/2016/04/02/hadoop%E7%94%9F%E6%80%81/hadoop/hadoop%20%E4%BF%AE%E6%94%B9%E5%A4%87%E4%BB%BD%E7%B3%BB%E6%95%B0/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="zhoul">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2016/04/02/hadoop%E7%94%9F%E6%80%81/hadoop/hadoop%20%E4%BF%AE%E6%94%B9%E5%A4%87%E4%BB%BD%E7%B3%BB%E6%95%B0/" class="post-title-link" itemprop="url">hadoop 修改备份系数</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2016-04-02 22:46:48" itemprop="dateCreated datePublished" datetime="2016-04-02T22:46:48+08:00">2016-04-02</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-02-27 17:16:07" itemprop="dateModified" datetime="2020-02-27T17:16:07+08:00">2020-02-27</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/hadoop%E7%94%9F%E6%80%81/" itemprop="url" rel="index">
                    <span itemprop="name">hadoop生态</span>
                  </a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/hadoop%E7%94%9F%E6%80%81/hadoop/" itemprop="url" rel="index">
                    <span itemprop="name">hadoop</span>
                  </a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="fa fa-comment-o"></i>
      </span>
      <span class="post-meta-item-text">Disqus：</span>
    
    <a title="disqus" href="/2016/04/02/hadoop%E7%94%9F%E6%80%81/hadoop/hadoop%20%E4%BF%AE%E6%94%B9%E5%A4%87%E4%BB%BD%E7%B3%BB%E6%95%B0/#comments" itemprop="discussionUrl">
      <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2016/04/02/hadoop生态/hadoop/hadoop 修改备份系数/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h3 id="查看文件备份数"><a href="#查看文件备份数" class="headerlink" title="查看文件备份数"></a>查看文件备份数</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@VLNX107011 hue]# hdfs dfs -ls &#x2F;facishare-data&#x2F;flume&#x2F;test</span><br><span class="line">Found 2 items</span><br><span class="line">drwxr-xr-x   - fsdevops fsdevops          0 2015-11-18 11:09 &#x2F;facishare-data&#x2F;flume&#x2F;test&#x2F;2015</span><br><span class="line">-rw-r--r--   2 fsdevops fsdevops         33 2015-11-30 17:49 &#x2F;facishare-data&#x2F;flume&#x2F;test&#x2F;nohup.out</span><br></pre></td></tr></table></figure>

<p>结果行中的第2列是备份系数(注：文件夹信息存储在namenode节点上，没有备份，故文件夹的备份系数是横杠)</p>
<h3 id="查看集群平均备份数"><a href="#查看集群平均备份数" class="headerlink" title="查看集群平均备份数"></a>查看集群平均备份数</h3><p>通过hadoop fsck /可以方便的看到Average block replication的值，这个值不一定会与Default replication factor相等。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">[root@VLNX107011 hue]# hdfs fsck &#x2F;</span><br><span class="line">Connecting to namenode via http:&#x2F;&#x2F;VLNX107011:50070</span><br><span class="line">FSCK started by root (auth:SIMPLE) from &#x2F;VLNX107011 for path &#x2F; at Fri Dec 04 19:08:09 CST 2015</span><br><span class="line">...................</span><br><span class="line"> Total size:	11837043630 B (Total open files size: 166 B)</span><br><span class="line"> Total dirs:	3980</span><br><span class="line"> Total files:	3254</span><br><span class="line"> Total symlinks:		0 (Files currently being written: 2)</span><br><span class="line"> Total blocks (validated):	2627 (avg. block size 4505916 B) (Total open file blocks (not validated): 2)</span><br><span class="line"> Minimally replicated blocks:	2627 (100.0 %)</span><br><span class="line"> Over-replicated blocks:	2253 (85.76323 %)</span><br><span class="line"> Under-replicated blocks:	0 (0.0 %)</span><br><span class="line"> Mis-replicated blocks:		0 (0.0 %)</span><br><span class="line"> Default replication factor:	3</span><br><span class="line"> Average block replication:	2.9798248</span><br><span class="line"> Corrupt blocks:		0</span><br><span class="line"> Missing replicas:		0 (0.0 %)</span><br><span class="line"> Number of data-nodes:		10</span><br><span class="line"> Number of racks:		1</span><br><span class="line">FSCK ended at Fri Dec 04 19:08:09 CST 2015 in 100 milliseconds</span><br><span class="line">The filesystem under path &#39;&#x2F;&#39; is HEALTHY</span><br></pre></td></tr></table></figure>

<p>可以看到<code>Average block replication</code>, <code>Corrupt blocks</code>, <code>Missing replicas</code>等信息。</p>
<h3 id="修改备份系数"><a href="#修改备份系数" class="headerlink" title="修改备份系数"></a>修改备份系数</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[root@VLNX107011 hue]# hdfs dfs -setrep -w 3 -R &#x2F;</span><br><span class="line">Replication 3 set: &#x2F;user&#x2F;oozie&#x2F;share&#x2F;lib&#x2F;lib_20151103160704&#x2F;hive&#x2F;jetty-all-7.6.0.v20120127.jar</span><br><span class="line">Replication 3 set: &#x2F;user&#x2F;oozie&#x2F;share&#x2F;lib&#x2F;lib_20151103160704&#x2F;hive&#x2F;jline-2.11.jar</span><br><span class="line">......</span><br><span class="line">Waiting for &#x2F;backup&#x2F;gitlab&#x2F;1447133001_gitlab_backup.tar ........... done</span><br><span class="line">Waiting for &#x2F;backup&#x2F;gitlab&#x2F;1447133732_gitlab_backup.tar ... done</span><br><span class="line">Waiting for &#x2F;backup&#x2F;gitlab&#x2F;1447180217_gitlab_backup.tar ... done</span><br><span class="line">......</span><br></pre></td></tr></table></figure>
<p>可以看到HDFS对所有文件的备份系数进行了刷新。</p>
<p>再次检查刚才文件的备份系数，可以看到从2变为3。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@VLNX107011 hue]# hdfs dfs -ls &#x2F;facishare-data&#x2F;flume&#x2F;test</span><br><span class="line">Found 2 items</span><br><span class="line">drwxr-xr-x   - fsdevops fsdevops          0 2015-11-18 11:09 &#x2F;facishare-data&#x2F;flume&#x2F;test&#x2F;2015</span><br><span class="line">-rw-r--r--   3 fsdevops fsdevops         33 2015-11-30 17:49 &#x2F;facishare-data&#x2F;flume&#x2F;test&#x2F;nohup.out</span><br></pre></td></tr></table></figure>

<p><strong>WARNING</strong><br>将备份系数从低到高比较容易，但从高到低会特别慢，所以在集群搭建初始就要规划好Default replication factor。<br>通常备份系数不需要太高，可以是服务器总量的1/3左右即可，Hadoop默认的数值是3。</p>
<h3 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h3><p><a href="http://wzktravel.github.io/2016/01/19/hdfs-add-nodes-dynamically/" target="_blank" rel="noopener">HDFS修改备份系数和动态增删节点</a></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://longzl2015.github.io/2016/04/02/hadoop%E7%94%9F%E6%80%81/hadoop/hadoop%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A4/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="zhoul">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2016/04/02/hadoop%E7%94%9F%E6%80%81/hadoop/hadoop%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A4/" class="post-title-link" itemprop="url">hadoop常用命令</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2016-04-02 22:46:48" itemprop="dateCreated datePublished" datetime="2016-04-02T22:46:48+08:00">2016-04-02</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-02-27 17:16:07" itemprop="dateModified" datetime="2020-02-27T17:16:07+08:00">2020-02-27</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/hadoop%E7%94%9F%E6%80%81/" itemprop="url" rel="index">
                    <span itemprop="name">hadoop生态</span>
                  </a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/hadoop%E7%94%9F%E6%80%81/hadoop/" itemprop="url" rel="index">
                    <span itemprop="name">hadoop</span>
                  </a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="fa fa-comment-o"></i>
      </span>
      <span class="post-meta-item-text">Disqus：</span>
    
    <a title="disqus" href="/2016/04/02/hadoop%E7%94%9F%E6%80%81/hadoop/hadoop%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A4/#comments" itemprop="discussionUrl">
      <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2016/04/02/hadoop生态/hadoop/hadoop基础命令/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>命令基本格式:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -cmd &lt; args &gt;</span><br></pre></td></tr></table></figure>

<h3 id="1-ls-列出文件列表"><a href="#1-ls-列出文件列表" class="headerlink" title="1. ls 列出文件列表"></a>1. ls 列出文件列表</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -ls  &#x2F;</span><br></pre></td></tr></table></figure>

<p>列出hdfs文件系统根目录下的目录和文件</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -ls -R &#x2F;</span><br></pre></td></tr></table></figure>

<p>列出hdfs文件系统所有的目录和文件</p>
<h3 id="2-put-上传文件"><a href="#2-put-上传文件" class="headerlink" title="2. put 上传文件"></a>2. put 上传文件</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -put &lt; local file &gt; &lt; hdfs file &gt;</span><br></pre></td></tr></table></figure>

<p>hdfs file的父目录一定要存在，否则命令不会执行</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -put  &lt; local file or dir &gt;...&lt; hdfs dir &gt;</span><br></pre></td></tr></table></figure>

<p>hdfs dir 一定要存在，否则命令不会执行</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -put - &lt; hdsf  file&gt;</span><br></pre></td></tr></table></figure>

<p>从键盘读取输入到hdfs file中，按Ctrl+D结束输入，hdfs file不能存在，否则命令不会执行</p>
<h4 id="2-1-moveFromLocal"><a href="#2-1-moveFromLocal" class="headerlink" title="2.1. moveFromLocal"></a>2.1. moveFromLocal</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -moveFromLocal  &lt; local src &gt; ... &lt; hdfs dst &gt;</span><br></pre></td></tr></table></figure>

<p>与put相类似，命令执行后源文件 local src 被删除，也可以从从键盘读取输入到hdfs file中</p>
<h4 id="2-2-copyFromLocal"><a href="#2-2-copyFromLocal" class="headerlink" title="2.2. copyFromLocal"></a>2.2. copyFromLocal</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -copyFromLocal  &lt; local src &gt; ... &lt; hdfs dst &gt;</span><br></pre></td></tr></table></figure>

<p>与put相类似，也可以从从键盘读取输入到hdfs file中</p>
<h3 id="3-get-获取hdfs文件"><a href="#3-get-获取hdfs文件" class="headerlink" title="3. get 获取hdfs文件"></a>3. get 获取hdfs文件</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -get &lt; hdfs file &gt; &lt; local file or dir&gt;</span><br></pre></td></tr></table></figure>

<p>local file不能和 hdfs file名字不能相同，否则会提示文件已存在，没有重名的文件会复制到本地</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -get &lt; hdfs file or dir &gt; ... &lt; local  dir &gt;</span><br></pre></td></tr></table></figure>

<p>拷贝多个文件或目录到本地时，本地要为文件夹路径<br>注意：如果用户不是root， local 路径要为用户文件夹下的路径，否则会出现权限问题，</p>
<h4 id="3-1-moveToLocal"><a href="#3-1-moveToLocal" class="headerlink" title="3.1. moveToLocal"></a>3.1. moveToLocal</h4><p>当前版本中还未实现此命令</p>
<h4 id="3-2-copyToLocal"><a href="#3-2-copyToLocal" class="headerlink" title="3.2. copyToLocal"></a>3.2. copyToLocal</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -copyToLocal &lt; local src &gt; ... &lt; hdfs dst &gt;</span><br></pre></td></tr></table></figure>

<p>与get相类似</p>
<h3 id="4-rm-删除文件"><a href="#4-rm-删除文件" class="headerlink" title="4. rm 删除文件"></a>4. rm 删除文件</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -rm &lt; hdfs file &gt; ...</span><br><span class="line">hadoop fs -rm -r &lt; hdfs dir&gt;...</span><br></pre></td></tr></table></figure>

<p>每次可以删除多个文件或目录</p>
<h3 id="5-mkdir-创建"><a href="#5-mkdir-创建" class="headerlink" title="5. mkdir 创建"></a>5. mkdir 创建</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -mkdir &lt; hdfs path&gt;</span><br></pre></td></tr></table></figure>

<p>只能一级一级的建目录，父目录不存在的话使用这个命令会报错</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -mkdir -p &lt; hdfs path&gt;</span><br></pre></td></tr></table></figure>

<p>所创建的目录如果父目录不存在就创建该父目录</p>
<h3 id="6-getmerge-下载并合并文件"><a href="#6-getmerge-下载并合并文件" class="headerlink" title="6. getmerge 下载并合并文件"></a>6. getmerge 下载并合并文件</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -getmerge &lt; hdfs dir &gt;  &lt; local file &gt;</span><br></pre></td></tr></table></figure>

<p>将hdfs指定目录下所有文件排序后合并到local指定的文件中，文件不存在时会自动创建，文件存在时会覆盖里面的内容</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -getmerge -nl  &lt; hdfs dir &gt;  &lt; local file &gt;</span><br></pre></td></tr></table></figure>

<p>加上nl后，合并到local file中的hdfs文件之间会空出一行</p>
<h3 id="7-cp-hdfs间复制"><a href="#7-cp-hdfs间复制" class="headerlink" title="7. cp hdfs间复制"></a>7. cp hdfs间复制</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -cp  &lt; hdfs file &gt;  &lt; hdfs file &gt;</span><br></pre></td></tr></table></figure>

<p>目标文件不能存在，否则命令不能执行，相当于给文件重命名并保存，源文件还存在</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -cp &lt; hdfs file or dir &gt;... &lt; hdfs dir &gt;</span><br></pre></td></tr></table></figure>

<p>目标文件夹要存在，否则命令不能执行</p>
<h3 id="8-mv-hdfs间移动"><a href="#8-mv-hdfs间移动" class="headerlink" title="8. mv hdfs间移动"></a>8. mv hdfs间移动</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -mv &lt; hdfs file &gt;  &lt; hdfs file &gt;</span><br></pre></td></tr></table></figure>

<p>目标文件不能存在，否则命令不能执行，相当于给文件重命名并保存，源文件不存在</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -mv  &lt; hdfs file or dir &gt;...  &lt; hdfs dir &gt;</span><br></pre></td></tr></table></figure>

<p>源路径有多个时，目标路径必须为目录，且必须存在。<br>注意：跨文件系统的移动（local到hdfs或者反过来）都是不允许的</p>
<h3 id="9-count-统计数据"><a href="#9-count-统计数据" class="headerlink" title="9. count 统计数据"></a>9. count 统计数据</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -count &lt; hdfs path &gt;</span><br></pre></td></tr></table></figure>

<p>统计hdfs对应路径下的目录个数，文件个数，文件总计大小<br>显示为目录个数，文件个数，文件总计大小，输入路径</p>
<h3 id="10-du"><a href="#10-du" class="headerlink" title="10. du"></a>10. du</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -du &lt; hdsf path&gt;</span><br></pre></td></tr></table></figure>

<p>显示hdfs对应路径下每个文件夹和文件的大小</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -du -s &lt; hdsf path&gt;</span><br></pre></td></tr></table></figure>

<p>显示hdfs对应路径下所有文件和（sum）的大小</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -du -h &lt; hdsf path&gt;</span><br></pre></td></tr></table></figure>

<p>显示hdfs对应路径下每个文件夹和文件的大小,文件的大小用方便阅读的形式表示，例如用64M代替67108864</p>
<h4 id="10-1-文件排序"><a href="#10-1-文件排序" class="headerlink" title="10.1 文件排序"></a>10.1 文件排序</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -du &#x2F;user&#x2F;mls_3.3 | sort -rn</span><br></pre></td></tr></table></figure>

<p>显示 <code>/user/mls_3.3</code>路径下的文件并按大小排序</p>
<h3 id="11-text"><a href="#11-text" class="headerlink" title="11. text"></a>11. text</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -text &lt; hdsf file&gt;</span><br></pre></td></tr></table></figure>

<p>将文本文件或某些格式的非文本文件通过文本格式输出</p>
<h3 id="12-setrep"><a href="#12-setrep" class="headerlink" title="12. setrep"></a>12. setrep</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -setrep -R 3 &lt; hdfs path &gt;</span><br></pre></td></tr></table></figure>

<p>改变一个文件在hdfs中的副本个数，上述命令中数字3为所设置的副本个数，-R选项可以对一个人目录下的所有目录+文件递归执行改变副本个数的操作</p>
<h3 id="13-stat-获取文件信息"><a href="#13-stat-获取文件信息" class="headerlink" title="13. stat 获取文件信息"></a>13. stat 获取文件信息</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdoop fs -stat [format] &lt; hdfs path &gt;</span><br></pre></td></tr></table></figure>

<p>返回对应路径的状态信息<br>[format]可选参数有：%b（文件大小），%o（Block大小），%n（文件名），%r（副本个数），%y（最后一次修改日期和时间）<br>可以这样书写hadoop fs -stat %b%o%n &lt; hdfs path &gt;，不过不建议，这样每个字符输出的结果不是太容易分清楚</p>
<h3 id="14-tail"><a href="#14-tail" class="headerlink" title="14. tail"></a>14. tail</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -tail &lt; hdfs file &gt;</span><br></pre></td></tr></table></figure>

<p>在标准输出中显示文件末尾的1KB数据</p>
<h3 id="15-archive"><a href="#15-archive" class="headerlink" title="15. archive"></a>15. archive</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop archive -archiveName name.har -p &lt; hdfs parent dir &gt; &lt; src &gt;* &lt; hdfs dst &gt;</span><br></pre></td></tr></table></figure>


<p>命令中参数name：压缩文件名，自己任意取；&lt; hdfs parent dir &gt; ：压缩文件所在的父目录；&lt; src &gt;：要压缩的文件名；&lt; hdfs dst &gt;：压缩文件存放路径<br>*示例：hadoop archive -archiveName hadoop.har -p /user 1.txt 2.txt /des<br>示例中将hdfs中/user目录下的文件1.txt，2.txt压缩成一个名叫hadoop.har的文件存放在hdfs中/des目录下，如果1.txt，2.txt不写就是将/user目录下所有的目录和文件压缩成一个名叫hadoop.har的文件存放在hdfs中/des目录下<br>显示har的内容可以用如下命令：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -ls &#x2F;des&#x2F;hadoop.jar</span><br></pre></td></tr></table></figure>

<p>显示har压缩的是那些文件可以用如下命令</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -ls -R har:&#x2F;&#x2F;&#x2F;des&#x2F;hadoop.har</span><br></pre></td></tr></table></figure>

<p>注意：har文件不能进行二次压缩。如果想给.har加文件，只能找到原来的文件，重新创建一个。har文件中原来文件的数据并没有变化，har文件真正的作用是减少NameNode和DataNode过多的空间浪费。</p>
<h3 id="16-balancer"><a href="#16-balancer" class="headerlink" title="16. balancer"></a>16. balancer</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdfs balancer</span><br></pre></td></tr></table></figure>

<p>如果管理员发现某些DataNode保存数据过多，某些DataNode保存数据相对较少，可以使用上述命令手动启动内部的均衡过程</p>
<h3 id="17-dfsadmin"><a href="#17-dfsadmin" class="headerlink" title="17. dfsadmin"></a>17. dfsadmin</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdfs dfsadmin -help</span><br></pre></td></tr></table></figure>

<p>管理员可以通过dfsadmin管理HDFS，用法可以通过上述命令查看<br>hdfs dfsadmin -report</p>
<p>显示文件系统的基本数据</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdfs dfsadmin -safemode &lt; enter | leave | get | wait &gt;</span><br></pre></td></tr></table></figure>

<p>enter：进入安全模式；leave：离开安全模式；get：获知是否开启安全模式；<br>wait：等待离开安全模式</p>
<h3 id="18-distcp"><a href="#18-distcp" class="headerlink" title="18. distcp"></a>18. distcp</h3><p>用来在两个HDFS之间拷贝数据</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://longzl2015.github.io/2016/04/02/hadoop%E7%94%9F%E6%80%81/hadoop/uber%20mode/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="zhoul">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2016/04/02/hadoop%E7%94%9F%E6%80%81/hadoop/uber%20mode/" class="post-title-link" itemprop="url">MapReduce 作业Uber模式介绍</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2016-04-02 22:46:48" itemprop="dateCreated datePublished" datetime="2016-04-02T22:46:48+08:00">2016-04-02</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-02-27 17:16:07" itemprop="dateModified" datetime="2020-02-27T17:16:07+08:00">2020-02-27</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/hadoop%E7%94%9F%E6%80%81/" itemprop="url" rel="index">
                    <span itemprop="name">hadoop生态</span>
                  </a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/hadoop%E7%94%9F%E6%80%81/hadoop/" itemprop="url" rel="index">
                    <span itemprop="name">hadoop</span>
                  </a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="fa fa-comment-o"></i>
      </span>
      <span class="post-meta-item-text">Disqus：</span>
    
    <a title="disqus" href="/2016/04/02/hadoop%E7%94%9F%E6%80%81/hadoop/uber%20mode/#comments" itemprop="discussionUrl">
      <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2016/04/02/hadoop生态/hadoop/uber mode/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>提交MapReduce作业时 肯定看过如下的输出：</p>
<p>17/04/17 14:00:38 INFO mapreduce.Job: Running job: job_1472052053889_0001<br>17/04/17 14:00:48 INFO mapreduce.Job: Job job_1472052053889_0001 running in uber mode : false<br>17/04/17 14:00:48 INFO mapreduce.Job: map 0% reduce 0%<br>17/04/17 14:00:58 INFO mapreduce.Job: map 100% reduce 0%<br>17/04/17 14:01:04 INFO mapreduce.Job: map 100% reduce 100%</p>
<p>注意上面日志的第二行，显示job_1472052053889_0001不是以<code>uber模式</code>运行的。</p>
<h2 id="什么是uber模式"><a href="#什么是uber模式" class="headerlink" title="什么是uber模式"></a>什么是uber模式</h2><p>该模式是2.x开始引入的；以Uber模式运行MR作业，所有的Map Tasks和Reduce Tasks将会在ApplicationMaster所在的容器（container）中运行，即</p>
<blockquote>
<p>整个MR作业运行的过程只会启动AM container，</p>
</blockquote>
<p>因为不需要启动mapper 和 reducer containers，所以AM不需要和远程containers通信，整个过程简单了。</p>
<h3 id="uber模式一般用处"><a href="#uber模式一般用处" class="headerlink" title="uber模式一般用处"></a>uber模式一般用处</h3><p>如果我们的MR作业输入的数据量非常小，启动Map container或Reduce container的时间都比处理数据要长，那么这个作业就可以考虑启用Uber模式运行，一般情况下，对小作业启用Uber模式运行会得到2x-3x的性能提升。</p>
<h3 id="如何启用Uber模式"><a href="#如何启用Uber模式" class="headerlink" title="如何启用Uber模式"></a>如何启用Uber模式</h3><p>启用uber模式的要求非常严格，代码如下：</p>
<p>isUber = uberEnabled &amp;&amp; smallNumMapTasks &amp;&amp; smallNumReduceTasks &amp;&amp; smallInput &amp;&amp; smallMemory &amp;&amp; smallCpu &amp;&amp; notChainJob &amp;&amp; isValidUberMaxReduces;</p>
<ul>
<li><strong>uberEnabled</strong>：其实就是 mapreduce.job.ubertask.enable 参数的值，默认情况下为 false ；也就是说默认情况不启用Uber模式；</li>
<li><strong>smallNumMapTasks</strong>：启用Uber模式的作业Map的个数必须小于等于 mapreduce.job.ubertask.maxmaps 参数的值，该值默认为9；也计算说，在默认情况下，如果你想启用Uber模式，作业的Map个数必须小于10；</li>
<li><strong>smallNumReduceTasks</strong>：同理，Uber模式的作业Reduce的个数必须小于等于mapreduce.job.ubertask.maxreduces，该值默认为1；也计算说，在默认情况下，如果你想启用Uber模式，作业的Reduce个数必须小于等于1；</li>
<li><strong>smallInput</strong>：不是任何作业都适合启用Uber模式的，输入数据的大小必须小于等于 mapreduce.job.ubertask.maxbytes 参数的值，默认情况是HDFS一个文件块大小；</li>
<li><strong>smallMemory</strong>：因为作业是在AM所在的container中运行，所以要求我们设置的Map内存（mapreduce.map.memory.mb）和Reduce内存（mapreduce.reduce.memory.mb）必须小于等于 AM所在容器内存大小设置（yarn.app.mapreduce.am.resource.mb）；</li>
<li><strong>smallCpu</strong>：同理，Map配置的vcores（mapreduce.map.cpu.vcores）个数和 Reduce配置的vcores（mapreduce.reduce.cpu.vcores）个数也必须小于等于AM所在容器vcores个数的设置（yarn.app.mapreduce.am.resource.cpu-vcores）；</li>
<li><strong>notChainJob</strong>：此外，处理数据的Map class（mapreduce.job.map.class）和Reduce class（mapreduce.job.reduce.class）必须不是 ChainMapper 或 ChainReducer 才行；</li>
<li><strong>isValidUberMaxReduces</strong>：目前仅当Reduce的个数小于等于1的作业才能启用Uber模式。</li>
</ul>
<p>同时满足上面八个条件才能在作业运行的时候启动Uber模式。下面是一个启用Uber模式运行的作业运行成功的日志：</p>
<p>File System Counters FILE: Number of bytes read=215 FILE: Number of bytes written=505 FILE: Number of read operations=0 FILE: Number of large read operations=0 FILE: Number of write operations=0 HDFS: Number of bytes read=1200 HDFS: Number of bytes written=274907 HDFS: Number of read operations=57 HDFS: Number of large read operations=0 HDFS: Number of write operations=11 Job Counters Launched map tasks=2 Launched reduce tasks=1 Other local map tasks=2 Total time spent by all maps in occupied slots (ms)=3664 Total time spent by all reduces in occupied slots (ms)=2492 TOTAL_LAUNCHED_UBERTASKS=3 NUM_UBER_SUBMAPS=2 NUM_UBER_SUBREDUCES=1 Map-Reduce Framework Map input records=2 Map output records=8 Map output bytes=82 Map output materialized bytes=85 Input split bytes=202 Combine input records=8 Combine output records=6 Reduce input groups=5 Reduce shuffle bytes=0 Reduce input records=6 Reduce output records=5 Spilled Records=12 Shuffled Maps =0 Failed Shuffles=0 Merged Map outputs=0 GC time elapsed (ms)=65 CPU time spent (ms)=1610 Physical memory (bytes) snapshot=1229729792 Virtual memory (bytes) snapshot=5839392768 Total committed heap usage (bytes)=3087532032 File Input Format Counters Bytes Read=50 File Output Format Counters Bytes Written=41</p>
<p>细心的同学应该会发现里面多了 TOTAL_LAUNCHED_UBERTASKS、NUM_UBER_SUBMAPS 以及 NUM_UBER_SUBREDUCES 信息，以前需要启用Map Task 或 Reduce Task运行的工作直接在AM中运行，所有出现了NUM_UBER_SUBMAPS和原来Map Task个数一样；同理，NUM_UBER_SUBREDUCES 和Reduce Task个数一样。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://longzl2015.github.io/2016/04/02/hadoop%E7%94%9F%E6%80%81/hive/hive%20metaStore%E7%BB%93%E6%9E%84%E4%BB%8B%E7%BB%8D/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="zhoul">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2016/04/02/hadoop%E7%94%9F%E6%80%81/hive/hive%20metaStore%E7%BB%93%E6%9E%84%E4%BB%8B%E7%BB%8D/" class="post-title-link" itemprop="url">hive metaStore 结构介绍</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2016-04-02 22:46:48" itemprop="dateCreated datePublished" datetime="2016-04-02T22:46:48+08:00">2016-04-02</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-02-27 17:16:07" itemprop="dateModified" datetime="2020-02-27T17:16:07+08:00">2020-02-27</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/hadoop%E7%94%9F%E6%80%81/" itemprop="url" rel="index">
                    <span itemprop="name">hadoop生态</span>
                  </a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/hadoop%E7%94%9F%E6%80%81/hive/" itemprop="url" rel="index">
                    <span itemprop="name">hive</span>
                  </a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="fa fa-comment-o"></i>
      </span>
      <span class="post-meta-item-text">Disqus：</span>
    
    <a title="disqus" href="/2016/04/02/hadoop%E7%94%9F%E6%80%81/hive/hive%20metaStore%E7%BB%93%E6%9E%84%E4%BB%8B%E7%BB%8D/#comments" itemprop="discussionUrl">
      <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2016/04/02/hadoop生态/hive/hive metaStore结构介绍/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="主要表"><a href="#主要表" class="headerlink" title="主要表"></a>主要表</h2><table>
<thead>
<tr>
<th>表名</th>
<th>说明</th>
<th>关联键</th>
</tr>
</thead>
<tbody><tr>
<td>TBLS</td>
<td>所有hive表的基本信息</td>
<td>TBL_ID,SD_ID</td>
</tr>
<tr>
<td>TABLE_PARAM</td>
<td>表级属性，如是否外部表，表注释等</td>
<td>TBL_ID</td>
</tr>
<tr>
<td>COLUMNS</td>
<td>Hive表字段信息(字段注释，字段名，字段类型，字段序号)</td>
<td>SD_ID</td>
</tr>
<tr>
<td>SDS</td>
<td>所有hive表、表分区所对应的hdfs数据目录和数据格式</td>
<td>SD_ID,SERDE_ID</td>
</tr>
<tr>
<td>SERDE_PARAM</td>
<td>序列化反序列化信息，如行分隔符、列分隔符、NULL的表示字符等</td>
<td>SERDE_ID</td>
</tr>
<tr>
<td>PARTITIONS</td>
<td>Hive表分区信息</td>
<td>PART_ID,SD_ID,TBL_ID</td>
</tr>
<tr>
<td>PARTITION_KEYS</td>
<td>Hive分区表分区键</td>
<td>TBL_ID</td>
</tr>
<tr>
<td>PARTITION_KEY_VALS</td>
<td>Hive表分区名(键值)</td>
<td>PART_ID</td>
</tr>
</tbody></table>
<p>从上面表的内容来看，hive整个创建表的过程已经比较清楚了。<br>   （1）解析用户提交hive语句，对其进行解析，分解为表、字段、分区等hive对象<br>   （2）根据解析到的信息构建对应的表、字段、分区等对象，从SEQUENCE_TABLE中获取构建对象的最新ID，与构建对象信息（名称，类型等）一同通过DAO方法写入到元数据表中去，成功后将SEQUENCE_TABLE中对应的最新ID+5。</p>
<h2 id="表介绍"><a href="#表介绍" class="headerlink" title="表介绍"></a>表介绍</h2><h3 id="1、SEQUENCE-TABLE"><a href="#1、SEQUENCE-TABLE" class="headerlink" title="1、SEQUENCE_TABLE"></a>1、SEQUENCE_TABLE</h3><p> 对于db、tbl、sds等的SEQUENCE_id ,每次新增的时候 Next_Val</p>
<h3 id="2、DBS"><a href="#2、DBS" class="headerlink" title="2、DBS"></a>2、DBS</h3><p>存储hive的DB信息，包括描述信息、存储路径、数据库名、拥有者和角色名</p>
<h3 id="3、DATABASE-PARAMS"><a href="#3、DATABASE-PARAMS" class="headerlink" title="3、DATABASE_PARAMS"></a>3、DATABASE_PARAMS</h3><p>db的key-value参数 ，不清楚用途。</p>
<p>###4、SDS</p>
<p>提供文件路径location、InputFormat、OutputFormat、是否压缩、是否是子文件夹存储、SerDe类（对应于SERDES表）。</p>
<p>SerDe类表示各种序列化和反序列化的类。</p>
<h3 id="5、SD-PARAMS"><a href="#5、SD-PARAMS" class="headerlink" title="5、SD_PARAMS"></a>5、SD_PARAMS</h3><p>每个SDS的key-value参数</p>
<h3 id="6、SERDES"><a href="#6、SERDES" class="headerlink" title="6、SERDES"></a>6、SERDES</h3><p>每个SDS对应的存储的SerDer类，每个SDS记录一个SERDES表的记录</p>
<h3 id="7、SERDE-PARAMS"><a href="#7、SERDE-PARAMS" class="headerlink" title="7、SERDE_PARAMS"></a>7、SERDE_PARAMS</h3><p>SERDE的一些参数，主要是行分隔符、列分隔符、NULL字符串等等，可以每个SerDer自己定义 </p>
<h3 id="8、CDS"><a href="#8、CDS" class="headerlink" title="8、CDS"></a>8、CDS</h3><p>暂时没明白到底是什么，不过其id和tbl_id是一致的，貌似就是tbl_id</p>
<h3 id="9、TBLS"><a href="#9、TBLS" class="headerlink" title="9、TBLS"></a>9、TBLS</h3><p>table的具体信息。 </p>
<p>Tabid、创建时间、数据库id、last_access、owner(这个后面会和权限控制有关)、表的存储位置id、表名、TBL_TYPE（外部表、内部表）等</p>
<h3 id="10、TABLE-PARAMS"><a href="#10、TABLE-PARAMS" class="headerlink" title="10、TABLE_PARAMS"></a>10、TABLE_PARAMS</h3><p>table级别的key-value参数</p>
<p>主要是总文件个数、总文件大小、comment、last_ddl_time（上次执行ddl的时间）、以及用户自定义的一些参数（orcfile中的参数）</p>
<h3 id="11、COLUMNS-V2"><a href="#11、COLUMNS-V2" class="headerlink" title="11、COLUMNS_V2"></a>11、COLUMNS_V2</h3><p>列的信息</p>
<p>CD_ID对应的应该是tbl_id  </p>
<h3 id="12、PARTITION-KEYS"><a href="#12、PARTITION-KEYS" class="headerlink" title="12、PARTITION_KEYS"></a>12、PARTITION_KEYS</h3><p>每个表的partitions 列 </p>
<h3 id="13、PARTITIONS"><a href="#13、PARTITIONS" class="headerlink" title="13、PARTITIONS"></a>13、PARTITIONS</h3><p>Partitions id 、create_time、part_name、sds_id、tbl_id</p>
<h3 id="14、PARTITION-KEY-VALS"><a href="#14、PARTITION-KEY-VALS" class="headerlink" title="14、PARTITION_KEY_VALS"></a>14、PARTITION_KEY_VALS</h3><p>和上面的表对应，每个partitions对应的具体值 </p>
<h3 id="15、PARTITION-PARAMS"><a href="#15、PARTITION-PARAMS" class="headerlink" title="15、PARTITION_PARAMS"></a>15、PARTITION_PARAMS</h3><p>分区参数，暂时为找到怎么设置每个分区的key-value参数</p>
<h3 id="16、PART-COL-STATS"><a href="#16、PART-COL-STATS" class="headerlink" title="16、PART_COL_STATS"></a>16、PART_COL_STATS</h3><p>对于每列的统计信息，在0.11以后增加了 </p>
<p><code>ANALYZE table contline_revenue_day PARTITION(pdate=&#39;2014-03-09&#39;) compute statistics for COLUMNS contract_line_id , st_date ,contract_no ;</code></p>
<p>这样的ddl命令来用于统计每个分区的基本统计信息，用于优化 </p>
<h3 id="17-未用到的空表"><a href="#17-未用到的空表" class="headerlink" title="17.     未用到的空表"></a>17.     未用到的空表</h3><p>BUCKETING_COLS ：</p>
<p>IDXS</p>
<p>INDEX_PARAMS</p>
<p>SKEWED_COL_NAMES</p>
<p>SKEWED_COL_VALUE_LOC_MAP</p>
<p>SKEWED_STRING_LIST</p>
<p>SKEWED_STRING_LIST_VALUES</p>
<p>SKEWED_VALUES</p>
<p>SORT_COLS</p>
<p>VERSION</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://longzl2015.github.io/2016/04/02/hadoop%E7%94%9F%E6%80%81/hive/hive_sql_%E6%8E%92%E5%BA%8F/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="zhoul">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2016/04/02/hadoop%E7%94%9F%E6%80%81/hive/hive_sql_%E6%8E%92%E5%BA%8F/" class="post-title-link" itemprop="url">Hive - row_number,rank(),dense_rank()</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2016-04-02 22:46:48" itemprop="dateCreated datePublished" datetime="2016-04-02T22:46:48+08:00">2016-04-02</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-02-27 17:16:07" itemprop="dateModified" datetime="2020-02-27T17:16:07+08:00">2020-02-27</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/hadoop%E7%94%9F%E6%80%81/" itemprop="url" rel="index">
                    <span itemprop="name">hadoop生态</span>
                  </a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/hadoop%E7%94%9F%E6%80%81/hive/" itemprop="url" rel="index">
                    <span itemprop="name">hive</span>
                  </a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="fa fa-comment-o"></i>
      </span>
      <span class="post-meta-item-text">Disqus：</span>
    
    <a title="disqus" href="/2016/04/02/hadoop%E7%94%9F%E6%80%81/hive/hive_sql_%E6%8E%92%E5%BA%8F/#comments" itemprop="discussionUrl">
      <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2016/04/02/hadoop生态/hive/hive_sql_排序/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h3 id="1-准备数据"><a href="#1-准备数据" class="headerlink" title="1. 准备数据"></a>1. 准备数据</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">浙江,杭州,300</span><br><span class="line">浙江,宁波,150</span><br><span class="line">浙江,温州,200</span><br><span class="line">浙江,嘉兴,100</span><br><span class="line">江苏,南京,270</span><br><span class="line">江苏,苏州,299</span><br><span class="line">江苏,某市,200</span><br><span class="line">江苏,某某市,100</span><br></pre></td></tr></table></figure>

<h3 id="2-创建表"><a href="#2-创建表" class="headerlink" title="2. 创建表"></a>2. 创建表</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">table</span> pcp</span><br><span class="line">(province <span class="keyword">string</span>,city <span class="keyword">string</span>,people <span class="built_in">int</span>)</span><br><span class="line"><span class="keyword">ROW</span> <span class="keyword">FORMAT</span> <span class="keyword">DELIMITED</span> <span class="keyword">FIELDS</span> <span class="keyword">TERMINATED</span> <span class="keyword">BY</span> <span class="string">','</span></span><br><span class="line"><span class="keyword">STORED</span> <span class="keyword">AS</span> TEXTFILE;</span><br></pre></td></tr></table></figure>

<h3 id="3-导入数据"><a href="#3-导入数据" class="headerlink" title="3. 导入数据"></a>3. 导入数据</h3><blockquote>
<p>load data inpath ‘/tmp/1.txt’ into table pcp;</p>
</blockquote>
<h3 id="4-普通查询"><a href="#4-普通查询" class="headerlink" title="4. 普通查询"></a>4. 普通查询</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> pcp <span class="keyword">order</span> <span class="keyword">by</span> people <span class="keyword">desc</span>;</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">浙江    杭州    300</span><br><span class="line">浙江    宁波    150</span><br><span class="line">浙江    温州    200</span><br><span class="line">浙江    嘉兴    100</span><br><span class="line">江苏    南京    270</span><br><span class="line">江苏    苏州    299</span><br><span class="line">江苏    某市    200</span><br><span class="line">江苏    某某市    100</span><br></pre></td></tr></table></figure>

<h3 id="5-综合查询"><a href="#5-综合查询" class="headerlink" title="5. 综合查询"></a>5. 综合查询</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> province,city,</span><br><span class="line"><span class="keyword">rank</span>() <span class="keyword">over</span>(<span class="keyword">order</span> <span class="keyword">by</span> people <span class="keyword">desc</span>) <span class="keyword">rank</span>,</span><br><span class="line"><span class="keyword">dense_rank</span>() <span class="keyword">over</span>(<span class="keyword">order</span> <span class="keyword">by</span> people <span class="keyword">desc</span>) <span class="keyword">dense_rank</span>,</span><br><span class="line">row_number() <span class="keyword">over</span>(<span class="keyword">order</span> <span class="keyword">by</span> people <span class="keyword">desc</span>) row_number</span><br><span class="line"><span class="keyword">from</span> pcp</span><br><span class="line"><span class="keyword">group</span> <span class="keyword">by</span> province,city,people;</span><br></pre></td></tr></table></figure>

<pre><code>浙江    杭州    300    1    1    1
江苏    苏州    299    2    2    2
江苏    南京    270    3    3    3
江苏    某市    200    4    4    4
浙江    温州    200    4    4    5
浙江    宁波    150    6    5    6
江苏    某某市    100    7    6    7
浙江    嘉兴    100    7    6    8</code></pre><p>主要注意4,5,6行的:</p>
<p>row_number:顺序下来,<br>rank:在遇到数据相同项时,会留下空位,(4，5，6 第一列,4,4,6)<br>dense_rank:在遇到数据相同项时,不会留下空位,(4，5，6第一列,4,4,5)</p>
<h3 id="6-分组统计查询"><a href="#6-分组统计查询" class="headerlink" title="6. 分组统计查询"></a>6. 分组统计查询</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> province,city,</span><br><span class="line"><span class="keyword">rank</span>() <span class="keyword">over</span> (<span class="keyword">partition</span> <span class="keyword">by</span> province <span class="keyword">order</span> <span class="keyword">by</span> people <span class="keyword">desc</span>) <span class="keyword">rank</span>,</span><br><span class="line"><span class="keyword">dense_rank</span>() <span class="keyword">over</span> (<span class="keyword">partition</span> <span class="keyword">by</span> province <span class="keyword">order</span> <span class="keyword">by</span> people <span class="keyword">desc</span>) <span class="keyword">dense_rank</span>,</span><br><span class="line">row_number() <span class="keyword">over</span>(<span class="keyword">partition</span> <span class="keyword">by</span> province <span class="keyword">order</span> <span class="keyword">by</span> people <span class="keyword">desc</span>) row_number</span><br><span class="line"><span class="keyword">from</span> pcp</span><br><span class="line"><span class="keyword">group</span> <span class="keyword">by</span> province,city,people;</span><br></pre></td></tr></table></figure>

<pre><code>江苏    苏州    299    1    1    1
江苏    南京    270    2    2    2
江苏    某市    200    3    3    3
江苏    某某市    100    4    4    4
浙江    杭州    300    1    1    1
浙江    温州    200    2    2    2
浙江    宁波    150    3    3    3
浙江    嘉兴    100    4    4    4</code></pre>
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://longzl2015.github.io/2016/04/02/hadoop%E7%94%9F%E6%80%81/parquet/Parquet_tool%E5%91%BD%E4%BB%A4%E8%A1%8C%E4%BD%BF%E7%94%A8/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="zhoul">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2016/04/02/hadoop%E7%94%9F%E6%80%81/parquet/Parquet_tool%E5%91%BD%E4%BB%A4%E8%A1%8C%E4%BD%BF%E7%94%A8/" class="post-title-link" itemprop="url">Parquet-tool命令行使用</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2016-04-02 22:46:48" itemprop="dateCreated datePublished" datetime="2016-04-02T22:46:48+08:00">2016-04-02</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-02-27 17:16:07" itemprop="dateModified" datetime="2020-02-27T17:16:07+08:00">2020-02-27</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/hadoop%E7%94%9F%E6%80%81/" itemprop="url" rel="index">
                    <span itemprop="name">hadoop生态</span>
                  </a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/hadoop%E7%94%9F%E6%80%81/parquet/" itemprop="url" rel="index">
                    <span itemprop="name">parquet</span>
                  </a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="fa fa-comment-o"></i>
      </span>
      <span class="post-meta-item-text">Disqus：</span>
    
    <a title="disqus" href="/2016/04/02/hadoop%E7%94%9F%E6%80%81/parquet/Parquet_tool%E5%91%BD%E4%BB%A4%E8%A1%8C%E4%BD%BF%E7%94%A8/#comments" itemprop="discussionUrl">
      <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2016/04/02/hadoop生态/parquet/Parquet_tool命令行使用/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>To examine the internal structure and data of Parquet files, you can use the parquet-tools command that comes with CDH. Make sure this command is in your $PATH. (Typically, it is symlinked from /usr/bin; sometimes, depending on your installation setup, you might need to locate it under a CDH-specific bin directory.) The arguments to this command let you perform operations such as:</p>
<ul>
<li>cat:    打印文件的全部内容信息到标准输出</li>
<li>head:  打印文件的头几行内容信息到标准输出</li>
<li>schema: 打印Parquet的schema</li>
<li>meta: 打印 file footer metadata, 包含 key-value properties (like Avro schema), compression ratios, encodings, compression used, and row group information.</li>
<li>dump: 打印所有数据和metadata.</li>
</ul>
<p>如果没有将jar配置到环境变量，可以使用<code>java -jar parquet-tools-1.8.2.jar -h</code></p>
<p>Use parquet-tools -h to see usage information for all the arguments. Here are some examples showing parquet-tools usage</p>
<h3 id="cat-命令"><a href="#cat-命令" class="headerlink" title="cat 命令"></a>cat 命令</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="comment"># Be careful doing this for a big file! Use parquet-tools head to be safe.</span></span><br><span class="line">$ parquet-tools cat sample.parq</span><br><span class="line">year = 1992</span><br><span class="line">month = 1</span><br><span class="line">day = 2</span><br><span class="line">dayofweek = 4</span><br><span class="line">dep_time = 748</span><br><span class="line">crs_dep_time = 750</span><br><span class="line">arr_time = 851</span><br><span class="line">crs_arr_time = 846</span><br><span class="line">carrier = US</span><br><span class="line">flight_num = 53</span><br><span class="line">actual_elapsed_time = 63</span><br><span class="line">crs_elapsed_time = 56</span><br><span class="line">arrdelay = 5</span><br><span class="line">depdelay = -2</span><br><span class="line">origin = CMH</span><br><span class="line">dest = IND</span><br><span class="line">distance = 182</span><br><span class="line">cancelled = 0</span><br><span class="line">diverted = 0</span><br><span class="line"></span><br><span class="line">year = 1992</span><br><span class="line">month = 1</span><br><span class="line">day = 3</span><br><span class="line">...</span><br></pre></td></tr></table></figure>

<h3 id="head-命令"><a href="#head-命令" class="headerlink" title="head 命令"></a>head 命令</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">$ parquet-tools head -n 2 sample.parq</span><br><span class="line">year = 1992</span><br><span class="line">month = 1</span><br><span class="line">day = 2</span><br><span class="line">dayofweek = 4</span><br><span class="line">dep_time = 748</span><br><span class="line">crs_dep_time = 750</span><br><span class="line">arr_time = 851</span><br><span class="line">crs_arr_time = 846</span><br><span class="line">carrier = US</span><br><span class="line">flight_num = 53</span><br><span class="line">actual_elapsed_time = 63</span><br><span class="line">crs_elapsed_time = 56</span><br><span class="line">arrdelay = 5</span><br><span class="line">depdelay = -2</span><br><span class="line">origin = CMH</span><br><span class="line">dest = IND</span><br><span class="line">distance = 182</span><br><span class="line">cancelled = 0</span><br><span class="line">diverted = 0</span><br><span class="line"></span><br><span class="line">year = 1992</span><br><span class="line">month = 1</span><br><span class="line">day = 3</span><br><span class="line">...</span><br></pre></td></tr></table></figure>

<h3 id="schema命令"><a href="#schema命令" class="headerlink" title="schema命令"></a>schema命令</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">$ parquet-tools schema sample.parq</span><br><span class="line">message schema &#123;</span><br><span class="line">optional int32 year;</span><br><span class="line">optional int32 month;</span><br><span class="line">optional int32 day;</span><br><span class="line">optional int32 dayofweek;</span><br><span class="line">optional int32 dep_time;</span><br><span class="line">optional int32 crs_dep_time;</span><br><span class="line">optional int32 arr_time;</span><br><span class="line">optional int32 crs_arr_time;</span><br><span class="line">optional binary carrier;</span><br><span class="line">optional int32 flight_num;</span><br><span class="line">...</span><br></pre></td></tr></table></figure>

<h3 id="meta-命令"><a href="#meta-命令" class="headerlink" title="meta 命令"></a>meta 命令</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">$ parquet-tools meta sample.parq</span><br><span class="line">creator:             impala version 2.2.0-cdh5.4.3 (build 517bb0f71cd604a00369254ac6d88394df83e0f6)</span><br><span class="line"></span><br><span class="line">file schema:         schema</span><br><span class="line">-------------------------------------------------------------------</span><br><span class="line">year:                OPTIONAL INT32 R:0 D:1</span><br><span class="line">month:               OPTIONAL INT32 R:0 D:1</span><br><span class="line">day:                 OPTIONAL INT32 R:0 D:1</span><br><span class="line">dayofweek:           OPTIONAL INT32 R:0 D:1</span><br><span class="line">dep_time:            OPTIONAL INT32 R:0 D:1</span><br><span class="line">crs_dep_time:        OPTIONAL INT32 R:0 D:1</span><br><span class="line">arr_time:            OPTIONAL INT32 R:0 D:1</span><br><span class="line">crs_arr_time:        OPTIONAL INT32 R:0 D:1</span><br><span class="line">carrier:             OPTIONAL BINARY R:0 D:1</span><br><span class="line">flight_num:          OPTIONAL INT32 R:0 D:1</span><br><span class="line">...</span><br><span class="line"></span><br><span class="line">row group 1:         RC:20636601 TS:265103674</span><br><span class="line">-------------------------------------------------------------------</span><br><span class="line">year:                 INT32 SNAPPY DO:4 FPO:35 SZ:10103/49723/4.92 VC:20636601 ENC:PLAIN_DICTIONARY,RLE,PLAIN</span><br><span class="line">month:                INT32 SNAPPY DO:10147 FPO:10210 SZ:11380/35732/3.14 VC:20636601 ENC:PLAIN_DICTIONARY,RLE,PLAIN</span><br><span class="line">day:                  INT32 SNAPPY DO:21572 FPO:21714 SZ:3071658/9868452/3.21 VC:20636601 ENC:PLAIN_DICTIONARY,RLE,PLAIN</span><br><span class="line">dayofweek:            INT32 SNAPPY DO:3093276 FPO:3093319 SZ:2274375/5941876/2.61 VC:20636601 ENC:PLAIN_DICTIONARY,RLE,PLAIN</span><br><span class="line">dep_time:             INT32 SNAPPY DO:5367705 FPO:5373967 SZ:28281281/28573175/1.01 VC:20636601 ENC:PLAIN_DICTIONARY,RLE,PLAIN</span><br><span class="line">crs_dep_time:         INT32 SNAPPY DO:33649039 FPO:33654262 SZ:10220839/11574964/1.13 VC:20636601 ENC:PLAIN_DICTIONARY,RLE,PLAIN</span><br><span class="line">arr_time:             INT32 SNAPPY DO:43869935 FPO:43876489 SZ:28562410/28797767/1.01 VC:20636601 ENC:PLAIN_DICTIONARY,RLE,PLAIN</span><br><span class="line">crs_arr_time:         INT32 SNAPPY DO:72432398 FPO:72438151 SZ:10908972/12164626/1.12 VC:20636601 ENC:PLAIN_DICTIONARY,RLE,PLAIN</span><br><span class="line">carrier:              BINARY SNAPPY DO:83341427 FPO:83341558 SZ:114916/128611/1.12 VC:20636601 ENC:PLAIN_DICTIONARY,RLE,PLAIN</span><br><span class="line">flight_num:           INT32 SNAPPY DO:83456393 FPO:83488603 SZ:10216514/11474301/1.12 VC:20636601 ENC:PLAIN_DICTIONARY,RLE,PLAIN</span><br><span class="line">...</span><br></pre></td></tr></table></figure>

<h2 id="Meta-Legend"><a href="#Meta-Legend" class="headerlink" title="Meta Legend"></a>Meta Legend</h2><h3 id="Row-Group-Totals"><a href="#Row-Group-Totals" class="headerlink" title="Row Group Totals"></a>Row Group Totals</h3><table>
<thead>
<tr>
<th>Acronym</th>
<th>Definition</th>
</tr>
</thead>
<tbody><tr>
<td>RC</td>
<td>Row Count</td>
</tr>
<tr>
<td>TS</td>
<td>Total Byte Size</td>
</tr>
</tbody></table>
<h3 id="Row-Group-Column-Details"><a href="#Row-Group-Column-Details" class="headerlink" title="Row Group Column Details"></a>Row Group Column Details</h3><table>
<thead>
<tr>
<th>Acronym</th>
<th>Definition</th>
</tr>
</thead>
<tbody><tr>
<td>DO</td>
<td>Dictionary Page Offset</td>
</tr>
<tr>
<td>FPO</td>
<td>First Data Page Offset</td>
</tr>
<tr>
<td>SZ:{x}/{y}/{z}</td>
<td>Size in bytes. x = Compressed total, y = uncompressed total, z = y:x ratio</td>
</tr>
<tr>
<td>VC</td>
<td>Value Count</td>
</tr>
<tr>
<td>RLE</td>
<td>Run-Length Encoding</td>
</tr>
</tbody></table>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://longzl2015.github.io/2016/04/02/hadoop%E7%94%9F%E6%80%81/parquet/parquet%20%E6%96%87%E4%BB%B6%E8%AF%BB%E5%8F%96/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="zhoul">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2016/04/02/hadoop%E7%94%9F%E6%80%81/parquet/parquet%20%E6%96%87%E4%BB%B6%E8%AF%BB%E5%8F%96/" class="post-title-link" itemprop="url">parquet 文件读取</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2016-04-02 22:46:48" itemprop="dateCreated datePublished" datetime="2016-04-02T22:46:48+08:00">2016-04-02</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-02-27 17:16:07" itemprop="dateModified" datetime="2020-02-27T17:16:07+08:00">2020-02-27</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/hadoop%E7%94%9F%E6%80%81/" itemprop="url" rel="index">
                    <span itemprop="name">hadoop生态</span>
                  </a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/hadoop%E7%94%9F%E6%80%81/parquet/" itemprop="url" rel="index">
                    <span itemprop="name">parquet</span>
                  </a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="fa fa-comment-o"></i>
      </span>
      <span class="post-meta-item-text">Disqus：</span>
    
    <a title="disqus" href="/2016/04/02/hadoop%E7%94%9F%E6%80%81/parquet/parquet%20%E6%96%87%E4%BB%B6%E8%AF%BB%E5%8F%96/#comments" itemprop="discussionUrl">
      <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2016/04/02/hadoop生态/parquet/parquet 文件读取/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="获取文件行数-ParquetFileReader-readFooters"><a href="#获取文件行数-ParquetFileReader-readFooters" class="headerlink" title="获取文件行数 - ParquetFileReader.readFooters"></a>获取文件行数 - ParquetFileReader.readFooters</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">String hdfspath = <span class="string">"/user/mls_zl/mysql2hdfs/parquet/time"</span>;</span><br><span class="line">      Configuration configuration = <span class="keyword">new</span> Configuration(<span class="keyword">true</span>);</span><br><span class="line">      configuration.set(<span class="string">"fs.defaultFS"</span>, <span class="string">"hdfs://10.100.1.131:9000"</span>);</span><br><span class="line">      Path inputPath = <span class="keyword">new</span> Path(hdfspath);</span><br><span class="line"></span><br><span class="line">      FileStatus inputFileStatus = inputPath.getFileSystem(configuration).getFileStatus(inputPath);</span><br><span class="line">      List&lt;Footer&gt; footers = org.apache.parquet.hadoop.ParquetFileReader.readFooters(HdfsUtils.getConfiguration(),</span><br><span class="line">              inputFileStatus, <span class="keyword">false</span>);</span><br><span class="line">      <span class="keyword">for</span> (Footer footer : footers) &#123;</span><br><span class="line">          System.out.println(<span class="string">"file:"</span> + footer.getFile().toString());</span><br><span class="line">          <span class="keyword">long</span> cout = <span class="number">0</span>;</span><br><span class="line">          <span class="keyword">for</span> (BlockMetaData blockMetaData : footer.getParquetMetadata().getBlocks()) &#123;</span><br><span class="line">              cout += blockMetaData.getRowCount();</span><br><span class="line">          &#125;</span><br><span class="line"></span><br><span class="line">          System.out.println(<span class="string">"size:"</span> + cout);</span><br><span class="line">      &#125;</span><br></pre></td></tr></table></figure>



<h2 id="递归统计-RemoteIterator"><a href="#递归统计-RemoteIterator" class="headerlink" title="递归统计 - RemoteIterator"></a>递归统计 - RemoteIterator<LocatedFileStatus></h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">fs = FileSystem.get(HdfsUtils.getConfiguration());</span><br><span class="line">Path parquetFile;</span><br><span class="line"><span class="keyword">boolean</span> isFirst = <span class="keyword">true</span>;</span><br><span class="line"></span><br><span class="line">RemoteIterator&lt;LocatedFileStatus&gt; listFiles = fs.listFiles(<span class="keyword">new</span> Path(tablePath), <span class="keyword">true</span>);</span><br><span class="line"><span class="keyword">while</span> (listFiles.hasNext()) &#123;</span><br><span class="line">    LocatedFileStatus fileStatus = listFiles.next();</span><br><span class="line">    <span class="keyword">if</span> (fileStatus.isFile() &amp;&amp; fileStatus.getPath().toString().toLowerCase().endsWith(<span class="string">".parquet"</span>)) &#123;</span><br><span class="line">        parquetFile = fileStatus.getPath();</span><br><span class="line">        fileSize += fileStatus.getLen();</span><br><span class="line"></span><br><span class="line">        parquetFileReader = <span class="keyword">new</span> ParquetFileReader(HdfsUtils.getConfiguration(), parquetFile,</span><br><span class="line">                ParquetMetadataConverter.NO_FILTER);</span><br><span class="line">        rows += parquetFileReader.getRecordCount();</span><br><span class="line">        <span class="keyword">if</span> (isFirst) &#123;</span><br><span class="line">            columns = (<span class="keyword">long</span>) parquetFileReader.getFileMetaData().getSchema().getFieldCount();</span><br><span class="line">            isFirst = <span class="keyword">false</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        parquetFileReader.close();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h2 id="读取文件信息"><a href="#读取文件信息" class="headerlink" title="读取文件信息"></a>读取文件信息</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">read1</span><span class="params">()</span></span>&#123;</span><br><span class="line">	ParquetMetadata readFooter = ParquetFileReader.readFooter(fs.getConf(), path, ParquetMetadataConverter.NO_FILTER);</span><br><span class="line">    MessageType schema = readFooter.getFileMetaData().getSchema();</span><br><span class="line">    List&lt;type&gt; columnInfos = schema.getFields();</span><br><span class="line">    ParquetReader&lt;group&gt; reader = ParquetReader.builder(<span class="keyword">new</span> GroupReadSupport(), path).</span><br><span class="line">                             withConf(fs.getConf()).build();</span><br><span class="line">    <span class="keyword">int</span> count = <span class="number">0</span>;</span><br><span class="line">    Group recordData = reader.read();</span><br><span class="line"> </span><br><span class="line">    <span class="keyword">while</span> (count &lt; <span class="number">10</span> &amp;&amp; recordData != <span class="keyword">null</span>) &#123;</span><br><span class="line">                 <span class="keyword">int</span> last = columnInfos.size() - <span class="number">1</span>;</span><br><span class="line">                 StringBuilder builder = <span class="keyword">new</span> StringBuilder();</span><br><span class="line">                 builder.append(<span class="string">"&#123;\""</span>);</span><br><span class="line">                 <span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; columnInfos.size(); j++) &#123;</span><br><span class="line">                     <span class="keyword">if</span> (j &lt; columnInfos.size() - <span class="number">1</span>) &#123;</span><br><span class="line">                         String columnName = columnInfos.get(j).getName();</span><br><span class="line">                         String value = recordData.getValueToString(j, <span class="number">0</span>);</span><br><span class="line">                         builder.append(columnName + <span class="string">"\":\""</span> + value + <span class="string">"\","</span>);</span><br><span class="line">                     &#125;</span><br><span class="line">                 &#125;</span><br><span class="line">                 String columnName = columnInfos.get(last).getName();</span><br><span class="line">                 String value = recordData.getValueToString(last, <span class="number">0</span>);</span><br><span class="line"> </span><br><span class="line">                 System.out.println(builder.toString());</span><br><span class="line">                 count++;</span><br><span class="line">                 recordData = reader.read();</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">   &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://longzl2015.github.io/2016/04/02/hadoop%E7%94%9F%E6%80%81/parquet/parquet%E6%96%87%E4%BB%B6%E6%97%B6%E9%97%B4%E6%A0%BC%E5%BC%8F%E6%80%BB%E7%BB%93/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="zhoul">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2016/04/02/hadoop%E7%94%9F%E6%80%81/parquet/parquet%E6%96%87%E4%BB%B6%E6%97%B6%E9%97%B4%E6%A0%BC%E5%BC%8F%E6%80%BB%E7%BB%93/" class="post-title-link" itemprop="url">parquet时间格式总结</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2016-04-02 22:46:48" itemprop="dateCreated datePublished" datetime="2016-04-02T22:46:48+08:00">2016-04-02</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-02-27 17:16:07" itemprop="dateModified" datetime="2020-02-27T17:16:07+08:00">2020-02-27</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/hadoop%E7%94%9F%E6%80%81/" itemprop="url" rel="index">
                    <span itemprop="name">hadoop生态</span>
                  </a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/hadoop%E7%94%9F%E6%80%81/parquet/" itemprop="url" rel="index">
                    <span itemprop="name">parquet</span>
                  </a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="fa fa-comment-o"></i>
      </span>
      <span class="post-meta-item-text">Disqus：</span>
    
    <a title="disqus" href="/2016/04/02/hadoop%E7%94%9F%E6%80%81/parquet/parquet%E6%96%87%E4%BB%B6%E6%97%B6%E9%97%B4%E6%A0%BC%E5%BC%8F%E6%80%BB%E7%BB%93/#comments" itemprop="discussionUrl">
      <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2016/04/02/hadoop生态/parquet/parquet文件时间格式总结/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="一、sqoop生成"><a href="#一、sqoop生成" class="headerlink" title="一、sqoop生成"></a>一、sqoop生成</h2><p>sqoop 将 mysql 等关系型数据库的数据导入到hive数据库中 并 生成parquet文件时，会将<code>date类型</code>转换成 <code>INT64</code>。</p>
<p>同时 sqoop 会在 parquet 的<code>fileMetaData</code>中记录原先的sql类型信息，如下所示：</p>
<table>
<thead>
<tr>
<th>type</th>
<th>sql type</th>
<th>parquet type</th>
<th>字段名</th>
</tr>
</thead>
<tbody><tr>
<td>long</td>
<td>-5</td>
<td>INT64</td>
<td>TABLE_ID</td>
</tr>
<tr>
<td>string</td>
<td>12</td>
<td>binary</td>
<td>TABLE_NAME</td>
</tr>
<tr>
<td>int</td>
<td>4</td>
<td>int32</td>
<td>TABLE_TYPE</td>
</tr>
<tr>
<td>long</td>
<td>93</td>
<td>Int64</td>
<td>MODIFY_TIME</td>
</tr>
<tr>
<td>bytes</td>
<td>-4</td>
<td>binary</td>
<td>TABLE_SCHEMA</td>
</tr>
</tbody></table>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="attr">"type"</span>: <span class="string">"record"</span>,</span><br><span class="line">  <span class="attr">"name"</span>: <span class="string">"dw_data_table"</span>,</span><br><span class="line">  <span class="attr">"doc"</span>: <span class="string">"Sqoop import of dw_data_table"</span>,</span><br><span class="line">  <span class="attr">"fields"</span>: [</span><br><span class="line">    &#123;</span><br><span class="line">      <span class="attr">"name"</span>: <span class="string">"TABLE_ID"</span>,</span><br><span class="line">      <span class="attr">"type"</span>: [</span><br><span class="line">        <span class="string">"null"</span>,</span><br><span class="line">        <span class="string">"long"</span></span><br><span class="line">      ],</span><br><span class="line">      <span class="attr">"default"</span>: <span class="literal">null</span>,</span><br><span class="line">      <span class="attr">"columnName"</span>: <span class="string">"TABLE_ID"</span>,</span><br><span class="line">      <span class="attr">"sqlType"</span>: <span class="string">"-5"</span></span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      <span class="attr">"name"</span>: <span class="string">"TABLE_NAME"</span>,</span><br><span class="line">      <span class="attr">"type"</span>: [</span><br><span class="line">        <span class="string">"null"</span>,</span><br><span class="line">        <span class="string">"string"</span></span><br><span class="line">      ],</span><br><span class="line">      <span class="attr">"default"</span>: <span class="literal">null</span>,</span><br><span class="line">      <span class="attr">"columnName"</span>: <span class="string">"TABLE_NAME"</span>,</span><br><span class="line">      <span class="attr">"sqlType"</span>: <span class="string">"12"</span></span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      <span class="attr">"name"</span>: <span class="string">"TABLE_TYPE"</span>,</span><br><span class="line">      <span class="attr">"type"</span>: [</span><br><span class="line">        <span class="string">"null"</span>,</span><br><span class="line">        <span class="string">"int"</span></span><br><span class="line">      ],</span><br><span class="line">      <span class="attr">"default"</span>: <span class="literal">null</span>,</span><br><span class="line">      <span class="attr">"columnName"</span>: <span class="string">"TABLE_TYPE"</span>,</span><br><span class="line">      <span class="attr">"sqlType"</span>: <span class="string">"4"</span></span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      <span class="attr">"name"</span>: <span class="string">"MODIFY_TIME"</span>,</span><br><span class="line">      <span class="attr">"type"</span>: [</span><br><span class="line">        <span class="string">"null"</span>,</span><br><span class="line">        <span class="string">"long"</span></span><br><span class="line">      ],</span><br><span class="line">      <span class="attr">"default"</span>: <span class="literal">null</span>,</span><br><span class="line">      <span class="attr">"columnName"</span>: <span class="string">"MODIFY_TIME"</span>,</span><br><span class="line">      <span class="attr">"sqlType"</span>: <span class="string">"93"</span></span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      <span class="attr">"name"</span>: <span class="string">"TABLE_SCHEMA"</span>,</span><br><span class="line">      <span class="attr">"type"</span>: [</span><br><span class="line">        <span class="string">"null"</span>,</span><br><span class="line">        <span class="string">"bytes"</span></span><br><span class="line">      ],</span><br><span class="line">      <span class="attr">"default"</span>: <span class="literal">null</span>,</span><br><span class="line">      <span class="attr">"columnName"</span>: <span class="string">"TABLE_SCHEMA"</span>,</span><br><span class="line">      <span class="attr">"sqlType"</span>: <span class="string">"-4"</span></span><br><span class="line">    &#125;</span><br><span class="line">  ],</span><br><span class="line">  <span class="attr">"tableName"</span>: <span class="string">"dw_data_table"</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h2 id="二、spark-生成"><a href="#二、spark-生成" class="headerlink" title="二、spark 生成"></a>二、spark 生成</h2><p>Spark 将 mysql 等关系型数据库的数据导入到hdfs中 并 生成parquet文件时，会将<code>date类型</code>转换成 <code>INT96</code>。</p>
<p>同样 spark也会在 parquet 的fileMetaData中记录相关类型信息，如下所示：</p>
<table>
<thead>
<tr>
<th align="left">type</th>
<th>字段名</th>
<th>parquet type</th>
</tr>
</thead>
<tbody><tr>
<td align="left">long</td>
<td>TABLE_ID</td>
<td>INT64</td>
</tr>
<tr>
<td align="left">string</td>
<td>TABLE_NAME</td>
<td>binary</td>
</tr>
<tr>
<td align="left">int</td>
<td>TABLE_TYPE</td>
<td>int32</td>
</tr>
<tr>
<td align="left">timestamp</td>
<td>LAST_UPDATE_TIME</td>
<td>Int96</td>
</tr>
<tr>
<td align="left">binary</td>
<td>TABLE_SCHEMA</td>
<td>binary</td>
</tr>
</tbody></table>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="attr">"type"</span>: <span class="string">"struct"</span>,</span><br><span class="line">  <span class="attr">"fields"</span>: [</span><br><span class="line">    &#123;</span><br><span class="line">      <span class="attr">"name"</span>: <span class="string">"TABLE_ID"</span>,</span><br><span class="line">      <span class="attr">"type"</span>: <span class="string">"long"</span>,</span><br><span class="line">      <span class="attr">"nullable"</span>: <span class="literal">false</span>,</span><br><span class="line">      <span class="attr">"metadata"</span>: &#123;</span><br><span class="line">        <span class="attr">"name"</span>: <span class="string">"TABLE_ID"</span>,</span><br><span class="line">        <span class="attr">"scale"</span>: <span class="number">0</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      <span class="attr">"name"</span>: <span class="string">"TABLE_NAME"</span>,</span><br><span class="line">      <span class="attr">"type"</span>: <span class="string">"string"</span>,</span><br><span class="line">      <span class="attr">"nullable"</span>: <span class="literal">false</span>,</span><br><span class="line">      <span class="attr">"metadata"</span>: &#123;</span><br><span class="line">        <span class="attr">"name"</span>: <span class="string">"TABLE_NAME"</span>,</span><br><span class="line">        <span class="attr">"scale"</span>: <span class="number">0</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      <span class="attr">"name"</span>: <span class="string">"TABLE_TYPE"</span>,</span><br><span class="line">      <span class="attr">"type"</span>: <span class="string">"integer"</span>,</span><br><span class="line">      <span class="attr">"nullable"</span>: <span class="literal">false</span>,</span><br><span class="line">      <span class="attr">"metadata"</span>: &#123;</span><br><span class="line">        <span class="attr">"name"</span>: <span class="string">"TABLE_TYPE"</span>,</span><br><span class="line">        <span class="attr">"scale"</span>: <span class="number">0</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      <span class="attr">"name"</span>: <span class="string">"LAST_UPDATE_TIME"</span>,</span><br><span class="line">      <span class="attr">"type"</span>: <span class="string">"timestamp"</span>,</span><br><span class="line">      <span class="attr">"nullable"</span>: <span class="literal">false</span>,</span><br><span class="line">      <span class="attr">"metadata"</span>: &#123;</span><br><span class="line">        <span class="attr">"name"</span>: <span class="string">"LAST_UPDATE_TIME"</span>,</span><br><span class="line">        <span class="attr">"scale"</span>: <span class="number">0</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      <span class="attr">"name"</span>: <span class="string">"TABLE_SCHEMA"</span>,</span><br><span class="line">      <span class="attr">"type"</span>: <span class="string">"binary"</span>,</span><br><span class="line">      <span class="attr">"nullable"</span>: <span class="literal">true</span>,</span><br><span class="line">      <span class="attr">"metadata"</span>: &#123;</span><br><span class="line">        <span class="attr">"name"</span>: <span class="string">"TABLE_SCHEMA"</span>,</span><br><span class="line">        <span class="attr">"scale"</span>: <span class="number">0</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="三、-总结"><a href="#三、-总结" class="headerlink" title="三、 总结"></a>三、 总结</h2><h3 id="3-1-对于-INT96"><a href="#3-1-对于-INT96" class="headerlink" title="3.1 对于 INT96"></a>3.1 对于 INT96</h3><p>一定是timestamp类型</p>
<h3 id="3-2-对于INT64"><a href="#3-2-对于INT64" class="headerlink" title="3.2 对于INT64"></a>3.2 对于INT64</h3><p>可能是 </p>
<p>源码：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line">typeName <span class="keyword">match</span> &#123;</span><br><span class="line">     <span class="keyword">case</span> <span class="type">BOOLEAN</span> =&gt; <span class="type">BooleanType</span></span><br><span class="line"></span><br><span class="line">     <span class="keyword">case</span> <span class="type">FLOAT</span> =&gt; <span class="type">FloatType</span></span><br><span class="line"></span><br><span class="line">     <span class="keyword">case</span> <span class="type">DOUBLE</span> =&gt; <span class="type">DoubleType</span></span><br><span class="line"></span><br><span class="line">     <span class="keyword">case</span> <span class="type">INT32</span> =&gt;</span><br><span class="line">       originalType <span class="keyword">match</span> &#123;</span><br><span class="line">         <span class="keyword">case</span> <span class="type">INT_8</span> =&gt; <span class="type">ByteType</span></span><br><span class="line">         <span class="keyword">case</span> <span class="type">INT_16</span> =&gt; <span class="type">ShortType</span></span><br><span class="line">         <span class="keyword">case</span> <span class="type">INT_32</span> | <span class="literal">null</span> =&gt; <span class="type">IntegerType</span></span><br><span class="line">         <span class="keyword">case</span> <span class="type">DATE</span> =&gt; <span class="type">DateType</span></span><br><span class="line">         <span class="keyword">case</span> <span class="type">DECIMAL</span> =&gt; makeDecimalType(<span class="type">Decimal</span>.<span class="type">MAX_INT_DIGITS</span>)</span><br><span class="line">         <span class="keyword">case</span> <span class="type">UINT_8</span> =&gt; typeNotSupported()</span><br><span class="line">         <span class="keyword">case</span> <span class="type">UINT_16</span> =&gt; typeNotSupported()</span><br><span class="line">         <span class="keyword">case</span> <span class="type">UINT_32</span> =&gt; typeNotSupported()</span><br><span class="line">         <span class="keyword">case</span> <span class="type">TIME_MILLIS</span> =&gt; typeNotImplemented()</span><br><span class="line">         <span class="keyword">case</span> _ =&gt; illegalType()</span><br><span class="line">       &#125;</span><br><span class="line"></span><br><span class="line">     <span class="keyword">case</span> <span class="type">INT64</span> =&gt;</span><br><span class="line">       originalType <span class="keyword">match</span> &#123;</span><br><span class="line">         <span class="keyword">case</span> <span class="type">INT_64</span> | <span class="literal">null</span> =&gt; <span class="type">LongType</span></span><br><span class="line">         <span class="keyword">case</span> <span class="type">DECIMAL</span> =&gt; makeDecimalType(<span class="type">Decimal</span>.<span class="type">MAX_LONG_DIGITS</span>)</span><br><span class="line">         <span class="keyword">case</span> <span class="type">UINT_64</span> =&gt; typeNotSupported()</span><br><span class="line">         <span class="keyword">case</span> <span class="type">TIMESTAMP_MILLIS</span> =&gt; typeNotImplemented()</span><br><span class="line">         <span class="keyword">case</span> _ =&gt; illegalType()</span><br><span class="line">       &#125;</span><br><span class="line"></span><br><span class="line">     <span class="keyword">case</span> <span class="type">INT96</span> =&gt;</span><br><span class="line">       <span class="type">ParquetSchemaConverter</span>.checkConversionRequirement(</span><br><span class="line">         assumeInt96IsTimestamp,</span><br><span class="line">         <span class="string">"INT96 is not supported unless it's interpreted as timestamp. "</span> +</span><br><span class="line">           <span class="string">s"Please try to set <span class="subst">$&#123;SQLConf.PARQUET_INT96_AS_TIMESTAMP.key&#125;</span> to true."</span>)</span><br><span class="line">       <span class="type">TimestampType</span></span><br><span class="line"></span><br><span class="line">     <span class="keyword">case</span> <span class="type">BINARY</span> =&gt;</span><br><span class="line">       originalType <span class="keyword">match</span> &#123;</span><br><span class="line">         <span class="keyword">case</span> <span class="type">UTF8</span> | <span class="type">ENUM</span> | <span class="type">JSON</span> =&gt; <span class="type">StringType</span></span><br><span class="line">         <span class="keyword">case</span> <span class="literal">null</span> <span class="keyword">if</span> assumeBinaryIsString =&gt; <span class="type">StringType</span></span><br><span class="line">         <span class="keyword">case</span> <span class="literal">null</span> =&gt; <span class="type">BinaryType</span></span><br><span class="line">         <span class="keyword">case</span> <span class="type">BSON</span> =&gt; <span class="type">BinaryType</span></span><br><span class="line">         <span class="keyword">case</span> <span class="type">DECIMAL</span> =&gt; makeDecimalType()</span><br><span class="line">         <span class="keyword">case</span> _ =&gt; illegalType()</span><br><span class="line">       &#125;</span><br><span class="line"></span><br><span class="line">     <span class="keyword">case</span> <span class="type">FIXED_LEN_BYTE_ARRAY</span> =&gt;</span><br><span class="line">       originalType <span class="keyword">match</span> &#123;</span><br><span class="line">         <span class="keyword">case</span> <span class="type">DECIMAL</span> =&gt; makeDecimalType(maxPrecisionForBytes(field.getTypeLength))</span><br><span class="line">         <span class="keyword">case</span> <span class="type">INTERVAL</span> =&gt; typeNotImplemented()</span><br><span class="line">         <span class="keyword">case</span> _ =&gt; illegalType()</span><br><span class="line">       &#125;</span><br><span class="line"></span><br><span class="line">     <span class="keyword">case</span> _ =&gt; illegalType()</span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure>




      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://longzl2015.github.io/2016/04/02/hadoop%E7%94%9F%E6%80%81/parquet/parquet%E6%96%87%E4%BB%B6%E7%BB%9F%E8%AE%A1/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="zhoul">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2016/04/02/hadoop%E7%94%9F%E6%80%81/parquet/parquet%E6%96%87%E4%BB%B6%E7%BB%9F%E8%AE%A1/" class="post-title-link" itemprop="url">parquet文件统计</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2016-04-02 22:46:48" itemprop="dateCreated datePublished" datetime="2016-04-02T22:46:48+08:00">2016-04-02</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-02-27 17:16:07" itemprop="dateModified" datetime="2020-02-27T17:16:07+08:00">2020-02-27</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/hadoop%E7%94%9F%E6%80%81/" itemprop="url" rel="index">
                    <span itemprop="name">hadoop生态</span>
                  </a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/hadoop%E7%94%9F%E6%80%81/parquet/" itemprop="url" rel="index">
                    <span itemprop="name">parquet</span>
                  </a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="fa fa-comment-o"></i>
      </span>
      <span class="post-meta-item-text">Disqus：</span>
    
    <a title="disqus" href="/2016/04/02/hadoop%E7%94%9F%E6%80%81/parquet/parquet%E6%96%87%E4%BB%B6%E7%BB%9F%E8%AE%A1/#comments" itemprop="discussionUrl">
      <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2016/04/02/hadoop生态/parquet/parquet文件统计/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> Map&lt;String, Long&gt; <span class="title">statisticsParquet</span><span class="params">(String tablePath)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">       Map&lt;String, Long&gt; map = <span class="keyword">new</span> HashMap&lt;&gt;(<span class="number">3</span>);</span><br><span class="line">       Long rows = <span class="number">0L</span>;</span><br><span class="line">       Long columns = <span class="number">0L</span>;</span><br><span class="line">       Long fileSize = <span class="number">0L</span>;</span><br><span class="line"></span><br><span class="line">       FileSystem fs = <span class="keyword">null</span>;</span><br><span class="line">       ParquetFileReader parquetFileReader = <span class="keyword">null</span>;</span><br><span class="line">       <span class="keyword">try</span> &#123;</span><br><span class="line">           fs = FileSystem.get(HdfsUtils.getConfiguration());</span><br><span class="line">           Path parquetFile;</span><br><span class="line">           <span class="keyword">boolean</span> isFirst = <span class="keyword">true</span>;</span><br><span class="line"></span><br><span class="line">           RemoteIterator&lt;LocatedFileStatus&gt; listFiles = fs.listFiles(<span class="keyword">new</span> Path(tablePath), <span class="keyword">true</span>);</span><br><span class="line">           <span class="keyword">while</span> (listFiles.hasNext()) &#123;</span><br><span class="line">               LocatedFileStatus fileStatus = listFiles.next();</span><br><span class="line">               <span class="keyword">if</span> (fileStatus.isFile() &amp;&amp; fileStatus.getPath().toString().toLowerCase().endsWith(<span class="string">".parquet"</span>)) &#123;</span><br><span class="line"></span><br><span class="line">                   parquetFile = fileStatus.getPath();</span><br><span class="line">                   fileSize += fileStatus.getLen();</span><br><span class="line"></span><br><span class="line">                   parquetFileReader = <span class="keyword">new</span> ParquetFileReader(HdfsUtils.getConfiguration(), parquetFile,</span><br><span class="line">                           ParquetMetadataConverter.NO_FILTER);</span><br><span class="line">                   rows += parquetFileReader.getRecordCount();</span><br><span class="line"></span><br><span class="line">                   <span class="keyword">if</span> (isFirst) &#123;</span><br><span class="line">                       columns = (<span class="keyword">long</span>) parquetFileReader.getFileMetaData().getSchema().getFieldCount();</span><br><span class="line">                       isFirst = <span class="keyword">false</span>;</span><br><span class="line">                   &#125;</span><br><span class="line"></span><br><span class="line">                   parquetFileReader.close();</span><br><span class="line">               &#125;</span><br><span class="line">           &#125;</span><br><span class="line"></span><br><span class="line">       &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">           <span class="keyword">if</span> (fs != <span class="keyword">null</span>) &#123;</span><br><span class="line">               <span class="keyword">try</span> &#123;</span><br><span class="line">                   fs.close();</span><br><span class="line">               &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">                   logger.error(<span class="string">"FileSystem close "</span>, e);</span><br><span class="line">               &#125;</span><br><span class="line">           &#125;</span><br><span class="line">           <span class="keyword">if</span> (parquetFileReader != <span class="keyword">null</span>) &#123;</span><br><span class="line">               <span class="keyword">try</span> &#123;</span><br><span class="line">                   parquetFileReader.close();</span><br><span class="line">               &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">                   logger.error(e.getLocalizedMessage(), e);</span><br><span class="line">               &#125;</span><br><span class="line">           &#125;</span><br><span class="line">       &#125;</span><br><span class="line"></span><br><span class="line">       map.put(<span class="string">"rows"</span>, rows);</span><br><span class="line">       map.put(<span class="string">"columns"</span>, columns);</span><br><span class="line">       map.put(<span class="string">"fileSize"</span>, fileSize);</span><br><span class="line">       <span class="keyword">return</span> map;</span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure>
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

  </div>

  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/31/"><i class="fa fa-angle-left" aria-label="上一页"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/31/">31</a><span class="page-number current">32</span><a class="page-number" href="/page/33/">33</a><span class="space">&hellip;</span><a class="page-number" href="/page/36/">36</a><a class="extend next" rel="next" href="/page/33/"><i class="fa fa-angle-right" aria-label="下一页"></i></a>
  </nav>



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let activeClass = CONFIG.comments.activeClass;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">zhoul</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">351</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">92</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">190</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/longzl2015" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;longzl2015" rel="noopener" target="_blank"><i class="fa fa-fw fa-github"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:289570126@qq.com" title="E-Mail → mailto:289570126@qq.com" rel="noopener" target="_blank"><i class="fa fa-fw fa-envelope"></i>E-Mail</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://stackoverflow.com/users/5276366/egg" title="StackOverflow → https:&#x2F;&#x2F;stackoverflow.com&#x2F;users&#x2F;5276366&#x2F;egg" rel="noopener" target="_blank"><i class="fa fa-fw fa-stack-overflow"></i>StackOverflow</a>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">zhoul</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> 强力驱动 v4.2.0
  </div>
  <span class="post-meta-divider">|</span>
  <div class="theme-info">主题 – <a href="https://theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a> v7.7.0
  </div>

        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>













  

  

<script>
  function loadCount() {
    var d = document, s = d.createElement('script');
    s.src = 'https://long12356-gitee-io.disqus.com/count.js';
    s.id = 'dsq-count-scr';
    (d.head || d.body).appendChild(s);
  }
  // defer loading until the whole page loading is completed
  window.addEventListener('load', loadCount, false);
</script>

</body>
</html>
